# Avalia√ß√£o Autom√°tica de Reda√ß√µes em Portugu√™s: Combinando Hand-Crafted Features e Transformers

Este reposit√≥rio cont√©m o c√≥digo e a metodologia para o desenvolvimento de um sistema de **Avalia√ß√£o Autom√°tica de Reda√ß√µes (AAR)** focado no contexto do ENEM. O projeto utiliza uma abordagem h√≠brida, unindo extra√ß√£o de caracter√≠sticas lingu√≠sticas manuais com modelos de deep learning.

## üìå Resumo do Projeto

A corre√ß√£o de grandes exames como o ENEM exige ferramentas que possam escalar a avalia√ß√£o mantendo a precis√£o. Este trabalho prop√µe um modelo que avalia as reda√ß√µes por compet√™ncia (C1 a C5) atrav√©s de:
1.  **Hand-crafted Features:** M√©tricas cl√°ssicas de coes√£o, gram√°tica e l√©xico.
2.  **Transformers:** Representa√ß√µes sem√¢nticas profundas utilizando o modelo **BERTimbau**.
3.  **Regress√£o Ordinal:** Uso do framework **CORAL** para garantir que o modelo respeite a hierarquia natural das notas (0 a 200).

O modelo h√≠brido alcan√ßou um **QWK m√©dio de 0,42**, demonstrando ser superior ao uso de caracter√≠sticas isoladas e competitivo com o estado da arte para o portugu√™s brasileiro.

## üõ†Ô∏è Ferramentas e Tecnologias

### Linguagem e Ambiente
* **Python 3.x**: Linguagem principal.
* **Google Colab**: Ambiente de desenvolvimento (utilizando GPU T4).

### Frameworks e Bibliotecas
* **PyTorch & PyTorch Lightning**: Constru√ß√£o e gerenciamento do ciclo de vida das redes neurais.
* **Hugging Face (Transformers)**: Implementa√ß√£o do modelo BERTimbau.
* **Coral_pytorch**: Implementa√ß√£o da camada de regress√£o ordinal.
* **Scikit-learn**: Pr√©-processamento, normaliza√ß√£o (`StandardScaler`) e sele√ß√£o de caracter√≠sticas.
* **Pandas & NumPy**: Manipula√ß√£o de dados e opera√ß√µes matriciais.
* **NILC-Metrix**: Extra√ß√£o de m√©tricas de legibilidade e complexidade.

## üìä Base de Dados

Utilizou-se o dataset **AES_ENEM** (Silveira et al., 2024), focado na "Fonte A".
* **Total de Reda√ß√µes:** 1.165 textos.
* **Divis√£o:** Treino (65%), Valida√ß√£o (17%) e Teste (18%).
* **Escala de Notas:** 0 a 200 pontos por compet√™ncia (distribui√ß√£o ordinal).

## üöÄ Como Replicar este Projeto

### 1. Prepara√ß√£o dos Dados
Extraia as caracter√≠sticas das reda√ß√µes utilizando as tr√™s frentes:
* **NILC-Metrix:** 200 caracter√≠sticas (coes√£o, sintaxe, etc).
* **M√©tricas de Neves:** 27 caracter√≠sticas (gram√°tica e sem√¢ntica).
* **TF-IDF:** 1.000 termos mais relevantes (via `SelectKBest`).

### 2. Gera√ß√£o de Embeddings
Utilize o **BERTimbau Base**. Para reda√ß√µes longas (>512 tokens), aplique a t√©cnica de **segmenta√ß√£o com stride (sobreposi√ß√£o) de 256 tokens** e extraia a m√©dia do token `[CLS]` de cada segmento.

### 3. Treinamento do Modelo
O modelo consiste em um Perceptron Multicamadas (MLP) integrado ao CORAL:
* **Arquitetura:** Camadas de 256, 128 e 64 neur√¥nios.
* **Configura√ß√£o:** Batch Size 128, Learning Rate 0,01.
* **Regulariza√ß√£o:** Early Stopping (50 √©pocas) monitorando o QWK.

### 4. Execu√ß√£o
O treinamento deve ser realizado de forma independente para cada uma das 5 compet√™ncias do ENEM.

## üìà Resultados Principais
* **Melhor Desempenho:** Modelo H√≠brido (Embedding + Neves).
* **Destaque:** Compet√™ncia 5 (Proposta de Interven√ß√£o) obteve o maior pico de concord√¢ncia (QWK 0,53) em reda√ß√µes de alto consenso humano.

---
**Desenvolvido por [Seu Nome] - 2025**
