{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GGMmattos/TCC/blob/main/TCC_Gabriel_Matos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Libs"
      ],
      "metadata": {
        "id": "neyIHZ4sV7c0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import re\n",
        "import time\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from google.colab import files\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "!pip install pytorch-lightning -q\n",
        "!pip install coral_pytorch -q\n",
        "\n",
        "import torch\n",
        "import os\n",
        "import json # Para lidar com os embeddings salvos como string JSON\n",
        "import ast # Para avaliar strings de lista de notas\n",
        "import shlex # Para o NILC Metrix (se ainda precisar rodar o script no mesmo arquivo)\n",
        "\n",
        "# Para PyTorch Lightning\n",
        "import pytorch_lightning as pl\n",
        "import torchmetrics\n",
        "from coral_pytorch.layers import CoralLayer\n",
        "from coral_pytorch.losses import coral_loss\n",
        "from coral_pytorch.dataset import levels_from_labelbatch, proba_to_label\n",
        "\n",
        "# Para Sklearn (pré-processamento e divisão de dados)\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from pytorch_lightning.loggers import CSVLogger\n"
      ],
      "metadata": {
        "id": "_A6RY2jjV6-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importação do dataset"
      ],
      "metadata": {
        "id": "al-3J8En5enw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onSyJFQc9ULx"
      },
      "source": [
        "**2018-Fonseca et al**\n",
        "\n",
        "* Automatically Grading Brazilian Student Essays - NILC Metrix  - [link NILC](http://www.nilc.icmc.usp.br/nilc/projects/unitex-pb/web/dicionarios.html) -  https://github.com/nilc-nlp/nilcmetrix\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-pBjpSQ4fng"
      },
      "outputs": [],
      "source": [
        "# Install huggingface_hub to inspect the repository\n",
        "# !pip install huggingface_hub -q\n",
        "# !huggingface-cli login\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import torch\n",
        "# from transformers import AutoTokenizer  # Or BertTokenizer\n",
        "# from transformers import AutoModelForPreTraining  # Or BertForPreTraining for loading pretraining heads\n",
        "# from transformers import AutoModel  # or BertModel, for BERT without pretraining heads"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2J8-L1wghIM"
      },
      "source": [
        "Importação do dataset [Link](https://huggingface.co/datasets/kamel-usp/aes_enem_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vLQ0qqkg6Dcl"
      },
      "outputs": [],
      "source": [
        "# # Usado no trabalho de referência Silveira (2024)\n",
        "# splits = {'train': 'PROPOR2024/train-00000-of-00001.parquet', 'validation': 'PROPOR2024/validation-00000-of-00001.parquet', 'test': 'PROPOR2024/test-00000-of-00001.parquet'}\n",
        "# df_PROPOR2024 = pd.read_parquet(\"hf://datasets/kamel-usp/aes_enem_dataset/\" + splits[\"train\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Login using e.g. `huggingface-cli login` to access this dataset\n",
        "splits = {'train': 'PROPOR2024/train-00000-of-00001.parquet', 'validation': 'PROPOR2024/validation-00000-of-00001.parquet', 'test': 'PROPOR2024/test-00000-of-00001.parquet'}\n",
        "\n",
        "# Load each split separately\n",
        "df_train = pd.read_parquet(\"hf://datasets/kamel-usp/aes_enem_dataset/\" + splits[\"train\"]) # Talves seja interessante mudarmos um pouco, estamo usando só essa repartição a princípio\n",
        "df_val = pd.read_parquet(\"hf://datasets/kamel-usp/aes_enem_dataset/\" + splits[\"validation\"])\n",
        "df_test = pd.read_parquet(\"hf://datasets/kamel-usp/aes_enem_dataset/\" + splits[\"test\"])\n",
        "\n",
        "# Concatenate the dataframes, or process them separately\n",
        "df = pd.concat([df_train, df_val, df_test], ignore_index=True)"
      ],
      "metadata": {
        "id": "e1aCR-uAi5ax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gerando embedding\n"
      ],
      "metadata": {
        "id": "dZYW-Jsu3RtE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mt4vD8Xm-b4D"
      },
      "source": [
        "BERTimbau (como a maioria dos BERTs base) tem um limite de 512 tokens para a entrada. Redações do ENEM geralmente são mais longas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rv6k2cNK8NLg"
      },
      "source": [
        "**Código para obter embedding (truncamento)** OBS: não utilizado para o nosso trabalho\n",
        "\n",
        "\n",
        "\n",
        "Simplesmente cortar a redação após 512 tokens. Simples, mas pode perder informações críticas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HCBDUqcLIX30"
      },
      "outputs": [],
      "source": [
        "# def get_bert_embedding(text, tokenizer, model, device, max_length=512):\n",
        "#     inputs = tokenizer(text, return_tensors='pt', truncation=True, max_length=max_length, padding='max_length')\n",
        "#     inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "#     with torch.no_grad(): # Desativa o cálculo de gradientes para inferência, economiza memória\n",
        "#         outputs = model(**inputs)\n",
        "\n",
        "#     # Retorna o embedding do token [CLS] da última camada\n",
        "#     # outputs.last_hidden_state[0, 0, :] é o embedding do [CLS]\n",
        "#     return outputs.last_hidden_state[0, 0, :].cpu().numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygsu-_B18fOK"
      },
      "source": [
        "**Código para obter embedding (segmentação)**\n",
        "\n",
        "Dividir a redação em pedaços de 512 tokens, gerar um embedding para cada pedaço e depois combiná-los"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HVppllive4a3"
      },
      "outputs": [],
      "source": [
        "def get_bert_embedding_segmented(text, tokenizer, model, device, max_length=512, stride=256):\n",
        "    \"\"\"\n",
        "    Gera um embedding BERT para um texto longo, utilizando segmentação e agregação.\n",
        "\n",
        "    Args:\n",
        "        text (str): O texto da redação.\n",
        "        tokenizer: O tokenizer do modelo BERT.\n",
        "        model: O modelo BERT (ex: BERTimbau).\n",
        "        device (torch.device): 'cuda' ou 'cpu'.\n",
        "        max_length (int): O tamanho máximo de cada segmento para o BERT (default: 512).\n",
        "        stride (int): O tamanho da sobreposição entre os segmentos (default: 256).\n",
        "                      Um stride menor significa mais sobreposição e possivelmente\n",
        "                      maior captura de contexto, mas mais processamento.\n",
        "\n",
        "    Returns:\n",
        "        np.array: O embedding combinado (média) de todos os segmentos, ou NaNs se o texto for nulo.\n",
        "    \"\"\"\n",
        "    if pd.isna(text) or not isinstance(text, str): # Lidar com possíveis valores NaN ou não-string\n",
        "        return np.full((model.config.hidden_size,), np.nan) # Retorna um array de NaNs\n",
        "\n",
        "    # Tokenizar o texto completo com o retorno de IDs (para controlar a segmentação)\n",
        "    # add_special_tokens=False para não adicionar [CLS]/[SEP] no começo e fim de cada segmento\n",
        "    # pois queremos controlar isso.\n",
        "    token_ids = tokenizer.encode(text, add_special_tokens=False)\n",
        "\n",
        "    # Lista para armazenar os embeddings de cada segmento\n",
        "    segment_embeddings = []\n",
        "\n",
        "    # Iterar sobre os tokens para criar segmentos\n",
        "    # max_length - 2 para dar espaço para [CLS] e [SEP] que serão adicionados pelo tokenizer em cada segmento\n",
        "    effective_max_length = max_length - 2\n",
        "\n",
        "    # Se o texto for muito curto, trata como um único segmento (mesmo que menor que max_length)\n",
        "    if len(token_ids) <= effective_max_length:\n",
        "        segments = [token_ids]\n",
        "    else:\n",
        "        segments = []\n",
        "        for i in range(0, len(token_ids), effective_max_length - stride):\n",
        "            segment = token_ids[i : i + effective_max_length]\n",
        "            segments.append(segment)\n",
        "            # Se o último segmento for menor que o stride (não suficiente para sobreposição),\n",
        "            # ou se já chegamos ao final, paramos.\n",
        "            if i + effective_max_length >= len(token_ids):\n",
        "                break\n",
        "\n",
        "\n",
        "    # Processar cada segmento\n",
        "    for segment in segments:\n",
        "        # Adicionar os tokens especiais para cada segmento individualmente\n",
        "        # return_tensors='pt' para PyTorch\n",
        "        # truncation=True é redundante aqui se já controlamos o tamanho, mas é bom manter\n",
        "        # padding='max_length' garante que todos os segmentos tenham o mesmo tamanho de input\n",
        "        inputs = tokenizer.prepare_for_model(\n",
        "            segment,\n",
        "            add_special_tokens=True,\n",
        "            return_tensors='pt',\n",
        "            max_length=max_length,\n",
        "            padding='max_length',\n",
        "            truncation=True # Em caso de erro na lógica de segmentação, isso garante\n",
        "        )\n",
        "\n",
        "        # Add batch dimension to each tensor in the inputs dictionary\n",
        "        inputs = {k: v.unsqueeze(0).to(device) for k, v in inputs.items()}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        # Retorna o embedding do token [CLS] do segmento\n",
        "        # outputs.last_hidden_state will now have shape (batch_size, sequence_length, hidden_size)\n",
        "        # We still want the CLS token for the single item in the batch, which is index 0\n",
        "        segment_embedding = outputs.last_hidden_state[0, 0, :].cpu().numpy()\n",
        "        segment_embeddings.append(segment_embedding)\n",
        "\n",
        "    if not segment_embeddings: # Se por algum motivo nenhum embedding foi gerado (ex: texto vazio após pré-processamento)\n",
        "        return np.full((model.config.hidden_size,), np.nan)\n",
        "\n",
        "    # Combinar os embeddings dos segmentos pela média\n",
        "    combined_embedding = np.mean(segment_embeddings, axis=0)\n",
        "\n",
        "    return combined_embedding"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # 1. Carregar o Tokenizer e o Modelo BERTimbau\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"neuralmind/bert-base-portuguese-cased\")\n",
        "# model = AutoModel.from_pretrained(\"neuralmind/bert-base-portuguese-cased\")\n",
        "\n",
        "# # Mover o modelo para a GPU, se disponível\n",
        "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# model.to(device)\n",
        "# model.eval() # Coloca o modelo em modo de avaliação"
      ],
      "metadata": {
        "id": "60QhvvivZP8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7UL04b8FeYuX"
      },
      "outputs": [],
      "source": [
        "# df['bert_embedding'] = df['essay_text'].apply(\n",
        "#     lambda text: get_bert_embedding_segmented(text, tokenizer, model, device, max_length=512, stride=256)\n",
        "# )\n",
        "\n",
        "# print(\"\\nDataFrame com embeddings BERTimbau segmentados:\")\n",
        "# print(df.head())\n",
        "\n",
        "# # Para verificar o formato do primeiro embedding:\n",
        "# print(f\"\\nShape do primeiro embedding segmentado: {df['bert_embedding'].iloc[0].shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df.head()"
      ],
      "metadata": {
        "id": "QgcKqkQDgnXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# nome_do_arquivo_csv = 'DataFrame_Final.csv'\n",
        "# df.to_csv(nome_do_arquivo_csv, index=False)"
      ],
      "metadata": {
        "id": "M_8LiNxfao-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ajuste no dataframe e Divisão (Treino, Validação, Teste)"
      ],
      "metadata": {
        "id": "uKgHVsp2tEOx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# df = pd.read_csv('/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame_Final/DataFrame_Final-2.0.csv')"
      ],
      "metadata": {
        "id": "ivhf2XsUiy1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criação da matrix X de features (contém as métricas e os embedding das redações)\n",
        "# X = df.loc[:, 'adjective_ratio':'ratio_function_to_content_words']"
      ],
      "metadata": {
        "id": "FOsDEhnSOQy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(\"Tipos de dados ANTES da limpeza:\")\n",
        "# print(X.dtypes.head(10)) # Mostra as primeiras colunas\n",
        "# print(\"\\n---\")"
      ],
      "metadata": {
        "id": "3VITQKZLXs49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# colunas_para_limpar = [col for col in X.columns] # pegamos todas as métricas"
      ],
      "metadata": {
        "id": "FzRzmrwuYbq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Iterar sobre as colunas e limpar/converter\n",
        "# for col in colunas_para_limpar:\n",
        "#     # APLICAR A LIMPEZA SOMENTE SE A COLUNA FOR DE TIPO 'object' (string)\n",
        "#     if X[col].dtype == 'object':\n",
        "#         # Substitui o ponto (separador de milhar) por vazio\n",
        "#         # E substitui a vírgula (separador decimal, se houvesse) por ponto\n",
        "#         # Depois, converte para numérico\n",
        "#         # errors='coerce' converte qualquer valor que não possa ser numérico para NaN\n",
        "#         X[col] = X[col].astype(str).str.replace('.', '', regex=False).str.replace(',', '.', regex=False)\n",
        "#         X[col] = pd.to_numeric(X[col], errors='coerce') # Use pd.to_numeric para conversão robusta\n",
        "\n",
        "# # Verificar os dtypes DEPOIS da limpeza\n",
        "# print(\"Tipos de dados DEPOIS da limpeza:\")\n",
        "# print(X.dtypes.head(10))\n",
        "# print(\"\\n---\")"
      ],
      "metadata": {
        "id": "KalDvBlkYI6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Procedimento para não gerar erro ao tentar utilizar o **StandardScaler**\n",
        "\n",
        "- Isso evita que features com valores maiores dominem o processo de aprendizado."
      ],
      "metadata": {
        "id": "j67OOVsYkxR-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Converter a string para array NumPy\n",
        "# def string_to_array(embedding_str):\n",
        "#     # Remove colchetes e espaços extras, depois divide pelos espaços\n",
        "#     embedding_str = embedding_str.strip('[]')\n",
        "#     # Divide pelos espaços e quebras de linha, filtrando valores vazios\n",
        "#     numbers = [float(x) for x in embedding_str.replace('\\n', ' ').split() if x]\n",
        "#     return np.array(numbers)\n",
        "\n",
        "# # Aplica a conversão para toda a coluna\n",
        "# conversao_embedding = df['bert_embedding'].apply(string_to_array)"
      ],
      "metadata": {
        "id": "ad-oL3W1fw03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_metrics  = np.vstack(X.values)\n",
        "# X_embeddings = np.vstack(conversao_embedding.values)\n",
        "# X_combined = np.hstack((X_metrics, X_embeddings))"
      ],
      "metadata": {
        "id": "dgVCTH7khbCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# scaler = StandardScaler()\n",
        "# X_scaled = scaler.fit_transform(X_combined)"
      ],
      "metadata": {
        "id": "XunoSUjOa86f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_scaled"
      ],
      "metadata": {
        "id": "mbiKw-_YaaNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Divisão das competências da classe alvo (y)**"
      ],
      "metadata": {
        "id": "CLGhedhL4L3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# y = df['grades'].values"
      ],
      "metadata": {
        "id": "Vmst_nEwz3uj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y_split = np.array([np.fromstring(grade_str[1:-1], sep=' ') for grade_str in y])\n",
        "# y_competencia1 = y_split[:, 0]  # Notas da competência 1\n",
        "# y_competencia2 = y_split[:, 1]  # Notas da competência 2\n",
        "# y_competencia3 = y_split[:, 2]  # Notas da competência 3\n",
        "# y_competencia4 = y_split[:, 3]  # Notas da competência 4\n",
        "# y_competencia5 = y_split[:, 4]  # Notas da competência 5\n",
        "# y_nota_final = y_split[:, 5]    # Nota final (soma das competências)"
      ],
      "metadata": {
        "id": "h07JKkLY4ZaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Config para a competência 1**"
      ],
      "metadata": {
        "id": "rhL8d11B4s4I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Divisão do Dataset (Treino, Validação, Teste)"
      ],
      "metadata": {
        "id": "iOi52kcum75z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Primeiro divide em treino + temp_teste\n",
        "# X_train0, X_temp0, y_train0, y_temp0 = train_test_split(X_scaled, y_split, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "# # Depois divide temp_teste em validação e teste\n",
        "# X_val0, X_test0, y_val0, y_test0 = train_test_split(X_temp0, y_temp0, test_size=0.5, random_state=42, stratify=y_temp)\n",
        "\n",
        "# # O 'stratify=y' é MUITO importante para garantir que a distribuição das notas\n",
        "# # seja semelhante em todos os conjuntos, o que é crucial para problemas ordinais."
      ],
      "metadata": {
        "id": "U-XNlACim7iZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O código acima resultou em um erro porque o **stratify=y** exige pelo menos 2 exemplos por classe para manter a proporção, e a saída mostra que muitas classes têm apenas 1 exemplo."
      ],
      "metadata": {
        "id": "DsCUCXPiqEjw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Algumas possíveis soluções?\n",
        "\n",
        "* Agrupe classes raras (com 1 ou 2 exemplos) em uma categoria mais ampla (ex: \"OUTROS\").\n",
        "\n",
        "* Remova o stratify (não recomendado, pois perde o balanceamento).\n",
        "\n",
        "* Use oversampling (ex: SMOTE) para aumentar exemplos das classes raras."
      ],
      "metadata": {
        "id": "Swa0txIJqUoZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remoção do stratify"
      ],
      "metadata": {
        "id": "FC0z9YGMrreg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train1, X_temp1, y_train1, y_temp1 = train_test_split(X_scaled, y_competencia1, test_size=0.3, random_state=42)\n",
        "# X_val1, X_test1, y_val1, y_test1 = train_test_split(X_temp1, y_temp1, test_size=0.5, random_state=42)"
      ],
      "metadata": {
        "id": "oR1FYsCdrq-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resultado da Divisão (ao menos a princípio):\n",
        "* Treino: 70% dos dados.\n",
        "* Validação: 15% dos dados .\n",
        "* Teste: 15% dos dados oriinais."
      ],
      "metadata": {
        "id": "X_YG5T-qupIG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Config para a competência 2**"
      ],
      "metadata": {
        "id": "4NhPEvm76Zlh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train2, X_temp2, y_train2, y_temp2 = train_test_split(X_scaled, y_competencia2, test_size=0.3, random_state=42)\n",
        "# X_val2, X_test2, y_val2, y_test2 = train_test_split(X_temp2, y_temp2, test_size=0.5, random_state=42)"
      ],
      "metadata": {
        "id": "kAsPTeas6uFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Config para a competência 3**"
      ],
      "metadata": {
        "id": "xghAqQxV6fdY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train3, X_temp3, y_train3, y_temp3 = train_test_split(X_scaled, y_competencia3, test_size=0.3, random_state=42)\n",
        "# X_val3, X_test3, y_val3, y_test3 = train_test_split(X_temp3, y_temp3, test_size=0.5, random_state=42)"
      ],
      "metadata": {
        "id": "rP9KlfXU6u74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Config para a competência 4**"
      ],
      "metadata": {
        "id": "o8_vBXfZ6gSA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train4, X_temp4, y_train4, y_temp4 = train_test_split(X_scaled, y_competencia4, test_size=0.3, random_state=42)\n",
        "# X_val4, X_test4, y_val4, y_test4 = train_test_split(X_temp4, y_temp4, test_size=0.5, random_state=42)"
      ],
      "metadata": {
        "id": "3RJUAhmM6vlo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Config para a competência 5**"
      ],
      "metadata": {
        "id": "_-EiUoy16iXS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train5, X_temp5, y_train5, y_temp5 = train_test_split(X_scaled, y_competencia5, test_size=0.3, random_state=42)\n",
        "# X_val5, X_test5, y_val5, y_test5 = train_test_split(X_temp5, y_temp5, test_size=0.5, random_state=42)"
      ],
      "metadata": {
        "id": "WkFtYfCZ6wIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Regressão Ordinal usando CORAL"
      ],
      "metadata": {
        "id": "PpR3-rOG5sX1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# df = pd.read_csv('/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame_Final/DataFrame_Final-2.0.csv')"
      ],
      "metadata": {
        "id": "Nk1B2duXuOvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Processamento da coluna de notas\n"
      ],
      "metadata": {
        "id": "xY9KkGjSw3c8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# # 1. Converter as strings de array para listas/arrays NumPy reais\n",
        "# print(\"Convertendo strings de notas (coluna 'grades') para listas de números...\")\n",
        "# df['grades_parsed'] = df['grades'].apply(\n",
        "#     # 1. .strip('[]') remove os colchetes\n",
        "#     # 2. .split() divide por qualquer espaço em branco (um ou vários)\n",
        "#     # 3. int(s) converte cada parte para inteiro\n",
        "#     lambda x: [int(s) for s in x.strip('[]').split()] if isinstance(x, str) else x\n",
        "# )\n",
        "# print(f\"Exemplo da coluna 'grades_parsed':\\n{df['grades_parsed'].head()}\")\n"
      ],
      "metadata": {
        "id": "YcclcoQNAd5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # 2. Extrair cada nota de competência e a nota total\n",
        "# print(\"Extraindo notas para cada competência e a nota total...\")\n",
        "# # Nomes das colunas para as notas de competência\n",
        "# competencia_cols = [f'nota_competencia_{i+1}' for i in range(5)]\n",
        "# # Coluna para a nota total\n",
        "# nota_total_col = 'nota_final_redacao'\n",
        "\n",
        "# # Iterar para criar as colunas de competência e a nota final\n",
        "# for i in range(6): # Iterar de 0 a 5 para pegar os 6 valores do vetor\n",
        "#     col_name = ''\n",
        "#     if i < 5:\n",
        "#         col_name = competencia_cols[i]\n",
        "#     else: # O sexto elemento (índice 5) é a nota total\n",
        "#         col_name = nota_total_col\n",
        "\n",
        "#     df[col_name] = df['grades_parsed'].apply(\n",
        "#         # Verifica se é uma lista e tem o tamanho esperado (6 elementos)\n",
        "#         lambda x: x[i] if isinstance(x, list) and len(x) == 6 else np.nan\n",
        "#     )\n",
        "#     # Garante que as notas sejam inteiras\n",
        "#     df[col_name] = df[col_name].astype(int)\n",
        "\n",
        "# print(\"Exemplo das novas colunas de notas de competência e total:\")\n",
        "# print(df[competencia_cols + [nota_total_col]].head())\n",
        "# print(\"\\n---\")"
      ],
      "metadata": {
        "id": "JVVGs-esBu3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # 4. Definir NUM_CLASSES para cada Competência e Mapeamento Ordinal\n",
        "# NUM_CLASSES_COMPETENCIA = 6 # 0, 40, 80, 120, 160, 200\n",
        "\n",
        "# # Mapeamento para o formato ordinal (0 a 5)\n",
        "# notas_competencia_unicas = np.array([0, 40, 80, 120, 160, 200])\n",
        "# mapeamento_competencia_ordinal = {nota: i for i, nota in enumerate(notas_competencia_unicas)}\n",
        "\n",
        "# # Aplicar o mapeamento para cada coluna de competência\n",
        "# print(f\"Mapeando notas de competência para o formato ordinal (0 a {NUM_CLASSES_COMPETENCIA-1})\")\n",
        "# for col_name in competencia_cols:\n",
        "#     df[f'{col_name}_ordinal'] = df[col_name].map(mapeamento_competencia_ordinal)\n",
        "\n",
        "# print(\"Exemplo das notas ordinais das competências:\")\n",
        "# print(df[[f'{col_name}_ordinal' for col_name in competencia_cols]].head())"
      ],
      "metadata": {
        "id": "W8D4NMmjCxeo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# nome_do_arquivo_csv = 'DataFrame_Final-3.0.csv'\n",
        "# df.to_csv(nome_do_arquivo_csv, index=False)"
      ],
      "metadata": {
        "id": "bVoTrnJXEZkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame_Final/DataFrame_Final-3.0.csv')"
      ],
      "metadata": {
        "id": "jljDWpndFd-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        },
        "id": "gkpQoVqcxoAL",
        "outputId": "a2d7e895-b74a-462c-8de2-f734714a9e42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    id_texto                                         essay_text  \\\n",
              "0  redacao_1  Ultimamente, temos observado, um aumento consi...   \n",
              "1  redacao_2  Infelizmente, no Brasil, na maioria dos lugare...   \n",
              "2  redacao_3  Em todos os lugares do Brasil temos violência,...   \n",
              "3  redacao_4  No Brasil, o número de cidadãos que querem mig...   \n",
              "4  redacao_5  Com apenas 20 anos de idade, o poeta romântico...   \n",
              "\n",
              "                            grades  adjective_ratio  adverbs  content_words  \\\n",
              "0                    [0 0 0 0 0 0]            5.495    5.495         54.396   \n",
              "1                    [0 0 0 0 0 0]            7.107    3.553         58.883   \n",
              "2                    [0 0 0 0 0 0]            2.564    5.128         53.846   \n",
              "3                    [0 0 0 0 0 0]            3.571    5.952         61.111   \n",
              "4  [ 200  200  200  200  200 1000]            7.459  663.000         61.602   \n",
              "\n",
              "      flesch  function_words  sentences_per_paragraph  \\\n",
              "0  1.201.548          45.604                    1.500   \n",
              "1  3.488.631          41.117                    2.000   \n",
              "2  4.271.548          46.154                  133.333   \n",
              "3     43.783          38.889                    3.000   \n",
              "4    327.519          38.398                    4.000   \n",
              "\n",
              "   syllables_per_content_word  ... nota_competencia_2  nota_competencia_3  \\\n",
              "0                     272.727  ...                  0                   0   \n",
              "1                     291.379  ...                  0                   0   \n",
              "2                     279.365  ...                  0                   0   \n",
              "3                     283.117  ...                  0                   0   \n",
              "4                     304.036  ...                200                 200   \n",
              "\n",
              "   nota_competencia_4  nota_competencia_5  nota_final_redacao  \\\n",
              "0                   0                   0                   0   \n",
              "1                   0                   0                   0   \n",
              "2                   0                   0                   0   \n",
              "3                   0                   0                   0   \n",
              "4                 200                 200                1000   \n",
              "\n",
              "   nota_competencia_1_ordinal  nota_competencia_2_ordinal  \\\n",
              "0                           0                           0   \n",
              "1                           0                           0   \n",
              "2                           0                           0   \n",
              "3                           0                           0   \n",
              "4                           5                           5   \n",
              "\n",
              "   nota_competencia_3_ordinal  nota_competencia_4_ordinal  \\\n",
              "0                           0                           0   \n",
              "1                           0                           0   \n",
              "2                           0                           0   \n",
              "3                           0                           0   \n",
              "4                           5                           5   \n",
              "\n",
              "   nota_competencia_5_ordinal  \n",
              "0                           0  \n",
              "1                           0  \n",
              "2                           0  \n",
              "3                           0  \n",
              "4                           5  \n",
              "\n",
              "[5 rows x 216 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5bebaa38-4ba7-4728-ac46-6e66a0e6633a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id_texto</th>\n",
              "      <th>essay_text</th>\n",
              "      <th>grades</th>\n",
              "      <th>adjective_ratio</th>\n",
              "      <th>adverbs</th>\n",
              "      <th>content_words</th>\n",
              "      <th>flesch</th>\n",
              "      <th>function_words</th>\n",
              "      <th>sentences_per_paragraph</th>\n",
              "      <th>syllables_per_content_word</th>\n",
              "      <th>...</th>\n",
              "      <th>nota_competencia_2</th>\n",
              "      <th>nota_competencia_3</th>\n",
              "      <th>nota_competencia_4</th>\n",
              "      <th>nota_competencia_5</th>\n",
              "      <th>nota_final_redacao</th>\n",
              "      <th>nota_competencia_1_ordinal</th>\n",
              "      <th>nota_competencia_2_ordinal</th>\n",
              "      <th>nota_competencia_3_ordinal</th>\n",
              "      <th>nota_competencia_4_ordinal</th>\n",
              "      <th>nota_competencia_5_ordinal</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>redacao_1</td>\n",
              "      <td>Ultimamente, temos observado, um aumento consi...</td>\n",
              "      <td>[0 0 0 0 0 0]</td>\n",
              "      <td>5.495</td>\n",
              "      <td>5.495</td>\n",
              "      <td>54.396</td>\n",
              "      <td>1.201.548</td>\n",
              "      <td>45.604</td>\n",
              "      <td>1.500</td>\n",
              "      <td>272.727</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>redacao_2</td>\n",
              "      <td>Infelizmente, no Brasil, na maioria dos lugare...</td>\n",
              "      <td>[0 0 0 0 0 0]</td>\n",
              "      <td>7.107</td>\n",
              "      <td>3.553</td>\n",
              "      <td>58.883</td>\n",
              "      <td>3.488.631</td>\n",
              "      <td>41.117</td>\n",
              "      <td>2.000</td>\n",
              "      <td>291.379</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>redacao_3</td>\n",
              "      <td>Em todos os lugares do Brasil temos violência,...</td>\n",
              "      <td>[0 0 0 0 0 0]</td>\n",
              "      <td>2.564</td>\n",
              "      <td>5.128</td>\n",
              "      <td>53.846</td>\n",
              "      <td>4.271.548</td>\n",
              "      <td>46.154</td>\n",
              "      <td>133.333</td>\n",
              "      <td>279.365</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>redacao_4</td>\n",
              "      <td>No Brasil, o número de cidadãos que querem mig...</td>\n",
              "      <td>[0 0 0 0 0 0]</td>\n",
              "      <td>3.571</td>\n",
              "      <td>5.952</td>\n",
              "      <td>61.111</td>\n",
              "      <td>43.783</td>\n",
              "      <td>38.889</td>\n",
              "      <td>3.000</td>\n",
              "      <td>283.117</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>redacao_5</td>\n",
              "      <td>Com apenas 20 anos de idade, o poeta romântico...</td>\n",
              "      <td>[ 200  200  200  200  200 1000]</td>\n",
              "      <td>7.459</td>\n",
              "      <td>663.000</td>\n",
              "      <td>61.602</td>\n",
              "      <td>327.519</td>\n",
              "      <td>38.398</td>\n",
              "      <td>4.000</td>\n",
              "      <td>304.036</td>\n",
              "      <td>...</td>\n",
              "      <td>200</td>\n",
              "      <td>200</td>\n",
              "      <td>200</td>\n",
              "      <td>200</td>\n",
              "      <td>1000</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 216 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5bebaa38-4ba7-4728-ac46-6e66a0e6633a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5bebaa38-4ba7-4728-ac46-6e66a0e6633a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5bebaa38-4ba7-4728-ac46-6e66a0e6633a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-977a8c8a-0743-44e6-9026-3239a5493ffe\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-977a8c8a-0743-44e6-9026-3239a5493ffe')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-977a8c8a-0743-44e6-9026-3239a5493ffe button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configurações gerais e hiperparâmetros\n"
      ],
      "metadata": {
        "id": "w_KlHzR3ySjy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 128\n",
        "NUM_EPOCHS = 400\n",
        "LEARNING_RATE = 0.01\n",
        "NUM_WORKERS = 0 # Este parâmemtro pode ajudar na velocidade do treinamento não na qualidade do modelo em termos das métricas\n",
        "# Notas de competência do ENEM: 0, 40, 80, 120, 160, 200\n",
        "NUM_CLASSES_COMPETENCIA = 6"
      ],
      "metadata": {
        "id": "t48T7ik2JJAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MultiLayerPerceptron**: Esta é a rede neural em \"PyTorch puro\". Ela define a arquitetura do Perceptron Multicamadas e incorpora a camada de saída especial do CORAL (CoralLayer)."
      ],
      "metadata": {
        "id": "JQFuqVhnJn_T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiLayerPerceptron(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_units, num_classes):\n",
        "        super().__init__() # Chama o construtor da classe base torch.nn.Module\n",
        "\n",
        "        # Armazena o número de classes, necessário para a função de perda CORAL\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        # Lista para armazenar todas as camadas da MLP\n",
        "        all_layers = []\n",
        "\n",
        "        # Loop para criar as camadas ocultas da MLP\n",
        "        # 'hidden_units' é uma tupla ou lista (ex: (256, 128, 64))\n",
        "        # Cada 'hidden_unit' representa o número de neurônios em uma camada oculta.\n",
        "        for hidden_unit in hidden_units:\n",
        "            # Cria uma camada linear (totalmente conectada)\n",
        "            # 'input_size' é o número de entradas para esta camada (saída da camada anterior ou features iniciais)\n",
        "            # 'hidden_unit' é o número de saídas desta camada\n",
        "            layer = torch.nn.Linear(input_size, hidden_unit)\n",
        "            all_layers.append(layer)\n",
        "\n",
        "            # Adiciona uma função de ativação ReLU após cada camada linear (exceto a última do CORAL)\n",
        "            all_layers.append(torch.nn.ReLU())\n",
        "\n",
        "            # Atualiza o 'input_size' para a próxima camada ser a saída da camada atual\n",
        "            input_size = hidden_unit\n",
        "\n",
        "        # --- Camada de Saída CORAL ---\n",
        "        # Esta é a principal adaptação para Regressão Ordinal com CORAL.\n",
        "        # Ao invés de uma camada linear normal (torch.nn.Linear) que retornaria um vetor de logits para classificação multiclasse,\n",
        "        # usamos a CoralLayer da biblioteca coral_pytorch.\n",
        "        # `size_in`: número de entradas para esta camada (que é a saída da última camada oculta, hidden_units[-1])\n",
        "        # `num_classes`: o número total de categorias de pontuação (ex: 6 para 0 a 200).\n",
        "        output_layer = CoralLayer(size_in=hidden_units[-1], num_classes=num_classes)\n",
        "        all_layers.append(output_layer)\n",
        "\n",
        "        # Combina todas as camadas em um modelo sequencial.\n",
        "        # 'Sequential' executa as camadas em ordem, uma após a outra.\n",
        "        self.model = torch.nn.Sequential(*all_layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Define o fluxo de dados para frente através da rede neural.\n",
        "        `x` é o tensor de entrada (as features).\n",
        "        \"\"\"\n",
        "        # Passa o tensor de entrada através da sequência de camadas definidas\n",
        "        x = self.model(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "7Vw-IVQQJlhi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LightningMLP**: Esta é uma classe do PyTorch Lightning. Ela \"envolve\" a rede neural (MultiLayerPerceptron) e adiciona toda a funcionalidade extra que o Lightning oferece (treinamento automatizado, validação, teste, logs, otimizadores, etc.), tornando o código de treino muito mais limpo e padronizado."
      ],
      "metadata": {
        "id": "jDJYp3rfQkTH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LightningMLP(pl.LightningModule):\n",
        "    def __init__(self, model, learning_rate):\n",
        "        super().__init__() # Chama o construtor da classe base pl.LightningModule\n",
        "\n",
        "        self.learning_rate = learning_rate # Taxa de aprendizado para o otimizador\n",
        "        self.model = model # A instância da rede neural MultiLayerPerceptron\n",
        "\n",
        "        # Salva configurações e hiperparâmetros (como learning_rate) no diretório de log.\n",
        "        # 'ignore=['model']' impede que os parâmetros do modelo sejam salvos duas vezes.\n",
        "        self.save_hyperparameters(ignore=['model'])\n",
        "\n",
        "        # --- Configuração das Métricas de Avaliação ---\n",
        "        # pythorthmetrics são uma forma conveniente de calcular métricas.\n",
        "        # Mean Absolute Error (MAE): Mede a diferença média absoluta entre previsões e rótulos verdadeiros.\n",
        "        self.train_mae = torchmetrics.MeanAbsoluteError()\n",
        "        self.valid_mae = torchmetrics.MeanAbsoluteError()\n",
        "        self.test_mae = torchmetrics.MeanAbsoluteError()\n",
        "\n",
        "        # Quadratic Weighted Kappa (QWK): Métrica CRUCIAL para AES.\n",
        "        # Ela considera a natureza ordinal das notas e penaliza erros maiores mais severamente.\n",
        "        # `num_classes`: número de categorias de nota (ex: 6 para competências).\n",
        "        # `task='multiclass'`: indica que é uma tarefa de classificação multi-classe (embora seja ordinal).\n",
        "        # `weights='quadratic'`: Aplica os pesos quadráticos para penalizar mais erros maiores.\n",
        "        self.train_qwk = torchmetrics.CohenKappa(num_classes=self.model.num_classes, task='multiclass', weights='quadratic')\n",
        "        self.valid_qwk = torchmetrics.CohenKappa(num_classes=self.model.num_classes, task='multiclass', weights='quadratic')\n",
        "        self.test_qwk = torchmetrics.CohenKappa(num_classes=self.model.num_classes, task='multiclass', weights='quadratic')\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Define o fluxo de dados para frente através do modelo PyTorch.\n",
        "        Este método é chamado internamente pelo Lightning para fazer previsões.\n",
        "        \"\"\"\n",
        "        return self.model(x) # Simplesmente passa a entrada para o MultiLayerPerceptron\n",
        "\n",
        "    def _shared_step(self, batch):\n",
        "        \"\"\"\n",
        "        Etapa comum de processamento que é usada para treinamento, validação e teste.\n",
        "        Isso evita a duplicação de código.\n",
        "        \"\"\"\n",
        "        features, true_labels = batch # Desempacota o batch de dados\n",
        "\n",
        "        # --- Adaptação CORAL: Converter labels para o formato binário estendido ---\n",
        "        # 'levels_from_labelbatch' é uma função de coral_pytorch.\n",
        "        # Ela transforma um rótulo de classe inteira (ex: 3) em um vetor binário de \"níveis\" (ex: [1, 1, 1, 0, 0, 0])\n",
        "        # `num_classes`: o número total de classes.\n",
        "        levels = levels_from_labelbatch(\n",
        "            true_labels, num_classes=self.model.num_classes)\n",
        "\n",
        "        # Passa as features para a rede neural para obter os logits (saídas brutas)\n",
        "        logits = self(features) # self(features) é o mesmo que self.forward(features)\n",
        "\n",
        "        # --- Adaptação CORAL: Calcular a função de perda CORAL ---\n",
        "        # 'coral_loss' é uma função de coral_pytorch.\n",
        "        # Ela calcula a perda entre os logits do modelo e os 'levels' binários.\n",
        "        # 'levels.type_as(logits)' garante que os tipos de dados dos tensores sejam compatíveis.\n",
        "        loss = coral_loss(logits, levels.type_as(logits))\n",
        "\n",
        "        # --- Adaptação CORAL: Converter probabilidades previstas em rótulos finais ---\n",
        "        # `torch.sigmoid(logits)`: Transforma os logits brutos em probabilidades entre 0 e 1.\n",
        "        # `proba_to_label`: Uma função de coral_pytorch que converte essas probabilidades\n",
        "        # em rótulos de classe previstos (ex: 0, 1, 2, ..., num_classes-1).\n",
        "        probas = torch.sigmoid(logits)\n",
        "        predicted_labels = proba_to_label(probas)\n",
        "\n",
        "        return loss, true_labels, predicted_labels\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        \"\"\"\n",
        "        Define o que acontece em cada passo de treinamento (para cada batch).\n",
        "        \"\"\"\n",
        "        loss, true_labels, predicted_labels = self._shared_step(batch) # Usa a etapa compartilhada\n",
        "\n",
        "        # Registrar a perda de treinamento\n",
        "        self.log(\"train_loss\", loss, on_epoch=True, on_step=False) # 'on_epoch=True' loga no final da epoch\n",
        "\n",
        "        # Calcular e registrar o MAE de treinamento\n",
        "        self.train_mae(predicted_labels, true_labels)\n",
        "        self.log(\"train_mae\", self.train_mae, on_epoch=True, on_step=False)\n",
        "\n",
        "        # Calcular e registrar o QWK de treinamento\n",
        "        self.train_qwk(predicted_labels, true_labels)\n",
        "        self.log(\"train_qwk\", self.train_qwk, on_epoch=True, on_step=False)\n",
        "\n",
        "        return loss  # A perda é retornada para o otimizador fazer o backpropagation\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        \"\"\"\n",
        "        Define o que acontece em cada passo de validação.\n",
        "        Similar ao training_step, mas não calcula gradientes.\n",
        "        \"\"\"\n",
        "        loss, true_labels, predicted_labels = self._shared_step(batch)\n",
        "\n",
        "        self.log(\"valid_loss\", loss, on_epoch=True, on_step=False)\n",
        "        self.valid_mae(predicted_labels, true_labels)\n",
        "        self.log(\"valid_mae\", self.valid_mae,\n",
        "                 on_epoch=True, on_step=False, prog_bar=True) # prog_bar mostra no progresso da barra\n",
        "        self.valid_qwk(predicted_labels, true_labels)\n",
        "        self.log(\"valid_qwk\", self.valid_qwk,\n",
        "                 on_epoch=True, on_step=False, prog_bar=True)\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        \"\"\"\n",
        "        Define o que acontece em cada passo de teste (avaliação final).\n",
        "        \"\"\"\n",
        "        # Não precisamos da perda para o teste, por isso o '_'\n",
        "        _, true_labels, predicted_labels = self._shared_step(batch)\n",
        "\n",
        "        self.test_mae(predicted_labels, true_labels)\n",
        "        self.log(\"test_mae\", self.test_mae, on_epoch=True, on_step=False)\n",
        "        self.test_qwk(predicted_labels, true_labels)\n",
        "        self.log(\"test_qwk\", self.test_qwk, on_epoch=True, on_step=False)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        \"\"\"\n",
        "        Configura o otimizador da rede neural.\n",
        "        \"\"\"\n",
        "        # Otimizador Adam: otimizador popular e eficiente.\n",
        "        # self.parameters() retorna todos os parâmetros treináveis do modelo.\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
        "        return optimizer"
      ],
      "metadata": {
        "id": "bZUF2Iz_QjKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Classe MyDataset**\n"
      ],
      "metadata": {
        "id": "TWi00SZEKIm0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este código define a classe MyDataset, que prepara os dados para o PyTorch. Ele armazena as features (X) e labels (y) em arrays NumPy. Os métodos **__len__** e **__getitem__** permitem que o PyTorch saiba o tamanho total do seu dataset e como acessar cada amostra individualmente (features e seu label correspondente) usando um índice. Isso é fundamental para organizar os dados para o treinamento do modelo.\n"
      ],
      "metadata": {
        "id": "ANmyRtDfKQXy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(Dataset): # A classe MyDataset herda de torch.utils.data.Dataset\n",
        "    def __init__(self, feature_array, label_array, dtype=np.float32):\n",
        "        \"\"\"\n",
        "        Método construtor da classe. É chamado quando você cria uma nova instância de MyDataset.\n",
        "\n",
        "        Args:\n",
        "            feature_array (np.ndarray): Um array NumPy contendo suas features (X).\n",
        "                                        Por exemplo, X_train_std, X_val_std, X_test_std.\n",
        "            label_array (np.ndarray): Um array NumPy contendo seus labels (y).\n",
        "                                      Por exemplo, y_train, y_val, y_test.\n",
        "            dtype (np.float32, optional): O tipo de dado em que as features serão convertidas.\n",
        "                                          np.float32 é um tipo comum para entradas de redes neurais,\n",
        "                                          pois economiza memória e é compatível com GPUs.\n",
        "        \"\"\"\n",
        "        # Converte o array de features para o tipo de dado especificado.\n",
        "        # Isso é importante para garantir que as features estejam no formato numérico\n",
        "        # esperado pelo PyTorch (geralmente float32 ou float64).\n",
        "        self.features = feature_array.astype(dtype)\n",
        "\n",
        "        # Armazena o array de labels.\n",
        "        # Comentário: \"Labels devem ser long para PyTorch\" -- isso é uma dica importante.\n",
        "        # Para problemas de classificação (e regressão ordinal como no presente trabalho, que usa classificadores binários internamente),\n",
        "        # o PyTorch geralmente espera que os rótulos de classe sejam tensores do tipo Long (torch.long).\n",
        "        # Se label_array for um NumPy array de inteiros, PyTorch lida com isso.\n",
        "        self.labels = label_array\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"\n",
        "        Método mágico que permite acessar amostras do dataset usando índices, como em uma lista.\n",
        "        Ex: dataset[0] chamaria __getitem__(0).\n",
        "\n",
        "        Args:\n",
        "            index (int): O índice da amostra que você deseja retornar.\n",
        "\n",
        "        Returns:\n",
        "            tuple: Uma tupla contendo (inputs, label) para a amostra no índice fornecido.\n",
        "                   - inputs: As features (dados de entrada) da amostra.\n",
        "                   - label: O rótulo (valor alvo) correspondente à amostra.\n",
        "        \"\"\"\n",
        "        inputs = self.features[index] # Pega a linha de features no 'index'\n",
        "        label = self.labels[index]   # Pega o label correspondente no 'index'\n",
        "        return inputs, label\n",
        "\n",
        "    def __len__(self, ):\n",
        "        \"\"\"\n",
        "        Método mágico que retorna o número total de amostras no dataset.\n",
        "        Permite usar len(dataset).\n",
        "\n",
        "        Returns:\n",
        "            int: O número de linhas (amostras) no array de features.\n",
        "        \"\"\"\n",
        "        return self.features.shape[0] # Retorna o número de linhas (primeira dimensão) do array de features"
      ],
      "metadata": {
        "id": "1hIBxbqLKGvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Classe CompetenceDataModule (Substitui DataModule)**\n"
      ],
      "metadata": {
        "id": "zCznS31CKXXC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta é a parte central da adaptação para múltiplos modelos. O DataModule agora será específico para cada competência, recebendo os X e y já divididos e escalados."
      ],
      "metadata": {
        "id": "QyosnL3NKiBK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CompetenceDataModule(pl.LightningDataModule): # A classe herda de pytorch_lightning.LightningDataModule\n",
        "    def __init__(self, X_train, y_train, X_val, y_val, X_test, y_test, batch_size, num_workers):\n",
        "        \"\"\"\n",
        "        Método construtor da classe. É chamado quando é criado uma nova instância de CompetenceDataModule.\n",
        "\n",
        "        Args:\n",
        "            X_train (np.ndarray): Matriz de features para o conjunto de treinamento.\n",
        "            y_train (np.ndarray): Vetor de labels (notas) para o conjunto de treinamento.\n",
        "            X_val (np.ndarray): Matriz de features para o conjunto de validação.\n",
        "            y_val (np.ndarray): Vetor de labels para o conjunto de validação.\n",
        "            X_test (np.ndarray): Matriz de features para o conjunto de teste.\n",
        "            y_test (np.ndarray): Vetor de labels para o conjunto de teste.\n",
        "            batch_size (int): O número de amostras por lote (batch) que o modelo processará de cada vez.\n",
        "            num_workers (int): O número de subprocessos a serem usados para carregamento de dados.\n",
        "                                0 significa que o carregamento será feito no processo principal.\n",
        "                                Valores > 0 podem acelerar o carregamento, mas podem causar problemas em ambientes como o Windows/WSL.\n",
        "        \"\"\"\n",
        "        super().__init__() # Chama o construtor da classe base pl.LightningDataModule\n",
        "\n",
        "        # Armazena os arrays NumPy dos conjuntos de dados\n",
        "        # Esses dados já devem estar pré-processados e escalados (ex: X_train_std)\n",
        "        self.X_train = X_train\n",
        "        self.y_train = y_train\n",
        "        self.X_val = X_val\n",
        "        self.y_val = y_val\n",
        "        self.X_test = X_test\n",
        "        self.y_test = y_test\n",
        "\n",
        "        # Armazena configurações de DataLoader\n",
        "        self.batch_size = batch_size\n",
        "        self.num_workers = num_workers\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        \"\"\"\n",
        "        Este método é chamado pelo PyTorch Lightning para preparar os dados.\n",
        "        Ele é chamado em cada \"nó\" (processo/GPU) em um ambiente distribuído.\n",
        "        Normalmente, é aqui que fazemos a divisão de dados, escalamento, etc.\n",
        "        Em nosso caso caso, ja fizemos isso no fluxo principal do script, então aqui ele\n",
        "        apenas cria as instâncias de MyDataset.\n",
        "\n",
        "        Args:\n",
        "            stage (str, optional): Indica a fase atual ('fit', 'validate', 'test', 'predict').\n",
        "                                   Permite lógica condicional se necessário. Ignorado aqui.\n",
        "        \"\"\"\n",
        "        # Cria os objetos MyDataset para cada conjunto (treino, validação, teste).\n",
        "        # MyDataset encapsula os arrays NumPy X e y em um formato que PyTorch pode usar.\n",
        "        self.train = MyDataset(self.X_train, self.y_train)\n",
        "        self.valid = MyDataset(self.X_val, self.y_val)\n",
        "        self.test = MyDataset(self.X_test, self.y_test)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        \"\"\"\n",
        "        Retorna o DataLoader para o conjunto de treinamento.\n",
        "        \"\"\"\n",
        "        return DataLoader(self.train,\n",
        "                          batch_size=self.batch_size, # Tamanho dos lotes para o treino\n",
        "                          num_workers=self.num_workers, # Número de subprocessos para carregar dados\n",
        "                          shuffle=True, # Embaralha os dados a cada epoch para evitar que o modelo \"decore\" a ordem\n",
        "                          drop_last=True) # Se o último batch não tiver o tamanho completo, ele é descartado.\n",
        "                                          # Útil para modelos que esperam batches de tamanho fixo, ou GPUs.\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        \"\"\"\n",
        "        Retorna o DataLoader para o conjunto de validação.\n",
        "        \"\"\"\n",
        "        return DataLoader(self.valid,\n",
        "                          batch_size=self.batch_size,\n",
        "                          num_workers=self.num_workers)\n",
        "                          # shuffle=False é o padrão para validação/teste, pois a ordem não importa.\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        \"\"\"\n",
        "        Retorna o DataLoader para o conjunto de teste.\n",
        "        \"\"\"\n",
        "        return DataLoader(self.test,\n",
        "                          batch_size=self.batch_size,\n",
        "                          num_workers=self.num_workers)\n",
        "                          # shuffle=False é o padrão para validação/teste."
      ],
      "metadata": {
        "id": "PU7iHhkUKaYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- FLUXO PRINCIPAL: Carregar, Pré-processar e Treinar Múltiplos Modelos ---\n",
        "\n",
        "#  Preparação da Matriz de Features (X)\n",
        "# Converta a coluna 'bert_embedding' de string para array NumPy\n",
        "print(\"\\nPreparando a matriz de features (X)...\", flush=True)\n",
        "\n",
        "df['bert_embedding'] = df['bert_embedding'].apply(\n",
        "    lambda x: (\n",
        "        np.array(ast.literal_eval(\n",
        "            # Passos mais robustos:\n",
        "            # 1. str(x).strip('[]'): Converte para string, remove colchetes e espaços extras.\n",
        "            # 2. re.sub(r'\\s+', ',', ...): Substitui QUALQUER sequência de espaços (um ou mais) por UMA VÍRGULA.\n",
        "            # 3. .replace(',,', ',') (Opcional): Lida com casos residuais de vírgulas duplas se o regex não for perfeito.\n",
        "            # 4. .strip(',') (Opcional): Remove vírgulas extras no início/fim.\n",
        "            re.sub(r'\\s+', ',', str(x).strip('[]')).strip(',')\n",
        "        ))\n",
        "        if pd.notna(x) and isinstance(x, str) and x.strip() else np.nan\n",
        "    )\n",
        ")\n",
        "\n",
        "# Depois de garantir que a coluna contém NumPy arrays ou NaNs, você pode empilhar:\n",
        "bert_embeddings_matrix = np.stack(df['bert_embedding'].values)\n",
        "\n",
        "# Limpar e converter colunas de métricas hand-crafted\n",
        "primeira_coluna_metrica = 'adjective_ratio' # Verifique o nome da primeira métrica real\n",
        "ultima_coluna_metrica = 'ratio_function_to_content_words' # Verifique o nome da última métrica real\n",
        "colunas_handcrafted_nomes = df.loc[:, primeira_coluna_metrica:ultima_coluna_metrica].columns.tolist()\n",
        "\n",
        "\n",
        "for col in colunas_handcrafted_nomes:\n",
        "    if col in df.columns and df[col].dtype == 'object':\n",
        "        df[col] = df[col].astype(str).str.replace('.', '', regex=False).str.replace(',', '.', regex=False)\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "# Combinar as features\n",
        "handcrafted_features_matrix = df[colunas_handcrafted_nomes].values\n",
        "X_combined = np.hstack((bert_embeddings_matrix, handcrafted_features_matrix))\n",
        "print(\"Matriz de features X_combined pronta.\", flush=True)"
      ],
      "metadata": {
        "id": "XNlCSucwKxQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_combined"
      ],
      "metadata": {
        "id": "c07_ly3GcOsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4. Loop para Treinar um Modelo para Cada Competência ---\n",
        "resultados_por_competencia = {}\n",
        "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\" #se GPU disponível usamos para o treinamento\n",
        "\n",
        "for comp_idx in range(1, 6): # Para competência 1 a 5\n",
        "    print(f\"\\n--- Treinando Modelo para Competência {comp_idx} ---\", flush=True)\n",
        "\n",
        "    # Define o vetor alvo (y) para a competência atual\n",
        "    y_competencia = df[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    # Divisão do Dataset (X_combined e y_competencia)\n",
        "    # stratify=y_competencia é CRUCIAL para dados desbalanceados\n",
        "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "        X_combined, y_competencia, test_size=0.3, random_state=42, stratify=y_competencia\n",
        "    )\n",
        "    X_val, X_test, y_val, y_test = train_test_split(\n",
        "        X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
        "    )\n",
        "    print(f\"Divisão de dados para Competência {comp_idx}: Treino={X_train.shape}, Validação={X_val.shape}, Teste={X_test.shape}\", flush=True)\n",
        "\n",
        "    # Escalamento de Features (feito por um novo scaler para cada modelo/divisão)\n",
        "    # Fit no treino, transform nos outros\n",
        "    scaler_comp = StandardScaler()\n",
        "    X_train_std = scaler_comp.fit_transform(X_train)\n",
        "    X_val_std = scaler_comp.transform(X_val)\n",
        "    X_test_std = scaler_comp.transform(X_test)\n",
        "    print(f\"Features escaladas para Competência {comp_idx}.\", flush=True)\n",
        "\n",
        "    # Opcional: Aplicar SMOTE APENAS no conjunto de treino se o desbalanceamento for severo\n",
        "    # from imblearn.over_sampling import SMOTE\n",
        "    # print(f\"Aplicando SMOTE para Competência {comp_idx}...\", flush=True)\n",
        "    # smote = SMOTE(random_state=42)\n",
        "    # X_train_resampled, y_train_resampled = smote.fit_resample(X_train_std, y_train)\n",
        "    # X_train_std, y_train = X_train_resampled, y_train_resampled\n",
        "    # print(f\"SMOTE aplicado. Novo shape de treino: {X_train_std.shape}\", flush=True)\n",
        "\n",
        "\n",
        "    # Criar DataModule para a competência atual\n",
        "    data_module_competencia = CompetenceDataModule(X_train_std, y_train, X_val_std, y_val, X_test_std, y_test, BATCH_SIZE, NUM_WORKERS)\n",
        "    data_module_competencia.setup()\n",
        "\n",
        "    # Inicializar e treinar o modelo PyTorch Lightning\n",
        "    input_dim = X_combined.shape[1] # A dimensão de entrada é a mesma para todos os modelos\n",
        "\n",
        "    pytorch_model_competencia = MultiLayerPerceptron(\n",
        "        input_size=input_dim,\n",
        "        hidden_units=(256, 128, 64), # Ajuste a arquitetura do MLP conforme testes\n",
        "        num_classes=NUM_CLASSES_COMPETENCIA # Passa o NUM_CLASSES_COMPETENCIA = 6\n",
        "    )\n",
        "    lightning_model_competencia = LightningMLP(\n",
        "        model=pytorch_model_competencia,\n",
        "        learning_rate=LEARNING_RATE\n",
        "    )\n",
        "\n",
        "    # Callbacks e Logger\n",
        "    # Salvar modelos e logs em pastas separadas para cada competência\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        save_top_k=1, mode=\"min\", monitor=\"valid_mae\",\n",
        "        dirpath=f\"logs_comp_{comp_idx}/\", filename=f\"best_model_comp_{comp_idx}\"\n",
        "    )\n",
        "    logger_competencia = CSVLogger(save_dir=\"logs/\", name=f\"mlp-coral-comp-{comp_idx}\")\n",
        "\n",
        "\n",
        "    early_stop_callback = EarlyStopping(\n",
        "    monitor=\"valid_qwk\",  # Monitorar o QWK na validação\n",
        "    min_delta=0.00,        # Mínima mudança para ser considerada uma melhoria, neste caso, consideramos qualquer melhora\n",
        "    patience=50,           # Parar se o QWK não melhorar por 10 épocas\n",
        "    verbose=True,\n",
        "    mode=\"max\"             # O \"valid_qwk\" deve ser maximizado\n",
        "    )\n",
        "\n",
        "    # Combine callbacks into a single list\n",
        "    callbacks_list = [\n",
        "        model_checkpoint_callback,\n",
        "        early_stop_callback\n",
        "    ]\n",
        "\n",
        "    # Trainer\n",
        "    trainer_competencia = pl.Trainer(\n",
        "        max_epochs=NUM_EPOCHS,\n",
        "        callbacks=callbacks_list,\n",
        "        accelerator=device_type,\n",
        "        devices=1,\n",
        "        logger=logger_competencia,\n",
        "        deterministic=True,\n",
        "        log_every_n_steps=10\n",
        "    )\n",
        "\n",
        "    # Treinar\n",
        "    start_time = time.time()\n",
        "    print(f\"Treinando modelo para Competência {comp_idx}...\", flush=True)\n",
        "    trainer_competencia.fit(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    runtime = (time.time() - start_time)/60\n",
        "    print(f\"Treinamento para Competência {comp_idx} levou {runtime:.2f} min.\", flush=True)\n",
        "\n",
        "    # Avaliar no conjunto de teste (avaliação final)\n",
        "    print(f\"Avaliando modelo para Competência {comp_idx} no conjunto de teste...\", flush=True)\n",
        "    test_results = trainer_competencia.test(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    resultados_por_competencia[f'competencia_{comp_idx}'] = test_results[0] # Armazenar os resultados do teste\n",
        "\n",
        "    print(f\"--- Modelo para Competência {comp_idx} concluído ---\", flush=True)\n",
        "\n",
        "print(\"\\n--- Todos os modelos de competência foram treinados e avaliados ---\", flush=True)\n",
        "print(\"Resultados de Teste por Competência (MAE e QWK):\", flush=True)\n",
        "for comp, results in resultados_por_competencia.items():\n",
        "    print(f\"{comp}: Test MAE = {results['test_mae']:.4f}, Test QWK = {results['test_qwk']:.4f}\", flush=True)"
      ],
      "metadata": {
        "id": "2nsX0KXqd9IR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "al-3J8En5enw",
        "dZYW-Jsu3RtE",
        "uKgHVsp2tEOx"
      ],
      "gpuType": "T4",
      "mount_file_id": "1i5-vPwnxR9NwmAXD3RX11bpoyHRmI6QP",
      "authorship_tag": "ABX9TyM0p4yuUrnzbZoaIO2OsCJ7",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}