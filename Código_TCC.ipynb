{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GGMmattos/TCC-Informatica/blob/main/C%C3%B3digo_TCC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neyIHZ4sV7c0"
      },
      "source": [
        "# Libs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_A6RY2jjV6-F"
      },
      "outputs": [],
      "source": [
        "\n",
        "#libs\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import nltk\n",
        "import re\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "import numpy as np\n",
        "import torch\n",
        "from datasets import Dataset\n",
        "import re\n",
        "import time\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from google.colab import files\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "\n",
        "!pip install pytorch-lightning -q\n",
        "!pip install coral_pytorch -q\n",
        "!pip install transformers==4.30.0 -q # Install a specific version of transformers\n",
        "\n",
        "import torch\n",
        "import os\n",
        "import json # Para lidar com os embeddings salvos como string JSON\n",
        "import ast # Para avaliar strings de lista de notas\n",
        "import shlex # Para o NILC Metrix (se ainda precisar rodar o script no mesmo arquivo)\n",
        "\n",
        "# Para PyTorch Lightning\n",
        "import pytorch_lightning as pl\n",
        "import torchmetrics\n",
        "from coral_pytorch.layers import CoralLayer\n",
        "from coral_pytorch.losses import coral_loss\n",
        "from coral_pytorch.dataset import levels_from_labelbatch, proba_to_label\n",
        "\n",
        "# Para Sklearn (pré-processamento e divisão de dados)\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from pytorch_lightning.loggers import CSVLogger"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Função de calculo acurácia do ENEM"
      ],
      "metadata": {
        "id": "v8cWBuX7avcA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchmetrics import Metric\n",
        "from typing import Any\n",
        "\n",
        "class ENEMAccuracy(Metric):\n",
        "    def __init__(self, dist_sync_on_step=False):\n",
        "        super().__init__(dist_sync_on_step=dist_sync_on_step)\n",
        "\n",
        "        # O limite de 80 pontos na escala original do ENEM\n",
        "        # corresponde a um limite de 2 na sua escala ordinal (0 a 5).\n",
        "        # A diferença absoluta máxima para ser 'não-divergente' é 2.\n",
        "        self.divergence_threshold = 2\n",
        "        self.add_state(\"non_divergent_count\", default=torch.tensor(0), dist_reduce_fx=\"sum\")\n",
        "        self.add_state(\"total_count\", default=torch.tensor(0), dist_reduce_fx=\"sum\")\n",
        "\n",
        "    def update(self, preds: torch.Tensor, target: torch.Tensor):\n",
        "        # A `preds` é o tensor de rótulos previstos pelo modelo.\n",
        "        # A `target` é o tensor de rótulos verdadeiros.\n",
        "\n",
        "        # Calcula a diferença absoluta entre a previsão e o valor real\n",
        "        diff = torch.abs(preds - target)\n",
        "\n",
        "        # Conta as previsões que estão dentro do limite de divergência\n",
        "        non_divergent_batch = torch.sum(diff <= self.divergence_threshold)\n",
        "\n",
        "        self.non_divergent_count += non_divergent_batch\n",
        "        self.total_count += target.numel()\n",
        "\n",
        "    def compute(self):\n",
        "        # Calcula a precisão final como a porcentagem de previsões não-divergentes\n",
        "        return self.non_divergent_count.float() / self.total_count.float()"
      ],
      "metadata": {
        "id": "dNKkgWOtapP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "al-3J8En5enw"
      },
      "source": [
        "# Importação do dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onSyJFQc9ULx"
      },
      "source": [
        "**2018-Fonseca et al**\n",
        "\n",
        "* Automatically Grading Brazilian Student Essays - NILC Metrix  - [link NILC](http://www.nilc.icmc.usp.br/nilc/projects/unitex-pb/web/dicionarios.html) -  https://github.com/nilc-nlp/nilcmetrix\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2J8-L1wghIM"
      },
      "source": [
        "Importação do dataset [Link](https://huggingface.co/datasets/kamel-usp/aes_enem_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jQ4LaR5rAIQO"
      },
      "outputs": [],
      "source": [
        "# # Login using e.g. `huggingface-cli login` to access this dataset\n",
        "# splits = {'train': 'PROPOR2024/train-00000-of-00001.parquet', 'validation': 'PROPOR2024/validation-00000-of-00001.parquet', 'test': 'PROPOR2024/test-00000-of-00001.parquet'}\n",
        "# df_train = pd.read_parquet(\"hf://datasets/kamel-usp/aes_enem_dataset/\" + splits[\"train\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7TTL9FesoSgh"
      },
      "outputs": [],
      "source": [
        "#Função de ordenação\n",
        "# def natural_sort_key(s):\n",
        "#     \"\"\"\n",
        "#     Função para ordenação natural de strings que contêm números.\n",
        "#     Exemplo: ['ID10', 'ID2'] será ordenado como ['ID2', 'ID10'] em vez de ['ID10', 'ID2']\n",
        "#     \"\"\"\n",
        "#     return [int(text) if text.isdigit() else text.lower() for text in re.split(r'(\\d+)', s)]\n",
        "\n",
        "# # Ordenar o DataFrame usando a chave de ordenação natural\n",
        "# df_test = df_test.iloc[pd.Index(df_test['id_texto']).map(lambda x: natural_sort_key(x)).argsort()]\n",
        "# df_test.reset_index(drop=True, inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vLQ0qqkg6Dcl"
      },
      "outputs": [],
      "source": [
        "# df_train = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics/df_train.csv\", encoding='latin-1')\n",
        "# df_validation = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics/df_validation.csv\", encoding='latin-1')\n",
        "# df_test = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics/df_test.csv\", encoding='latin-1')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "gCr12oJDn9X0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_validation = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/textos + NILC/df_val.csv\", encoding='latin-1',     decimal=',')\n"
      ],
      "metadata": {
        "id": "ZQXxkvtckEZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_validation['honore']"
      ],
      "metadata": {
        "id": "3M55Tjiakdug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vR_HwRrx8po3"
      },
      "outputs": [],
      "source": [
        "# df_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oOqvHcLQ8w9f"
      },
      "outputs": [],
      "source": [
        "# df_validation.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evewyf7P8yEG"
      },
      "outputs": [],
      "source": [
        "# df_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u6HO7aT3AGdZ"
      },
      "outputs": [],
      "source": [
        "# # Concatenando verticalmente\n",
        "# df = pd.concat([df_train, df_validation, df_test], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ClMrxZY0A6Em"
      },
      "outputs": [],
      "source": [
        "# df.drop(columns='id_texto', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6-Y6SsnAOse"
      },
      "outputs": [],
      "source": [
        "# df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PKD_TrGhSn0O"
      },
      "outputs": [],
      "source": [
        "# df.to_csv('df.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZYW-Jsu3RtE"
      },
      "source": [
        "# Gerando embedding\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Importa as classes necessárias da biblioteca 'transformers'\n",
        "# from transformers import AutoTokenizer, AutoModel\n",
        "# import torch\n",
        "\n",
        "# # --- 1. Definição do Tokenizer e do Modelo ---\n",
        "# # O AutoTokenizer e o AutoModel se encarregam de carregar as configurações\n",
        "# # corretas para o modelo BERTimbau.\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"neuralmind/bert-base-portuguese-cased\")\n",
        "# model = AutoModel.from_pretrained(\"neuralmind/bert-base-portuguese-cased\")\n",
        "\n",
        "# # --- 2. Movendo para a GPU (prática recomendada) ---\n",
        "# if torch.cuda.is_available():\n",
        "#     device = torch.device(\"cuda\")\n",
        "#     model.to(device)\n",
        "#     print(\"Modelo BERTimbau carregado e movido para a GPU.\")\n",
        "# else:\n",
        "#     device = torch.device(\"cpu\")\n",
        "#     print(\"Modelo BERTimbau carregado e usando a CPU.\")"
      ],
      "metadata": {
        "id": "F3d8Y2pEdTmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "-1Jj5cwjiNkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AMWaG8XZg4kh"
      },
      "outputs": [],
      "source": [
        "# Importação dos dataset com text + metrix\n",
        "df_test = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/textos + NILC/df_test.csv\", encoding='latin-1', decimal=',')\n",
        "df_train = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/textos + NILC/df_train.csv\", encoding='latin-1', decimal=',')\n",
        "df_val = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/textos + NILC/df_val.csv\", encoding='latin-1', decimal=',')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.shape"
      ],
      "metadata": {
        "id": "SxrB7tbjcjUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.shape"
      ],
      "metadata": {
        "id": "c9xfEWIFcnbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_val.shape"
      ],
      "metadata": {
        "id": "X0EZ2Z5Bcn0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mt4vD8Xm-b4D"
      },
      "source": [
        "BERTimbau (como a maioria dos BERTs base) tem um limite de 512 tokens para a entrada. Redações do ENEM geralmente são mais longas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygsu-_B18fOK"
      },
      "source": [
        "**Código para obter embedding (segmentação)**\n",
        "\n",
        "Dividir a redação em pedaços de 512 tokens, gerar um embedding para cada pedaço e depois combiná-los"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HVppllive4a3"
      },
      "outputs": [],
      "source": [
        "def get_bert_embedding_segmented(text, tokenizer, model, device, max_length=512, stride=256):\n",
        "    \"\"\"\n",
        "    Gera um embedding BERT para um texto longo, utilizando segmentação e agregação.\n",
        "\n",
        "    Args:\n",
        "        text (str): O texto da redação.\n",
        "        tokenizer: O tokenizer do modelo BERT.\n",
        "        model: O modelo BERT (ex: BERTimbau).\n",
        "        device (torch.device): 'cuda' ou 'cpu'.\n",
        "        max_length (int): O tamanho máximo de cada segmento para o BERT (default: 512).\n",
        "        stride (int): O tamanho da sobreposição entre os segmentos (default: 256).\n",
        "                      Um stride menor significa mais sobreposição e possivelmente\n",
        "                      maior captura de contexto, mas mais processamento.\n",
        "\n",
        "    Returns:\n",
        "        np.array: O embedding combinado (média) de todos os segmentos, ou NaNs se o texto for nulo.\n",
        "    \"\"\"\n",
        "    if pd.isna(text) or not isinstance(text, str): # Lidar com possíveis valores NaN ou não-string\n",
        "        return np.full((model.config.hidden_size,), np.nan) # Retorna um array de NaNs\n",
        "\n",
        "    # Tokenizar o texto completo com o retorno de IDs (para controlar a segmentação)\n",
        "    # add_special_tokens=False para não adicionar [CLS]/[SEP] no começo e fim de cada segmento\n",
        "    # pois queremos controlar isso.\n",
        "    token_ids = tokenizer.encode(text, add_special_tokens=False)\n",
        "\n",
        "    # Lista para armazenar os embeddings de cada segmento\n",
        "    segment_embeddings = []\n",
        "\n",
        "    # Iterar sobre os tokens para criar segmentos\n",
        "    # max_length - 2 para dar espaço para [CLS] e [SEP] que serão adicionados pelo tokenizer em cada segmento\n",
        "    effective_max_length = max_length - 2\n",
        "\n",
        "    # Se o texto for muito curto, trata como um único segmento (mesmo que menor que max_length)\n",
        "    if len(token_ids) <= effective_max_length:\n",
        "        segments = [token_ids]\n",
        "    else:\n",
        "        segments = []\n",
        "        for i in range(0, len(token_ids), effective_max_length - stride):\n",
        "            segment = token_ids[i : i + effective_max_length]\n",
        "            segments.append(segment)\n",
        "            # Se o último segmento for menor que o stride (não suficiente para sobreposição),\n",
        "            # ou se já chegamos ao final, paramos.\n",
        "            if i + effective_max_length >= len(token_ids):\n",
        "                break\n",
        "\n",
        "\n",
        "    # Processar cada segmento\n",
        "    for segment in segments:\n",
        "        # Adicionar os tokens especiais para cada segmento individualmente\n",
        "        # return_tensors='pt' para PyTorch\n",
        "        # truncation=True é redundante aqui se já controlamos o tamanho, mas é bom manter\n",
        "        # padding='max_length' garante que todos os segmentos tenham o mesmo tamanho de input\n",
        "        inputs = tokenizer.prepare_for_model(\n",
        "            segment,\n",
        "            add_special_tokens=True,\n",
        "            return_tensors='pt',\n",
        "            max_length=max_length,\n",
        "            padding='max_length',\n",
        "            truncation=True # Em caso de erro na lógica de segmentação, isso garante\n",
        "        )\n",
        "\n",
        "        # Add batch dimension to each tensor in the inputs dictionary\n",
        "        inputs = {k: v.unsqueeze(0).to(device) for k, v in inputs.items()}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        # Retorna o embedding do token [CLS] do segmento\n",
        "        # outputs.last_hidden_state will now have shape (batch_size, sequence_length, hidden_size)\n",
        "        # We still want the CLS token for the single item in the batch, which is index 0\n",
        "        segment_embedding = outputs.last_hidden_state[0, 0, :].cpu().numpy()\n",
        "        segment_embeddings.append(segment_embedding)\n",
        "\n",
        "    if not segment_embeddings: # Se por algum motivo nenhum embedding foi gerado (ex: texto vazio após pré-processamento)\n",
        "        return np.full((model.config.hidden_size,), np.nan)\n",
        "\n",
        "    # Combinar os embeddings dos segmentos pela média\n",
        "    combined_embedding = np.mean(segment_embeddings, axis=0)\n",
        "\n",
        "    return combined_embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60QhvvivZP8Q"
      },
      "outputs": [],
      "source": [
        "# 1. Carregar o Tokenizer e o Modelo BERTimbau\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"neuralmind/bert-base-portuguese-cased\")\n",
        "model = AutoModel.from_pretrained(\"neuralmind/bert-base-portuguese-cased\")\n",
        "\n",
        "# Mover o modelo para a GPU, se disponível\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "model.eval() # Coloca o modelo em modo de avaliação"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7UL04b8FeYuX"
      },
      "outputs": [],
      "source": [
        "df_val['bert_embedding'] = df_val['essay_text'].apply(\n",
        "    lambda text: get_bert_embedding_segmented(text, tokenizer, model, device, max_length=512, stride=256)\n",
        ")\n",
        "\n",
        "print(\"\\nDataFrame com embeddings BERTimbau segmentados:\")\n",
        "print(df_val.head())\n",
        "\n",
        "#Para verificar o formato do primeiro embedding:\n",
        "print(f\"\\nShape do primeiro embedding segmentado: {df_val['bert_embedding'].iloc[0].shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QgcKqkQDgnXR"
      },
      "outputs": [],
      "source": [
        "nome_do_arquivo_csv = 'df_val.csv'\n",
        "df_val.to_csv(nome_do_arquivo_csv, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpR3-rOG5sX1"
      },
      "source": [
        "# Ajuste para regressão ordinal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nk1B2duXuOvp"
      },
      "outputs": [],
      "source": [
        "# Importação dos dataset com text + metrix + embeddings\n",
        "df_train = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/NILC + Embedding/df_train.csv\")\n",
        "df_test = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/NILC + Embedding/df_test.csv\")\n",
        "df_val = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/NILC + Embedding/df_val.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xY9KkGjSw3c8"
      },
      "source": [
        "Processamento da coluna de notas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YcclcoQNAd5X"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 1. Converter as strings de array para listas/arrays NumPy reais\n",
        "print(\"Convertendo strings de notas (coluna 'grades') para listas de números...\")\n",
        "df_val['grades_parsed'] = df_val['grades'].apply(\n",
        "    # 1. .strip('[]') remove os colchetes\n",
        "    # 2. .split() divide por qualquer espaço em branco (um ou vários)\n",
        "    # 3. int(s) converte cada parte para inteiro\n",
        "    lambda x: [int(s) for s in x.strip('[]').split()] if isinstance(x, str) else x\n",
        ")\n",
        "print(f\"Exemplo da coluna 'grades_parsed':\\n{df_val['grades_parsed'].head()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVVGs-esBu3o"
      },
      "outputs": [],
      "source": [
        "# 2. Extrair cada nota de competência e a nota total\n",
        "print(\"Extraindo notas para cada competência e a nota total...\")\n",
        "# Nomes das colunas para as notas de competência\n",
        "competencia_cols = [f'nota_competencia_{i+1}' for i in range(5)]\n",
        "# Coluna para a nota total\n",
        "nota_total_col = 'nota_final_redacao'\n",
        "\n",
        "# Iterar para criar as colunas de competência e a nota final\n",
        "for i in range(6): # Iterar de 0 a 5 para pegar os 6 valores do vetor\n",
        "    col_name = ''\n",
        "    if i < 5:\n",
        "        col_name = competencia_cols[i]\n",
        "    else: # O sexto elemento (índice 5) é a nota total\n",
        "        col_name = nota_total_col\n",
        "\n",
        "    df_val[col_name] = df_val['grades_parsed'].apply(\n",
        "        # Verifica se é uma lista e tem o tamanho esperado (6 elementos)\n",
        "        lambda x: x[i] if isinstance(x, list) and len(x) == 6 else np.nan\n",
        "    )\n",
        "    # Garante que as notas sejam inteiras\n",
        "    df_val[col_name] = df_val[col_name].astype(int)\n",
        "\n",
        "print(\"Exemplo das novas colunas de notas de competência e total:\")\n",
        "print(df_val[competencia_cols + [nota_total_col]].head())\n",
        "print(\"\\n---\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ZhmKuMfhhVB"
      },
      "outputs": [],
      "source": [
        "df_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8D4NMmjCxeo"
      },
      "outputs": [],
      "source": [
        "# 4. Definir NUM_CLASSES para cada Competência e Mapeamento Ordinal\n",
        "NUM_CLASSES_COMPETENCIA = 6 # 0, 40, 80, 120, 160, 200\n",
        "\n",
        "# Mapeamento para o formato ordinal (0 a 5)\n",
        "notas_competencia_unicas = np.array([0, 40, 80, 120, 160, 200])\n",
        "mapeamento_competencia_ordinal = {nota: i for i, nota in enumerate(notas_competencia_unicas)}\n",
        "\n",
        "# Aplicar o mapeamento para cada coluna de competência\n",
        "print(f\"Mapeando notas de competência para o formato ordinal (0 a {NUM_CLASSES_COMPETENCIA-1})\")\n",
        "for col_name in competencia_cols:\n",
        "    df_val[f'{col_name}_ordinal'] = df_val[col_name].map(mapeamento_competencia_ordinal)\n",
        "\n",
        "print(\"Exemplo das notas ordinais das competências:\")\n",
        "print(df_val[[f'{col_name}_ordinal' for col_name in competencia_cols]].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bVoTrnJXEZkg"
      },
      "outputs": [],
      "source": [
        "nome_do_arquivo_csv = 'df_val.csv'\n",
        "df_val.to_csv(nome_do_arquivo_csv, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Luqc3udpwAX5"
      },
      "source": [
        "# Configurações do modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jljDWpndFd-Z"
      },
      "outputs": [],
      "source": [
        "# df = pd.read_csv('/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Dataframe final/DataFrame_Final-2.0.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_KlHzR3ySjy"
      },
      "source": [
        "Configurações gerais e hiperparâmetros\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t48T7ik2JJAA"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 128\n",
        "NUM_EPOCHS = 400\n",
        "LEARNING_RATE = 0.01\n",
        "NUM_WORKERS = 0 # Este parâmemtro pode ajudar na velocidade do treinamento não na qualidade do modelo em termos das métricas\n",
        "# Notas de competência do ENEM: 0, 40, 80, 120, 160, 200\n",
        "NUM_CLASSES_COMPETENCIA = 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQFuqVhnJn_T"
      },
      "source": [
        "**MultiLayerPerceptron**: Esta é a rede neural em \"PyTorch puro\". Ela define a arquitetura do Perceptron Multicamadas e incorpora a camada de saída especial do CORAL (CoralLayer)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Vw-IVQQJlhi"
      },
      "outputs": [],
      "source": [
        "class MultiLayerPerceptron(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_units, num_classes):\n",
        "        super().__init__() # Chama o construtor da classe base torch.nn.Module\n",
        "\n",
        "        # Armazena o número de classes, necessário para a função de perda CORAL\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        # Lista para armazenar todas as camadas da MLP\n",
        "        all_layers = []\n",
        "\n",
        "        # Loop para criar as camadas ocultas da MLP\n",
        "        # 'hidden_units' é uma tupla ou lista (ex: (256, 128, 64))\n",
        "        # Cada 'hidden_unit' representa o número de neurônios em uma camada oculta.\n",
        "        for hidden_unit in hidden_units:\n",
        "            # Cria uma camada linear (totalmente conectada)\n",
        "            # 'input_size' é o número de entradas para esta camada (saída da camada anterior ou features iniciais)\n",
        "            # 'hidden_unit' é o número de saídas desta camada\n",
        "            layer = torch.nn.Linear(input_size, hidden_unit)\n",
        "            all_layers.append(layer)\n",
        "\n",
        "            # Adiciona uma função de ativação ReLU após cada camada linear (exceto a última do CORAL)\n",
        "            all_layers.append(torch.nn.ReLU())\n",
        "\n",
        "            # Atualiza o 'input_size' para a próxima camada ser a saída da camada atual\n",
        "            input_size = hidden_unit\n",
        "\n",
        "        # --- Camada de Saída CORAL ---\n",
        "        # Esta é a principal adaptação para Regressão Ordinal com CORAL.\n",
        "        # Ao invés de uma camada linear normal (torch.nn.Linear) que retornaria um vetor de logits para classificação multiclasse,\n",
        "        # usamos a CoralLayer da biblioteca coral_pytorch.\n",
        "        # `size_in`: número de entradas para esta camada (que é a saída da última camada oculta, hidden_units[-1])\n",
        "        # `num_classes`: o número total de categorias de pontuação (ex: 6 para 0 a 200).\n",
        "        output_layer = CoralLayer(size_in=hidden_units[-1], num_classes=num_classes)\n",
        "        all_layers.append(output_layer)\n",
        "\n",
        "        # Combina todas as camadas em um modelo sequencial.\n",
        "        # 'Sequential' executa as camadas em ordem, uma após a outra.\n",
        "        self.model = torch.nn.Sequential(*all_layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Define o fluxo de dados para frente através da rede neural.\n",
        "        `x` é o tensor de entrada (as features).\n",
        "        \"\"\"\n",
        "        # Passa o tensor de entrada através da sequência de camadas definidas\n",
        "        x = self.model(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDJYp3rfQkTH"
      },
      "source": [
        "**LightningMLP**: Esta é uma classe do PyTorch Lightning. Ela \"envolve\" a rede neural (MultiLayerPerceptron) e adiciona toda a funcionalidade extra que o Lightning oferece (treinamento automatizado, validação, teste, logs, otimizadores, etc.), tornando o código de treino muito mais limpo e padronizado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZUF2Iz_QjKO"
      },
      "outputs": [],
      "source": [
        "class LightningMLP(pl.LightningModule):\n",
        "    def __init__(self, model, learning_rate):\n",
        "        super().__init__() # Chama o construtor da classe base pl.LightningModule\n",
        "\n",
        "        self.learning_rate = learning_rate # Taxa de aprendizado para o otimizador\n",
        "        self.model = model # A instância da rede neural MultiLayerPerceptron\n",
        "\n",
        "        # Salva configurações e hiperparâmetros (como learning_rate) no diretório de log.\n",
        "        # 'ignore=['model']' impede que os parâmetros do modelo sejam salvos duas vezes.\n",
        "        self.save_hyperparameters(ignore=['model'])\n",
        "\n",
        "        # MODIFICAÇÃO REALIZADA AQUI\n",
        "        # Inicializa a métrica ENEMAccuracy para cada etapa\n",
        "        self.train_enem_acc = ENEMAccuracy()\n",
        "        self.valid_enem_acc = ENEMAccuracy()\n",
        "        self.test_enem_acc = ENEMAccuracy()\n",
        "\n",
        "        self.train_rmse = torchmetrics.MeanSquaredError(squared=False)\n",
        "        self.valid_rmse = torchmetrics.MeanSquaredError(squared=False)\n",
        "        self.test_rmse = torchmetrics.MeanSquaredError(squared=False)\n",
        "\n",
        "\n",
        "        # --- Configuração das Métricas de Avaliação ---\n",
        "        # pythorthmetrics são uma forma conveniente de calcular métricas.\n",
        "        # Mean Absolute Error (MAE): Mede a diferença média absoluta entre previsões e rótulos verdadeiros.\n",
        "        self.train_mae = torchmetrics.MeanAbsoluteError()\n",
        "        self.valid_mae = torchmetrics.MeanAbsoluteError()\n",
        "        self.test_mae = torchmetrics.MeanAbsoluteError()\n",
        "\n",
        "        # Quadratic Weighted Kappa (QWK): Métrica CRUCIAL para AES.\n",
        "        # Ela considera a natureza ordinal das notas e penaliza erros maiores mais severamente.\n",
        "        # `num_classes`: número de categorias de nota (ex: 6 para competências).\n",
        "        # `task='multiclass'`: indica que é uma tarefa de classificação multi-classe (embora seja ordinal).\n",
        "        # `weights='quadratic'`: Aplica os pesos quadráticos para penalizar mais erros maiores.\n",
        "        self.train_qwk = torchmetrics.CohenKappa(num_classes=self.model.num_classes, task='multiclass', weights='quadratic')\n",
        "        self.valid_qwk = torchmetrics.CohenKappa(num_classes=self.model.num_classes, task='multiclass', weights='quadratic')\n",
        "        self.test_qwk = torchmetrics.CohenKappa(num_classes=self.model.num_classes, task='multiclass', weights='quadratic')\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Define o fluxo de dados para frente através do modelo PyTorch.\n",
        "        Este método é chamado internamente pelo Lightning para fazer previsões.\n",
        "        \"\"\"\n",
        "        return self.model(x) # Simplesmente passa a entrada para o MultiLayerPerceptron\n",
        "\n",
        "    def _shared_step(self, batch):\n",
        "        \"\"\"\n",
        "        Etapa comum de processamento que é usada para treinamento, validação e teste.\n",
        "        Isso evita a duplicação de código.\n",
        "        \"\"\"\n",
        "        features, true_labels = batch # Desempacota o batch de dados\n",
        "\n",
        "        # --- Adaptação CORAL: Converter labels para o formato binário estendido ---\n",
        "        # 'levels_from_labelbatch' é uma função de coral_pytorch.\n",
        "        # Ela transforma um rótulo de classe inteira (ex: 3) em um vetor binário de \"níveis\" (ex: [1, 1, 1, 0, 0, 0])\n",
        "        # `num_classes`: o número total de classes.\n",
        "        levels = levels_from_labelbatch(\n",
        "            true_labels, num_classes=self.model.num_classes)\n",
        "\n",
        "        # Passa as features para a rede neural para obter os logits (saídas brutas)\n",
        "        logits = self(features) # self(features) é o mesmo que self.forward(features)\n",
        "\n",
        "        # --- Adaptação CORAL: Calcular a função de perda CORAL ---\n",
        "        # 'coral_loss' é uma função de coral_pytorch.\n",
        "        # Ela calcula a perda entre os logits do modelo e os 'levels' binários.\n",
        "        # 'levels.type_as(logits)' garante que os tipos de dados dos tensores sejam compatíveis.\n",
        "        loss = coral_loss(logits, levels.type_as(logits))\n",
        "\n",
        "        # --- Adaptação CORAL: Converter probabilidades previstas em rótulos finais ---\n",
        "        # `torch.sigmoid(logits)`: Transforma os logits brutos em probabilidades entre 0 e 1.\n",
        "        # `proba_to_label`: Uma função de coral_pytorch que converte essas probabilidades\n",
        "        # em rótulos de classe previstos (ex: 0, 1, 2, ..., num_classes-1).\n",
        "        probas = torch.sigmoid(logits)\n",
        "        predicted_labels = proba_to_label(probas)\n",
        "\n",
        "        return loss, true_labels, predicted_labels\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        \"\"\"\n",
        "        Define o que acontece em cada passo de treinamento (para cada batch).\n",
        "        \"\"\"\n",
        "        loss, true_labels, predicted_labels = self._shared_step(batch) # Usa a etapa compartilhada\n",
        "\n",
        "        # MODIFICADO AQUI\n",
        "        self.train_enem_acc(predicted_labels.float(), true_labels.float())\n",
        "        self.log(\"train_enem_acc\", self.train_enem_acc, on_epoch=True, on_step=False)\n",
        "\n",
        "        # Registrar a perda de treinamento\n",
        "        self.log(\"train_loss\", loss, on_epoch=True, on_step=False) # 'on_epoch=True' loga no final da epoch\n",
        "\n",
        "        # Calcular e registrar o MAE de treinamento\n",
        "        self.train_mae(predicted_labels, true_labels)\n",
        "        self.log(\"train_mae\", self.train_mae, on_epoch=True, on_step=False)\n",
        "\n",
        "        # Calcular e registrar o QWK de treinamento\n",
        "        self.train_qwk(predicted_labels, true_labels)\n",
        "        self.log(\"train_qwk\", self.train_qwk, on_epoch=True, on_step=False)\n",
        "\n",
        "        # --- Adição do RMSE em training_step ---\n",
        "        self.train_rmse(predicted_labels.float(), true_labels.float())\n",
        "        self.log(\"train_rmse\", self.train_rmse, on_epoch=True, on_step=False)\n",
        "\n",
        "        return loss  # A perda é retornada para o otimizador fazer o backpropagation\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        \"\"\"\n",
        "        Define o que acontece em cada passo de validação.\n",
        "        Similar ao training_step, mas não calcula gradientes.\n",
        "        \"\"\"\n",
        "        loss, true_labels, predicted_labels = self._shared_step(batch)\n",
        "\n",
        "        # MODIFICADO AQUI\n",
        "        self.valid_enem_acc(predicted_labels.float(), true_labels.float())\n",
        "        self.log(\"valid_enem_acc\", self.valid_enem_acc, on_epoch=True, on_step=False, prog_bar=True)\n",
        "\n",
        "        self.log(\"valid_loss\", loss, on_epoch=True, on_step=False)\n",
        "        self.valid_mae(predicted_labels, true_labels)\n",
        "\n",
        "        self.log(\"valid_mae\", self.valid_mae,on_epoch=True, on_step=False, prog_bar=True) # prog_bar mostra no progresso da barra\n",
        "        self.valid_qwk(predicted_labels, true_labels)\n",
        "\n",
        "        self.log(\"valid_qwk\", self.valid_qwk,on_epoch=True, on_step=False, prog_bar=True)\n",
        "\n",
        "  # --- Adição do RMSE em validation_step ---\n",
        "        self.valid_rmse(predicted_labels.float(), true_labels.float())\n",
        "        self.log(\"valid_rmse\", self.valid_rmse, on_epoch=True, on_step=False, prog_bar=True)\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        \"\"\"\n",
        "        Define o que acontece em cada passo de teste (avaliação final).\n",
        "        \"\"\"\n",
        "        # Não precisamos da perda para o teste, por isso o '_'\n",
        "        _, true_labels, predicted_labels = self._shared_step(batch)\n",
        "\n",
        "        self.test_enem_acc(predicted_labels.float(), true_labels.float())\n",
        "        self.log(\"test_enem_acc\", self.test_enem_acc, on_epoch=True, on_step=False)\n",
        "\n",
        "        self.test_mae(predicted_labels, true_labels)\n",
        "        self.log(\"test_mae\", self.test_mae, on_epoch=True, on_step=False)\n",
        "\n",
        "        self.test_qwk(predicted_labels, true_labels)\n",
        "        self.log(\"test_qwk\", self.test_qwk, on_epoch=True, on_step=False)\n",
        "\n",
        "        self.test_rmse(predicted_labels.float(), true_labels.float())\n",
        "        self.log(\"test_rmse\", self.test_rmse, on_epoch=True, on_step=False)\n",
        "\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        \"\"\"\n",
        "        Configura o otimizador da rede neural.\n",
        "        \"\"\"\n",
        "        # Otimizador Adam: otimizador popular e eficiente.\n",
        "        # self.parameters() retorna todos os parâmetros treináveis do modelo.\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
        "        return optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWi00SZEKIm0"
      },
      "source": [
        "**Classe MyDataset**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANmyRtDfKQXy"
      },
      "source": [
        "Este código define a classe MyDataset, que prepara os dados para o PyTorch. Ele armazena as features (X) e labels (y) em arrays NumPy. Os métodos **__len__** e **__getitem__** permitem que o PyTorch saiba o tamanho total do seu dataset e como acessar cada amostra individualmente (features e seu label correspondente) usando um índice. Isso é fundamental para organizar os dados para o treinamento do modelo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1hIBxbqLKGvy"
      },
      "outputs": [],
      "source": [
        "class MyDataset(Dataset): # A classe MyDataset herda de torch.utils.data.Dataset\n",
        "    def __init__(self, feature_array, label_array, dtype=np.float32):\n",
        "        \"\"\"\n",
        "        Método construtor da classe. É chamado quando você cria uma nova instância de MyDataset.\n",
        "\n",
        "        Args:\n",
        "            feature_array (np.ndarray): Um array NumPy contendo suas features (X).\n",
        "                                        Por exemplo, X_train_std, X_val_std, X_test_std.\n",
        "            label_array (np.ndarray): Um array NumPy contendo seus labels (y).\n",
        "                                      Por exemplo, y_train, y_val, y_test.\n",
        "            dtype (np.float32, optional): O tipo de dado em que as features serão convertidas.\n",
        "                                          np.float32 é um tipo comum para entradas de redes neurais,\n",
        "                                          pois economiza memória e é compatível com GPUs.\n",
        "        \"\"\"\n",
        "        # Converte o array de features para o tipo de dado especificado.\n",
        "        # Isso é importante para garantir que as features estejam no formato numérico\n",
        "        # esperado pelo PyTorch (geralmente float32 ou float64).\n",
        "        self.feature_data = feature_array.astype(dtype)\n",
        "\n",
        "        # Armazena o array de labels.\n",
        "        # Comentário: \"Labels devem ser long para PyTorch\" -- isso é uma dica importante.\n",
        "        # Para problemas de classificação (e regressão ordinal como no presente trabalho, que usa classificadores binários internamente),\n",
        "        # o PyTorch geralmente espera que os rótulos de classe sejam tensores do tipo Long (torch.long).\n",
        "        # Se label_array for um NumPy array de inteiros, PyTorch lida com isso.\n",
        "        self.labels = label_array\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"\n",
        "        Método mágico que permite acessar amostras do dataset usando índices, como em uma lista.\n",
        "        Ex: dataset[0] chamaria __getitem__(0).\n",
        "\n",
        "        Args:\n",
        "            index (int): O índice da amostra que você deseja retornar.\n",
        "\n",
        "        Returns:\n",
        "            tuple: Uma tupla contendo (inputs, label) para a amostra no índice fornecido.\n",
        "                   - inputs: As features (dados de entrada) da amostra.\n",
        "                   - label: O rótulo (valor alvo) correspondente à amostra.\n",
        "        \"\"\"\n",
        "        inputs = self.feature_data[index] # Pega a linha de features no 'index'\n",
        "        label = self.labels[index]   # Pega o label correspondente no 'index'\n",
        "        return inputs, label\n",
        "\n",
        "    def __len__(self, ):\n",
        "        \"\"\"\n",
        "        Método mágico que retorna o número total de amostras no dataset.\n",
        "        Permite usar len(dataset).\n",
        "\n",
        "        Returns:\n",
        "            int: O número de linhas (amostras) no array de features.\n",
        "        \"\"\"\n",
        "        return self.feature_data.shape[0] # Retorna o número de linhas (primeira dimensão) do array de features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCznS31CKXXC"
      },
      "source": [
        "**Classe CompetenceDataModule (Substitui DataModule)**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyosnL3NKiBK"
      },
      "source": [
        "Esta é a parte central da adaptação para múltiplos modelos. O DataModule agora será específico para cada competência, recebendo os X e y já divididos e escalados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PU7iHhkUKaYS"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "class CompetenceDataModule(pl.LightningDataModule): # A classe herda de pytorch_lightning.LightningDataModule\n",
        "    def __init__(self, X_train, y_train, X_val, y_val, X_test, y_test, batch_size, num_workers):\n",
        "        \"\"\"\n",
        "        Método construtor da classe. É chamado quando é criado uma nova instância de CompetenceDataModule.\n",
        "\n",
        "        Args:\n",
        "            X_train (np.ndarray): Matriz de features para o conjunto de treinamento.\n",
        "            y_train (np.ndarray): Vetor de labels (notas) para o conjunto de treinamento.\n",
        "            X_val (np.ndarray): Matriz de features para o conjunto de validação.\n",
        "            y_val (np.ndarray): Vetor de labels para o conjunto de validação.\n",
        "            X_test (np.ndarray): Matriz de features para o conjunto de teste.\n",
        "            y_test (np.ndarray): Vetor de labels para o conjunto de teste.\n",
        "            batch_size (int): O número de amostras por lote (batch) que o modelo processará de cada vez.\n",
        "            num_workers (int): O número de subprocessos a serem usados para carregamento de dados.\n",
        "                                0 significa que o carregamento será feito no processo principal.\n",
        "                                Valores > 0 podem acelerar o carregamento, mas podem causar problemas em ambientes como o Windows/WSL.\n",
        "        \"\"\"\n",
        "        super().__init__() # Chama o construtor da classe base pl.LightningDataModule\n",
        "\n",
        "        # Armazena os arrays NumPy dos conjuntos de dados\n",
        "        # Esses dados já devem estar pré-processados e escalados (ex: X_train_std)\n",
        "        # self.X_train = X_train\n",
        "        # self.y_train = y_train\n",
        "        # self.X_val = X_val\n",
        "        # self.y_val = y_val\n",
        "        # self.X_test = X_test\n",
        "        # self.y_test = y_test\n",
        "\n",
        "        self.X_train = torch.FloatTensor(X_train)\n",
        "        self.y_train = torch.IntTensor(y_train)  # ou IntTensor dependendo do seu caso\n",
        "        self.X_val = torch.FloatTensor(X_val)\n",
        "        self.y_val = torch.IntTensor(y_val)\n",
        "        self.X_test = torch.FloatTensor(X_test)\n",
        "        self.y_test = torch.IntTensor(y_test)\n",
        "\n",
        "        # Armazena configurações de DataLoader\n",
        "        self.batch_size = batch_size\n",
        "        self.num_workers = num_workers\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        \"\"\"\n",
        "        Este método é chamado pelo PyTorch Lightning para preparar os dados.\n",
        "        Ele é chamado em cada \"nó\" (processo/GPU) em um ambiente distribuído.\n",
        "        Normalmente, é aqui que fazemos a divisão de dados, escalamento, etc.\n",
        "        Em nosso caso caso, ja fizemos isso no fluxo principal do script, então aqui ele\n",
        "        apenas cria as instâncias de MyDataset.\n",
        "\n",
        "        Args:\n",
        "            stage (str, optional): Indica a fase atual ('fit', 'validate', 'test', 'predict').\n",
        "                                   Permite lógica condicional se necessário. Ignorado aqui.\n",
        "        \"\"\"\n",
        "        # Cria os objetos MyDataset para cada conjunto (treino, validação, teste).\n",
        "        # MyDataset encapsula os arrays NumPy X e y em um formato que PyTorch pode usar.\n",
        "        # self.train = MyDataset(self.X_train, self.y_train)\n",
        "        # self.valid = MyDataset(self.X_val, self.y_val)\n",
        "        # self.test = MyDataset(self.X_test, self.y_test)\n",
        "\n",
        "        self.train = TensorDataset(self.X_train, self.y_train)\n",
        "        self.valid = TensorDataset(self.X_val, self.y_val)\n",
        "        self.test = TensorDataset(self.X_test, self.y_test)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        \"\"\"\n",
        "        Retorna o DataLoader para o conjunto de treinamento.\n",
        "        \"\"\"\n",
        "        return DataLoader(self.train,\n",
        "                          batch_size=self.batch_size, # Tamanho dos lotes para o treino\n",
        "                          num_workers=self.num_workers, # Número de subprocessos para carregar dados\n",
        "                          shuffle=True, # Embaralha os dados a cada epoch para evitar que o modelo \"decore\" a ordem\n",
        "                          drop_last=True) # Se o último batch não tiver o tamanho completo, ele é descartado.\n",
        "                                          # Útil para modelos que esperam batches de tamanho fixo, ou GPUs.\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        \"\"\"\n",
        "        Retorna o DataLoader para o conjunto de validação.\n",
        "        \"\"\"\n",
        "        return DataLoader(self.valid,\n",
        "                          batch_size=self.batch_size,\n",
        "                          num_workers=self.num_workers,\n",
        "                          drop_last=True) # Explicitly set drop_last to True for validation\n",
        "                          # shuffle=False é o padrão para validação/teste, pois a ordem não importa.\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        \"\"\"\n",
        "        Retorna o DataLoader para o conjunto de teste.\n",
        "        \"\"\"\n",
        "        return DataLoader(self.test,\n",
        "                          batch_size=self.batch_size,\n",
        "                          num_workers=self.num_workers)\n",
        "                          # shuffle=False é o padrão para validação/teste."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAt8GrhA8fin"
      },
      "source": [
        "# Importação"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aBwJxKz-8nKW"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/NILC + Embedding + ORD (final df)/df_train.csv\")\n",
        "df_val = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/NILC + Embedding + ORD (final df)/df_val.csv\")\n",
        "df_test = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/NILC + Embedding + ORD (final df)/df_test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/df com métrica NILC/df_validation.csv\")\n"
      ],
      "metadata": {
        "id": "GlqH8ENZe974"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['honore']"
      ],
      "metadata": {
        "id": "8uSezWDZfElH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWNec_aT8vNY"
      },
      "source": [
        "# Análise de divergência (test_hard and test_easy)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definição do Tipo de Análise:\n",
        "# Valores de 0 a 4: Competências do ENEM (C1 a C5)\n",
        "# Valor 5: Nota final (soma das competências)\n",
        "REFERENCE_CONCEPT = 4"
      ],
      "metadata": {
        "id": "I92Dgs5tvFcb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"kamel-usp/aes_enem_dataset\", \"sourceAWithGraders\", cache_dir=\"/tmp/aes_enem\", trust_remote_code=True)"
      ],
      "metadata": {
        "id": "Mans7jB7s3X2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4lGrHGn80Q7"
      },
      "outputs": [],
      "source": [
        "def computa_diferenca(lists):\n",
        "    \"\"\"Identifica redações com grande divergência entre avaliadores (>80 pontos)\"\"\"\n",
        "    if len(lists) < 3:\n",
        "        return False\n",
        "\n",
        "    referencia = lists[0][REFERENCE_CONCEPT]\n",
        "    avaliador_a = lists[1][REFERENCE_CONCEPT]\n",
        "    avaliador_b = lists[2][REFERENCE_CONCEPT]\n",
        "\n",
        "    diff_ref_a = abs(referencia - avaliador_a)\n",
        "    diff_ref_b = abs(referencia - avaliador_b)\n",
        "    diff_a_b = abs(avaliador_a - avaliador_b)\n",
        "\n",
        "    return diff_ref_a > 80 or diff_ref_b > 80 or diff_a_b > 80"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separação em conjuntos easy/hard\n",
        "test_df = dataset[\"test\"].to_pandas()\n",
        "\n",
        "new_test_df = pd.merge(\n",
        "    test_df.groupby([\"id_prompt\", \"id\"])\n",
        "           .agg({\"grades\": list})\n",
        "           .apply(lambda x: computa_diferenca(x['grades']), axis=1)\n",
        "           .reset_index(),\n",
        "    test_df,\n",
        "    on=[\"id_prompt\", \"id\"]\n",
        ").rename(columns={0: \"is_hard\"})"
      ],
      "metadata": {
        "id": "dtvO-LnixhAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "# O restante do seu código...\n",
        "dataset[\"test_easy\"] = Dataset.from_pandas(new_test_df[new_test_df[\"is_hard\"]==False])\n",
        "dataset[\"test_hard\"] = Dataset.from_pandas(new_test_df[new_test_df[\"is_hard\"]==True])"
      ],
      "metadata": {
        "id": "xlZricHBye53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Cria o DataFrame de Redações Fáceis (is_hard == False)\n",
        "df_test_easy = new_test_df[new_test_df[\"is_hard\"] == False].copy()\n",
        "\n",
        "# 2. Cria o DataFrame de Redações Difíceis (is_hard == True)\n",
        "df_test_hard = new_test_df[new_test_df[\"is_hard\"] == True].copy()\n",
        "\n",
        "# Exibe os tamanhos dos novos conjuntos para verificação\n",
        "print(f\"DataFrame EASY criado. Tamanho: {len(df_test_easy)}\")\n",
        "print(f\"DataFrame HARD criado. Tamanho: {len(df_test_hard)}\")"
      ],
      "metadata": {
        "id": "qYsJ0g5Gy9V_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/df features Murilo/test_murilo.csv\")"
      ],
      "metadata": {
        "id": "-1pLh5y3FCAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_test['id'] = range(len(df_test))\n",
        "df_test_easy['id'] = range(len(df_test_easy))\n",
        "df_test_hard['id'] = range(len(df_test_hard))"
      ],
      "metadata": {
        "id": "Pk2j49J2GcTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "textos_easy = df_test_easy['id'].unique()\n",
        "textos_hard = df_test_hard['id'].unique()\n",
        "\n",
        "# 2. Criar os novos DataFrames (df_final_easy e df_final_hard) a partir do df_test principal\n",
        "# Usamos o método .isin() para filtrar o df_test principal pelas chaves de texto.\n",
        "\n",
        "# Filtrar as redações \"fáceis\"\n",
        "df_final_easy = df_test[df_test['id'].isin(textos_easy)].copy()\n",
        "\n",
        "# Filtrar as redações \"difíceis\"\n",
        "df_final_hard = df_test[df_test['id'].isin(textos_hard)].copy()\n",
        "\n",
        "# 3. Verificação dos tamanhos e da integridade dos dados\n",
        "print(\"Separação concluída com o df_test como fonte:\")\n",
        "print(f\"df_final_easy (Baixa Divergência): {len(df_final_easy)} registros\")\n",
        "print(f\"df_final_hard (Alta Divergência): {len(df_final_hard)} registros\")\n",
        "\n",
        "# Verificação da soma\n",
        "soma_total = len(df_final_easy) + len(df_final_hard)\n",
        "print(f\"Soma das partições: {soma_total} (Deve ser 209)\")"
      ],
      "metadata": {
        "id": "gY8xH4NZDfYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nome_do_arquivo_csv = 'df_test_easy.csv'\n",
        "df_final_easy.to_csv(nome_do_arquivo_csv, index=False)"
      ],
      "metadata": {
        "id": "sYL1eGqjJa9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nome_do_arquivo_csv = 'df_test_hard.csv'\n",
        "df_final_hard.to_csv(nome_do_arquivo_csv, index=False)"
      ],
      "metadata": {
        "id": "-CMCw1D2Jc1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_easy.head()"
      ],
      "metadata": {
        "id": "qNHtmjET2x0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ovNBO7qs52Y"
      },
      "source": [
        "# TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HCTT2RkYbvC2"
      },
      "outputs": [],
      "source": [
        "# Aqui garantimos que lista de stop words do NLTK esteja disponível\n",
        "try:\n",
        "    nltk.data.find('corpora/stopwords')\n",
        "except LookupError:\n",
        "    nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5iVai53FUspO"
      },
      "outputs": [],
      "source": [
        "# Importação dos dataframes\n",
        "df_train = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/NILC + Embedding + ORD (final df)/df_train.csv\")\n",
        "df_val = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/NILC + Embedding + ORD (final df)/df_val.csv\")\n",
        "df_test_easy = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/test easy and hard/df_test_easy.csv\")\n",
        "df_test_hard = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/test easy and hard/df_test_hard.csv\")\n",
        "df_test = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/NILC + Embedding + ORD (final df)/df_test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_easy.shape"
      ],
      "metadata": {
        "id": "HM17JDOy4PhC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.shape"
      ],
      "metadata": {
        "id": "ycYe31cA4TFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_val.shape"
      ],
      "metadata": {
        "id": "4P9x27gB4ZWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.shape"
      ],
      "metadata": {
        "id": "5N_5ZhID4ps0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jXZYCu7Pd2Mt"
      },
      "outputs": [],
      "source": [
        "# Pré-processmaento dos textos\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    stop_words_pt = set(stopwords.words('portuguese'))\n",
        "    text = ' '.join([word for word in text.split() if word not in stop_words_pt])\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2FvP75Ivh-RX"
      },
      "outputs": [],
      "source": [
        "df_train['processed_text'] = df_train['essay_text'].apply(preprocess_text)\n",
        "df_test['processed_text'] = df_test['essay_text'].apply(preprocess_text)\n",
        "df_val['processed_text'] = df_val['essay_text'].apply(preprocess_text)\n",
        "df_test_easy['processed_text'] = df_test_easy['essay_text'].apply(preprocess_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jkdkwkoxj6O3"
      },
      "outputs": [],
      "source": [
        "# --- 1. Geração da Matriz TF-IDF Completa (apenas no treino) ---\n",
        "# A matriz TF-IDF deve ser criada a partir do conjunto de treino para evitar vazamento\n",
        "# de dados.\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1, 2), stop_words=stopwords.words('portuguese'))\n",
        "X_train_tfidf_matrix = vectorizer.fit_transform(df_train['processed_text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OnO1qShqkDbW"
      },
      "outputs": [],
      "source": [
        "# Aplicação do pré-processamento nos textos\n",
        "X_val_tfidf_matrix = vectorizer.transform(df_val['processed_text'])\n",
        "X_test_tfidf_matrix = vectorizer.transform(df_test['processed_text'])\n",
        "X_test_easy_tfidf_matrix = vectorizer.transform(df_test_easy['processed_text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tGRWkSxNkF1m"
      },
      "outputs": [],
      "source": [
        "# --- 2. Seleção e União dos Índices de Features ---\n",
        "# O número de features a selecionar por competência\n",
        "K_FEATURES_PER_COMPETENCE = 1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uqdqpBKWkI00"
      },
      "outputs": [],
      "source": [
        "# Lista para armazenar os índices das features selecionadas para cada competência\n",
        "selected_features_indices_list = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u8DucTtXkLe8"
      },
      "outputs": [],
      "source": [
        "for comp_idx in range(1, 6):\n",
        "    print(f\"Selecionando features para a Competência {comp_idx}...\", flush=True)\n",
        "\n",
        "    # Definir a variável alvo (y) para a competência atual no conjunto de treino\n",
        "    y_train_comp = df_train[f'nota_competencia_{comp_idx}_ordinal']\n",
        "\n",
        "    # Ajusta o SelectKBest para encontrar as K_FEATURES_PER_COMPETENCE mais relevantes\n",
        "    selector = SelectKBest(f_classif, k=K_FEATURES_PER_COMPETENCE)\n",
        "    selector.fit(X_train_tfidf_matrix, y_train_comp)\n",
        "\n",
        "    # Adiciona os índices das features selecionadas à lista\n",
        "    selected_features_indices_list.extend(selector.get_support(indices=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDW3vZNOkUPc"
      },
      "outputs": [],
      "source": [
        "# 3. Criar uma lista única de índices e ordenar\n",
        "# O uso de np.unique remove duplicatas caso uma mesma feature seja relevante para\n",
        "# mais de uma competência.\n",
        "unique_selected_indices = np.sort(np.unique(selected_features_indices_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CtUpKs5QkfAF"
      },
      "outputs": [],
      "source": [
        "# --- 4. Reduzir as Matrizes TF-IDF Originais ---\n",
        "# Agora, aplicamos a lista de índices unificada a todas as matrizes TF-IDF.\n",
        "X_train_tfidf_final = X_train_tfidf_matrix[:, unique_selected_indices]\n",
        "X_val_tfidf_final = X_val_tfidf_matrix[:, unique_selected_indices]\n",
        "X_test_tfidf_final = X_test_tfidf_matrix[:, unique_selected_indices]\n",
        "X_test_easy_tfidf_final = X_test_easy_tfidf_matrix[:, unique_selected_indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eYpqODgMkh6t"
      },
      "outputs": [],
      "source": [
        "# Converte para arrays densos, se necessário, para concatenação futura\n",
        "X_train_tfidf_final_array = X_train_tfidf_final.toarray()\n",
        "X_val_tfidf_final_array = X_val_tfidf_final.toarray()\n",
        "X_test_tfidf_final_array = X_test_tfidf_final.toarray()\n",
        "X_test_easy_tfidf_final_array = X_test_easy_tfidf_final.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gon2wYFqks58"
      },
      "outputs": [],
      "source": [
        "print(f\"Matriz TF-IDF final do treino. Dimensão: {X_train_tfidf_final_array.shape}\")\n",
        "print(f\"Matriz TF-IDF final do teste. Dimensão: {X_test_tfidf_final_array.shape}\")\n",
        "print(f\"Matriz TF-IDF final da validação. Dimensão: {X_val_tfidf_final_array.shape}\")\n",
        "print(f\"Matriz TF-IDF final da test easy. Dimensão: {X_test_easy_tfidf_final_array.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Treinamento base test inteira"
      ],
      "metadata": {
        "id": "iGAa1Q0zF4D0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZM0JFeeoQy19"
      },
      "outputs": [],
      "source": [
        "# --- 4. Loop para Treinar um Modelo para Cada Competência ---\n",
        "resultados_por_competencia = {}\n",
        "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "for comp_idx in range(1, 6): # Para competência 1 a 5\n",
        "    print(f\"\\n--- Treinando Modelo para Competência {comp_idx} ---\", flush=True)\n",
        "\n",
        "    # Concatena as features artesanais com as features TF-IDF\n",
        "    X_train =  X_train_tfidf_final_array\n",
        "    y_train = df_train[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_val =  X_val_tfidf_final_array\n",
        "    y_val = df_val[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_test = X_test_tfidf_final_array\n",
        "    y_test = df_test[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    print(f\"Divisão de dados para Competência {comp_idx}: Treino={X_train.shape}, Validação={X_val.shape}, Teste={X_test.shape}\", flush=True)\n",
        "\n",
        "    # Escalamento de Features (Fit no treino, transform nos outros)\n",
        "    scaler_comp = StandardScaler()\n",
        "    X_train_std = scaler_comp.fit_transform(X_train)\n",
        "    X_val_std = scaler_comp.transform(X_val)\n",
        "    X_test_std = scaler_comp.transform(X_test)\n",
        "    print(f\"Features escaladas para Competência {comp_idx}.\", flush=True)\n",
        "\n",
        "\n",
        "    # Criar DataModule para a competência atual\n",
        "    data_module_competencia = CompetenceDataModule(X_train_std, y_train, X_val_std, y_val, X_test_std, y_test, BATCH_SIZE, NUM_WORKERS)\n",
        "    data_module_competencia.setup()\n",
        "\n",
        "\n",
        "    # Inicializar e treinar o modelo PyTorch Lightning\n",
        "    input_dim = X_train_std.shape[1]\n",
        "\n",
        "    pytorch_model_competencia = MultiLayerPerceptron(\n",
        "        input_size=input_dim,\n",
        "        hidden_units=(256, 128, 64),\n",
        "        num_classes=NUM_CLASSES_COMPETENCIA\n",
        "    )\n",
        "    lightning_model_competencia = LightningMLP(\n",
        "        model=pytorch_model_competencia,\n",
        "        learning_rate=LEARNING_RATE\n",
        "    )\n",
        "\n",
        "    # Callbacks e Logger\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        save_top_k=1, mode=\"min\", monitor=\"valid_mae\",\n",
        "        dirpath=f\"logs_comp_{comp_idx}/\", filename=f\"best_model_comp_{comp_idx}\"\n",
        "    )\n",
        "    logger_competencia = CSVLogger(save_dir=\"logs/\", name=f\"mlp-coral-comp-{comp_idx}\")\n",
        "\n",
        "\n",
        "    early_stop_callback = EarlyStopping(\n",
        "    monitor=\"valid_qwk\",\n",
        "    min_delta=0.00,\n",
        "    patience=50,\n",
        "    verbose=True,\n",
        "    mode=\"max\"\n",
        "    )\n",
        "\n",
        "    callbacks_list = [\n",
        "        model_checkpoint_callback,\n",
        "        early_stop_callback\n",
        "    ]\n",
        "\n",
        "    trainer_competencia = pl.Trainer(\n",
        "        max_epochs=NUM_EPOCHS,\n",
        "        callbacks=callbacks_list,\n",
        "        accelerator=device_type,\n",
        "        devices=1,\n",
        "        logger=logger_competencia,\n",
        "        deterministic=True,\n",
        "        log_every_n_steps=10\n",
        "    )\n",
        "\n",
        "    # Treinar\n",
        "    start_time = time.time()\n",
        "    print(f\"Treinando modelo para Competência {comp_idx}...\", flush=True)\n",
        "    trainer_competencia.fit(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    runtime = (time.time() - start_time)/60\n",
        "    print(f\"Treinamento para Competência {comp_idx} levou {runtime:.2f} min.\", flush=True)\n",
        "\n",
        "    # Avaliar no conjunto de teste (avaliação final)\n",
        "    print(f\"Avaliando modelo para Competência {comp_idx} no conjunto de teste...\", flush=True)\n",
        "    test_results = trainer_competencia.test(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    resultados_por_competencia[f'competencia_{comp_idx}'] = test_results[0]\n",
        "\n",
        "    # Geração do classification Report\n",
        "    # Obter o modelo treinado\n",
        "    model_path = model_checkpoint_callback.best_model_path\n",
        "    best_model = LightningMLP.load_from_checkpoint(model_path, model=pytorch_model_competencia, learning_rate=LEARNING_RATE)\n",
        "    best_model.eval()\n",
        "\n",
        "    # Fazer previsões no conjunto de teste para obter o y_pred\n",
        "    y_pred_list = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_module_competencia.test_dataloader():\n",
        "            features, _ = batch\n",
        "            logits = best_model(features)\n",
        "            probas = torch.sigmoid(logits)\n",
        "            predicted_labels = proba_to_label(probas)\n",
        "            y_pred_list.append(predicted_labels.cpu().numpy())\n",
        "\n",
        "    y_pred = np.hstack(y_pred_list)\n",
        "    y_true = y_test # o y_test já foi definido no loop\n",
        "\n",
        "    # Discretizar as previsões para o formato de classe\n",
        "    y_pred_discreto = np.clip(np.round(y_pred), 0, NUM_CLASSES_COMPETENCIA - 1).astype(int)\n",
        "\n",
        "    # Gerar os relatórios de classificação\n",
        "    print(\"--- Relatório de Classificação da Competência \", comp_idx, \" ---\")\n",
        "    print(classification_report(y_true, y_pred_discreto, zero_division=0.0))\n",
        "    print(\"\\n--- Matriz de Confusão da Competência \", comp_idx, \" ---\")\n",
        "    print(confusion_matrix(y_true, y_pred_discreto))\n",
        "\n",
        "    print(f\"--- Modelo para Competência {comp_idx} concluído ---\", flush=True)\n",
        "\n",
        "print(\"\\n--- Todos os modelos de competência foram treinados e avaliados ---\", flush=True)\n",
        "for comp, results in resultados_por_competencia.items():\n",
        "    print(f\"{comp}: QWK = {results['test_qwk']:.4f}, RMSE = {results['test_rmse']:.4f}, HDIV = {1- results['test_enem_acc']:.4f}\", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Treinamento com Easy test"
      ],
      "metadata": {
        "id": "pt0ur-1KJyiK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4. Loop para Treinar um Modelo para Cada Competência ---\n",
        "resultados_por_competencia = {}\n",
        "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "for comp_idx in range(1, 6): # Para competência 1 a 5\n",
        "    print(f\"\\n--- Treinando Modelo para Competência {comp_idx} ---\", flush=True)\n",
        "\n",
        "    # Concatena as features artesanais com as features TF-IDF\n",
        "    X_train =  X_train_tfidf_final_array\n",
        "    y_train = df_train[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_val =  X_val_tfidf_final_array\n",
        "    y_val = df_val[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_test = X_test_easy_tfidf_final_array\n",
        "    y_test = df_test_easy[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    print(f\"Divisão de dados para Competência {comp_idx}: Treino={X_train.shape}, Validação={X_val.shape}, Teste={X_test.shape}\", flush=True)\n",
        "\n",
        "    # Escalamento de Features (Fit no treino, transform nos outros)\n",
        "    scaler_comp = StandardScaler()\n",
        "    X_train_std = scaler_comp.fit_transform(X_train)\n",
        "    X_val_std = scaler_comp.transform(X_val)\n",
        "    X_test_std = scaler_comp.transform(X_test)\n",
        "    print(f\"Features escaladas para Competência {comp_idx}.\", flush=True)\n",
        "\n",
        "\n",
        "    # Criar DataModule para a competência atual\n",
        "    data_module_competencia = CompetenceDataModule(X_train_std, y_train, X_val_std, y_val, X_test_std, y_test, BATCH_SIZE, NUM_WORKERS)\n",
        "    data_module_competencia.setup()\n",
        "\n",
        "\n",
        "    # Inicializar e treinar o modelo PyTorch Lightning\n",
        "    input_dim = X_train_std.shape[1]\n",
        "\n",
        "    pytorch_model_competencia = MultiLayerPerceptron(\n",
        "        input_size=input_dim,\n",
        "        hidden_units=(256, 128, 64),\n",
        "        num_classes=NUM_CLASSES_COMPETENCIA\n",
        "    )\n",
        "    lightning_model_competencia = LightningMLP(\n",
        "        model=pytorch_model_competencia,\n",
        "        learning_rate=LEARNING_RATE\n",
        "    )\n",
        "\n",
        "    # Callbacks e Logger\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        save_top_k=1, mode=\"min\", monitor=\"valid_mae\",\n",
        "        dirpath=f\"logs_comp_{comp_idx}/\", filename=f\"best_model_comp_{comp_idx}\"\n",
        "    )\n",
        "    logger_competencia = CSVLogger(save_dir=\"logs/\", name=f\"mlp-coral-comp-{comp_idx}\")\n",
        "\n",
        "\n",
        "    early_stop_callback = EarlyStopping(\n",
        "    monitor=\"valid_qwk\",\n",
        "    min_delta=0.00,\n",
        "    patience=50,\n",
        "    verbose=True,\n",
        "    mode=\"max\"\n",
        "    )\n",
        "\n",
        "    callbacks_list = [\n",
        "        model_checkpoint_callback,\n",
        "        early_stop_callback\n",
        "    ]\n",
        "\n",
        "    trainer_competencia = pl.Trainer(\n",
        "        max_epochs=NUM_EPOCHS,\n",
        "        callbacks=callbacks_list,\n",
        "        accelerator=device_type,\n",
        "        devices=1,\n",
        "        logger=logger_competencia,\n",
        "        deterministic=True,\n",
        "        log_every_n_steps=10\n",
        "    )\n",
        "\n",
        "    # Treinar\n",
        "    start_time = time.time()\n",
        "    print(f\"Treinando modelo para Competência {comp_idx}...\", flush=True)\n",
        "    trainer_competencia.fit(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    runtime = (time.time() - start_time)/60\n",
        "    print(f\"Treinamento para Competência {comp_idx} levou {runtime:.2f} min.\", flush=True)\n",
        "\n",
        "    # Avaliar no conjunto de teste (avaliação final)\n",
        "    print(f\"Avaliando modelo para Competência {comp_idx} no conjunto de teste...\", flush=True)\n",
        "    test_results = trainer_competencia.test(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    resultados_por_competencia[f'competencia_{comp_idx}'] = test_results[0]\n",
        "\n",
        "    # Geração do classification Report\n",
        "    # Obter o modelo treinado\n",
        "    model_path = model_checkpoint_callback.best_model_path\n",
        "    best_model = LightningMLP.load_from_checkpoint(model_path, model=pytorch_model_competencia, learning_rate=LEARNING_RATE)\n",
        "    best_model.eval()\n",
        "\n",
        "    # Fazer previsões no conjunto de teste para obter o y_pred\n",
        "    y_pred_list = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_module_competencia.test_dataloader():\n",
        "            features, _ = batch\n",
        "            logits = best_model(features)\n",
        "            probas = torch.sigmoid(logits)\n",
        "            predicted_labels = proba_to_label(probas)\n",
        "            y_pred_list.append(predicted_labels.cpu().numpy())\n",
        "\n",
        "    y_pred = np.hstack(y_pred_list)\n",
        "    y_true = y_test # o y_test já foi definido no loop\n",
        "\n",
        "    # Discretizar as previsões para o formato de classe\n",
        "    y_pred_discreto = np.clip(np.round(y_pred), 0, NUM_CLASSES_COMPETENCIA - 1).astype(int)\n",
        "\n",
        "    # Gerar os relatórios de classificação\n",
        "    print(\"--- Relatório de Classificação da Competência \", comp_idx, \" ---\")\n",
        "    print(classification_report(y_true, y_pred_discreto, zero_division=0.0))\n",
        "    print(\"\\n--- Matriz de Confusão da Competência \", comp_idx, \" ---\")\n",
        "    print(confusion_matrix(y_true, y_pred_discreto))\n",
        "\n",
        "    print(f\"--- Modelo para Competência {comp_idx} concluído ---\", flush=True)\n",
        "\n",
        "print(\"\\n--- Todos os modelos de competência foram treinados e avaliados ---\", flush=True)\n",
        "for comp, results in resultados_por_competencia.items():\n",
        "    print(f\"{comp}: QWK = {results['test_qwk']:.4f}, RMSE = {results['test_rmse']:.4f}, HDIV = {1- results['test_enem_acc']:.4f}\", flush=True)"
      ],
      "metadata": {
        "id": "LyCHJJ0bJvAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJmzDbPsSYry"
      },
      "source": [
        "# NILC"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importação dos dataframes\n",
        "df_train = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/NILC + Embedding + ORD (final df)/df_train.csv\", decimal=',')\n",
        "df_val = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/NILC + Embedding + ORD (final df)/df_val.csv\", decimal=',')\n",
        "df_test_easy = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/test easy and hard/df_test_easy.csv\", decimal=',')\n",
        "df_test_hard = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/test easy and hard/df_test_hard.csv\", decimal=',')\n",
        "df_test = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/NILC + Embedding + ORD (final df)/df_test.csv\", decimal=',')"
      ],
      "metadata": {
        "id": "615A31R_M6WF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JTpxFSlWhbBj"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def prepare_feature_matrix_pure_handcrafted(df):\n",
        "    \"\"\"\n",
        "    Prepara a matriz de features usando apenas as features artesanais.\n",
        "    \"\"\"\n",
        "    print(\"\\nPreparando a matriz de features (X) com Handcrafted Puro...\", flush=True)\n",
        "\n",
        "    # 1. Pré-processar Features Hand-crafted\n",
        "    primeira_coluna_metrica = ' adjective_ratio'\n",
        "    ultima_coluna_metrica = 'ratio_function_to_content_words'\n",
        "    colunas_handcrafted_nomes = df.loc[:, primeira_coluna_metrica:ultima_coluna_metrica].columns.tolist()\n",
        "\n",
        "    for col in colunas_handcrafted_nomes:\n",
        "        if col in df.columns and df[col].dtype == 'object':\n",
        "            df[col] = df[col].astype(str).str.replace('.', '', regex=False).str.replace(',', '.', regex=False)\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "    handcrafted_features_matrix = df[colunas_handcrafted_nomes].fillna(df[colunas_handcrafted_nomes].mean()).values\n",
        "    X_pure_handcrafted = handcrafted_features_matrix\n",
        "    print(f\"Matriz de features X_pure_handcrafted pronta. Dimensão: {X_pure_handcrafted.shape}\")\n",
        "\n",
        "    return X_pure_handcrafted\n",
        "\n",
        "X_train_handcrafted = prepare_feature_matrix_pure_handcrafted(df_train)\n",
        "X_val_handcrafted = prepare_feature_matrix_pure_handcrafted(df_val)\n",
        "X_test_handcrafted = prepare_feature_matrix_pure_handcrafted(df_test)\n",
        "X_test_easy_handcrafted = prepare_feature_matrix_pure_handcrafted(df_test_easy)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Treinamento com a base teste inteira"
      ],
      "metadata": {
        "id": "GQoG27rPNfzs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJRxjXCqLCcZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "resultados_por_competencia = {}\n",
        "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "for comp_idx in range(1, 6):\n",
        "    print(f\"\\n--- Treinando Modelo para Competência {comp_idx} ---\", flush=True)\n",
        "\n",
        "    X_train = X_train_handcrafted\n",
        "    y_train = df_train[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_val = X_val_handcrafted\n",
        "    y_val = df_val[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_test = X_test_handcrafted\n",
        "    y_test = df_test[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    print(f\"Divisão de dados para Competência {comp_idx}: Treino={X_train.shape}, Validação={X_val.shape}, Teste={X_test.shape}\", flush=True)\n",
        "\n",
        "\n",
        "    scaler_comp = StandardScaler()\n",
        "    X_train_std = scaler_comp.fit_transform(X_train)\n",
        "    X_val_std = scaler_comp.transform(X_val)\n",
        "    X_test_std = scaler_comp.transform(X_test)\n",
        "    print(f\"Features escaladas para Competência {comp_idx}.\", flush=True)\n",
        "\n",
        "\n",
        "    data_module_competencia = CompetenceDataModule(X_train_std, y_train, X_val_std, y_val, X_test_std, y_test, BATCH_SIZE, NUM_WORKERS)\n",
        "    data_module_competencia.setup()\n",
        "\n",
        "\n",
        "    input_dim = X_train_std.shape[1]\n",
        "\n",
        "    pytorch_model_competencia = MultiLayerPerceptron(\n",
        "        input_size=input_dim,\n",
        "        hidden_units=(256, 128, 64),\n",
        "        num_classes=NUM_CLASSES_COMPETENCIA\n",
        "    )\n",
        "    lightning_model_competencia = LightningMLP(\n",
        "        model=pytorch_model_competencia,\n",
        "        learning_rate=LEARNING_RATE\n",
        "    )\n",
        "\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        save_top_k=1, mode=\"min\", monitor=\"valid_mae\",\n",
        "        dirpath=f\"logs_comp_{comp_idx}/\", filename=f\"best_model_comp_{comp_idx}\"\n",
        "    )\n",
        "    logger_competencia = CSVLogger(save_dir=\"logs/\", name=f\"mlp-coral-comp-{comp_idx}\")\n",
        "\n",
        "\n",
        "    early_stop_callback = EarlyStopping(\n",
        "    monitor=\"valid_qwk\",\n",
        "    min_delta=0.00,\n",
        "    patience=50,\n",
        "    verbose=True,\n",
        "    mode=\"max\"\n",
        "    )\n",
        "\n",
        "    callbacks_list = [\n",
        "        model_checkpoint_callback,\n",
        "        early_stop_callback\n",
        "    ]\n",
        "\n",
        "    trainer_competencia = pl.Trainer(\n",
        "        max_epochs=NUM_EPOCHS,\n",
        "        callbacks=callbacks_list,\n",
        "        accelerator=device_type,\n",
        "        devices=1,\n",
        "        logger=logger_competencia,\n",
        "        deterministic=True,\n",
        "        log_every_n_steps=10\n",
        "    )\n",
        "\n",
        "    # Treinar\n",
        "    start_time = time.time()\n",
        "    print(f\"Treinando modelo para Competência {comp_idx}...\", flush=True)\n",
        "    trainer_competencia.fit(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    runtime = (time.time() - start_time)/60\n",
        "    print(f\"Treinamento para Competência {comp_idx} levou {runtime:.2f} min.\", flush=True)\n",
        "\n",
        "    print(f\"Avaliando modelo para Competência {comp_idx} no conjunto de teste...\", flush=True)\n",
        "    test_results = trainer_competencia.test(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    resultados_por_competencia[f'competencia_{comp_idx}'] = test_results[0]\n",
        "\n",
        "    model_path = model_checkpoint_callback.best_model_path\n",
        "    best_model = LightningMLP.load_from_checkpoint(model_path, model=pytorch_model_competencia, learning_rate=LEARNING_RATE)\n",
        "    best_model.eval()\n",
        "\n",
        "    y_pred_list = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_module_competencia.test_dataloader():\n",
        "            features, _ = batch\n",
        "            logits = best_model(features)\n",
        "            probas = torch.sigmoid(logits)\n",
        "            predicted_labels = proba_to_label(probas)\n",
        "            y_pred_list.append(predicted_labels.cpu().numpy())\n",
        "\n",
        "    y_pred = np.hstack(y_pred_list)\n",
        "    y_true = y_test\n",
        "\n",
        "    y_pred_discreto = np.clip(np.round(y_pred), 0, NUM_CLASSES_COMPETENCIA - 1).astype(int)\n",
        "\n",
        "    print(\"--- Relatório de Classificação da Competência \", comp_idx, \" ---\")\n",
        "    print(classification_report(y_true, y_pred_discreto, zero_division=0.0))\n",
        "    print(\"\\n--- Matriz de Confusão da Competência \", comp_idx, \" ---\")\n",
        "    print(confusion_matrix(y_true, y_pred_discreto))\n",
        "\n",
        "    print(f\"--- Modelo para Competência {comp_idx} concluído ---\", flush=True)\n",
        "\n",
        "print(\"\\n--- Todos os modelos de competência foram treinados e avaliados ---\", flush=True)\n",
        "for comp, results in resultados_por_competencia.items():\n",
        "    print(f\"{comp}: QWK = {results['test_qwk']:.4f}, RMSE = {results['test_rmse']:.4f}, HDIV = {1- results['test_enem_acc']:.4f}\", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Treinamento com easy test"
      ],
      "metadata": {
        "id": "MD3KFIfRO6V8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "resultados_por_competencia = {}\n",
        "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "for comp_idx in range(1, 6):\n",
        "    print(f\"\\n--- Treinando Modelo para Competência {comp_idx} ---\", flush=True)\n",
        "\n",
        "    X_train = X_train_handcrafted\n",
        "    y_train = df_train[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_val = X_val_handcrafted\n",
        "    y_val = df_val[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_test = X_test_easy_handcrafted\n",
        "    y_test = df_test_easy[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    print(f\"Divisão de dados para Competência {comp_idx}: Treino={X_train.shape}, Validação={X_val.shape}, Teste={X_test.shape}\", flush=True)\n",
        "\n",
        "\n",
        "    scaler_comp = StandardScaler()\n",
        "    X_train_std = scaler_comp.fit_transform(X_train)\n",
        "    X_val_std = scaler_comp.transform(X_val)\n",
        "    X_test_std = scaler_comp.transform(X_test)\n",
        "    print(f\"Features escaladas para Competência {comp_idx}.\", flush=True)\n",
        "\n",
        "\n",
        "    data_module_competencia = CompetenceDataModule(X_train_std, y_train, X_val_std, y_val, X_test_std, y_test, BATCH_SIZE, NUM_WORKERS)\n",
        "    data_module_competencia.setup()\n",
        "\n",
        "\n",
        "    input_dim = X_train_std.shape[1]\n",
        "\n",
        "    pytorch_model_competencia = MultiLayerPerceptron(\n",
        "        input_size=input_dim,\n",
        "        hidden_units=(256, 128, 64),\n",
        "        num_classes=NUM_CLASSES_COMPETENCIA\n",
        "    )\n",
        "    lightning_model_competencia = LightningMLP(\n",
        "        model=pytorch_model_competencia,\n",
        "        learning_rate=LEARNING_RATE\n",
        "    )\n",
        "\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        save_top_k=1, mode=\"min\", monitor=\"valid_mae\",\n",
        "        dirpath=f\"logs_comp_{comp_idx}/\", filename=f\"best_model_comp_{comp_idx}\"\n",
        "    )\n",
        "    logger_competencia = CSVLogger(save_dir=\"logs/\", name=f\"mlp-coral-comp-{comp_idx}\")\n",
        "\n",
        "\n",
        "    early_stop_callback = EarlyStopping(\n",
        "    monitor=\"valid_qwk\",\n",
        "    min_delta=0.00,\n",
        "    patience=50,\n",
        "    verbose=True,\n",
        "    mode=\"max\"\n",
        "    )\n",
        "\n",
        "    callbacks_list = [\n",
        "        model_checkpoint_callback,\n",
        "        early_stop_callback\n",
        "    ]\n",
        "\n",
        "    trainer_competencia = pl.Trainer(\n",
        "        max_epochs=NUM_EPOCHS,\n",
        "        callbacks=callbacks_list,\n",
        "        accelerator=device_type,\n",
        "        devices=1,\n",
        "        logger=logger_competencia,\n",
        "        deterministic=True,\n",
        "        log_every_n_steps=10\n",
        "    )\n",
        "\n",
        "    # Treinar\n",
        "    start_time = time.time()\n",
        "    print(f\"Treinando modelo para Competência {comp_idx}...\", flush=True)\n",
        "    trainer_competencia.fit(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    runtime = (time.time() - start_time)/60\n",
        "    print(f\"Treinamento para Competência {comp_idx} levou {runtime:.2f} min.\", flush=True)\n",
        "\n",
        "    print(f\"Avaliando modelo para Competência {comp_idx} no conjunto de teste...\", flush=True)\n",
        "    test_results = trainer_competencia.test(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    resultados_por_competencia[f'competencia_{comp_idx}'] = test_results[0]\n",
        "\n",
        "    model_path = model_checkpoint_callback.best_model_path\n",
        "    best_model = LightningMLP.load_from_checkpoint(model_path, model=pytorch_model_competencia, learning_rate=LEARNING_RATE)\n",
        "    best_model.eval()\n",
        "\n",
        "    y_pred_list = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_module_competencia.test_dataloader():\n",
        "            features, _ = batch\n",
        "            logits = best_model(features)\n",
        "            probas = torch.sigmoid(logits)\n",
        "            predicted_labels = proba_to_label(probas)\n",
        "            y_pred_list.append(predicted_labels.cpu().numpy())\n",
        "\n",
        "    y_pred = np.hstack(y_pred_list)\n",
        "    y_true = y_test\n",
        "\n",
        "    y_pred_discreto = np.clip(np.round(y_pred), 0, NUM_CLASSES_COMPETENCIA - 1).astype(int)\n",
        "\n",
        "    print(\"--- Relatório de Classificação da Competência \", comp_idx, \" ---\")\n",
        "    print(classification_report(y_true, y_pred_discreto, zero_division=0.0))\n",
        "    print(\"\\n--- Matriz de Confusão da Competência \", comp_idx, \" ---\")\n",
        "    print(confusion_matrix(y_true, y_pred_discreto))\n",
        "\n",
        "    print(f\"--- Modelo para Competência {comp_idx} concluído ---\", flush=True)\n",
        "\n",
        "print(\"\\n--- Todos os modelos de competência foram treinados e avaliados ---\", flush=True)\n",
        "for comp, results in resultados_por_competencia.items():\n",
        "    print(f\"{comp}: QWK = {results['test_qwk']:.4f}, RMSE = {results['test_rmse']:.4f}, HDIV = {1- results['test_enem_acc']:.4f}\", flush=True)"
      ],
      "metadata": {
        "id": "8pAOZHmoPC_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0MU1yMcyrfF"
      },
      "source": [
        "# BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZcKkpEayxMK"
      },
      "outputs": [],
      "source": [
        "# Importação dos dataframes\n",
        "df_train = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/NILC + Embedding + ORD (final df)/df_train.csv\", decimal=',')\n",
        "df_val = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/NILC + Embedding + ORD (final df)/df_val.csv\", decimal=',')\n",
        "df_test_easy = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/test easy and hard/df_test_easy.csv\", decimal=',')\n",
        "df_test_hard = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/test easy and hard/df_test_hard.csv\", decimal=',')\n",
        "df_test = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/NILC + Embedding + ORD (final df)/df_test.csv\", decimal=',')\n",
        "\n",
        "def prepare_feature_matrix_pure_bert(df):\n",
        "    \"\"\"\n",
        "    Prepara a matriz de features usando apenas os embeddings do BERT.\n",
        "    \"\"\"\n",
        "    print(\"\\nPreparando a matriz de features (X) com BERT Puro...\", flush=True)\n",
        "\n",
        "    # 1. Pré-processar BERT Embeddings (esta etapa permanece a mesma)\n",
        "    df['bert_embedding'] = df['bert_embedding'].apply(\n",
        "        lambda x: np.array(ast.literal_eval(re.sub(r'\\s+', ',', str(x).strip('[]')).strip(',')))\n",
        "        if pd.notna(x) and isinstance(x, str) and x.strip() else np.zeros(768)\n",
        "    )\n",
        "    bert_embeddings_matrix = np.stack(df['bert_embedding'].values)\n",
        "\n",
        "    # 3. Retorne apenas a matriz de embeddings do BERT\n",
        "    X_pure_bert = bert_embeddings_matrix\n",
        "    print(f\"Matriz de features X_pure_bert pronta. Dimensão: {X_pure_bert.shape}\")\n",
        "\n",
        "    return X_pure_bert\n",
        "\n",
        "# Passo 2: Aplicar a função a cada DataFrame para obter as matrizes X\n",
        "# Os nomes das variáveis foram alterados para refletir a abordagem pura\n",
        "X_train_pure = prepare_feature_matrix_pure_bert(df_train)\n",
        "X_val_pure = prepare_feature_matrix_pure_bert(df_val)\n",
        "X_test_pure = prepare_feature_matrix_pure_bert(df_test)\n",
        "X_test_easy_pure = prepare_feature_matrix_pure_bert(df_test_easy)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Treinamento com toda base de teste"
      ],
      "metadata": {
        "id": "qaMFA0X0EkMb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HTz6QsZPy2eZ",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "resultados_por_competencia = {}\n",
        "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "for comp_idx in range(1, 6):\n",
        "    print(f\"\\n--- Treinando Modelo para Competência {comp_idx} ---\", flush=True)\n",
        "\n",
        "    X_train = X_train_pure\n",
        "    y_train = df_train[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_val = X_val_pure\n",
        "    y_val = df_val[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_test = X_test_pure\n",
        "    y_test = df_test[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    print(f\"Divisão de dados para Competência {comp_idx}: Treino={X_train.shape}, Validação={X_val.shape}, Teste={X_test.shape}\", flush=True)\n",
        "\n",
        "    scaler_comp = StandardScaler()\n",
        "    X_train_std = scaler_comp.fit_transform(X_train)\n",
        "    X_val_std = scaler_comp.transform(X_val)\n",
        "    X_test_std = scaler_comp.transform(X_test)\n",
        "    print(f\"Features escaladas para Competência {comp_idx}.\", flush=True)\n",
        "\n",
        "    data_module_competencia = CompetenceDataModule(X_train_std, y_train, X_val_std, y_val, X_test_std, y_test, BATCH_SIZE, NUM_WORKERS)\n",
        "    data_module_competencia.setup()\n",
        "\n",
        "    input_dim = X_train_std.shape[1]\n",
        "\n",
        "    pytorch_model_competencia = MultiLayerPerceptron(\n",
        "        input_size=input_dim,\n",
        "        hidden_units=(256, 128, 64),\n",
        "        num_classes=NUM_CLASSES_COMPETENCIA\n",
        "    )\n",
        "    lightning_model_competencia = LightningMLP(\n",
        "        model=pytorch_model_competencia,\n",
        "        learning_rate=LEARNING_RATE\n",
        "    )\n",
        "\n",
        "\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        save_top_k=1, mode=\"min\", monitor=\"valid_mae\",\n",
        "        dirpath=f\"logs_comp_{comp_idx}/\", filename=f\"best_model_comp_{comp_idx}\"\n",
        "    )\n",
        "    logger_competencia = CSVLogger(save_dir=\"logs/\", name=f\"mlp-coral-comp-{comp_idx}\")\n",
        "\n",
        "\n",
        "    early_stop_callback = EarlyStopping(\n",
        "    monitor=\"valid_qwk\",\n",
        "    min_delta=0.00,\n",
        "    patience=50,\n",
        "    verbose=True,\n",
        "    mode=\"max\"\n",
        "    )\n",
        "\n",
        "    callbacks_list = [\n",
        "        model_checkpoint_callback,\n",
        "        early_stop_callback\n",
        "    ]\n",
        "\n",
        "    trainer_competencia = pl.Trainer(\n",
        "        max_epochs=NUM_EPOCHS,\n",
        "        callbacks=callbacks_list,\n",
        "        accelerator=device_type,\n",
        "        devices=1,\n",
        "        logger=logger_competencia,\n",
        "        deterministic=True,\n",
        "        log_every_n_steps=10\n",
        "    )\n",
        "\n",
        "    start_time = time.time()\n",
        "    print(f\"Treinando modelo para Competência {comp_idx}...\", flush=True)\n",
        "    trainer_competencia.fit(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    runtime = (time.time() - start_time)/60\n",
        "    print(f\"Treinamento para Competência {comp_idx} levou {runtime:.2f} min.\", flush=True)\n",
        "\n",
        "    print(f\"Avaliando modelo para Competência {comp_idx} no conjunto de teste...\", flush=True)\n",
        "    test_results = trainer_competencia.test(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    resultados_por_competencia[f'competencia_{comp_idx}'] = test_results[0]\n",
        "\n",
        "    model_path = model_checkpoint_callback.best_model_path\n",
        "    best_model = LightningMLP.load_from_checkpoint(model_path, model=pytorch_model_competencia, learning_rate=LEARNING_RATE)\n",
        "    best_model.eval()\n",
        "\n",
        "    y_pred_list = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_module_competencia.test_dataloader():\n",
        "            features, _ = batch\n",
        "            logits = best_model(features)\n",
        "            probas = torch.sigmoid(logits)\n",
        "            predicted_labels = proba_to_label(probas)\n",
        "            y_pred_list.append(predicted_labels.cpu().numpy())\n",
        "\n",
        "    y_pred = np.hstack(y_pred_list)\n",
        "    y_true = y_test\n",
        "\n",
        "    y_pred_discreto = np.clip(np.round(y_pred), 0, NUM_CLASSES_COMPETENCIA - 1).astype(int)\n",
        "\n",
        "    print(\"--- Relatório de Classificação da Competência \", comp_idx, \" ---\")\n",
        "    print(classification_report(y_true, y_pred_discreto, zero_division=0.0))\n",
        "    print(\"\\n--- Matriz de Confusão da Competência \", comp_idx, \" ---\")\n",
        "    print(confusion_matrix(y_true, y_pred_discreto))\n",
        "\n",
        "    print(f\"--- Modelo para Competência {comp_idx} concluído ---\", flush=True)\n",
        "\n",
        "print(\"\\n--- Todos os modelos de competência foram treinados e avaliados ---\", flush=True)\n",
        "for comp, results in resultados_por_competencia.items():\n",
        "    print(f\"{comp}: QWK = {results['test_qwk']:.4f}, RMSE = {results['test_rmse']:.4f}, HDIV = {1- results['test_enem_acc']:.4f}\", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Treinamento apenas com easy test"
      ],
      "metadata": {
        "id": "r1cKT9MjEuiu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resultados_por_competencia = {}\n",
        "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "for comp_idx in range(1, 6):\n",
        "    print(f\"\\n--- Treinando Modelo para Competência {comp_idx} ---\", flush=True)\n",
        "\n",
        "    X_train = X_train_pure\n",
        "    y_train = df_train[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_val = X_val_pure\n",
        "    y_val = df_val[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_test = X_test_easy_pure\n",
        "    y_test = df_test_easy[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    print(f\"Divisão de dados para Competência {comp_idx}: Treino={X_train.shape}, Validação={X_val.shape}, Teste={X_test.shape}\", flush=True)\n",
        "\n",
        "    scaler_comp = StandardScaler()\n",
        "    X_train_std = scaler_comp.fit_transform(X_train)\n",
        "    X_val_std = scaler_comp.transform(X_val)\n",
        "    X_test_std = scaler_comp.transform(X_test)\n",
        "    print(f\"Features escaladas para Competência {comp_idx}.\", flush=True)\n",
        "\n",
        "    data_module_competencia = CompetenceDataModule(X_train_std, y_train, X_val_std, y_val, X_test_std, y_test, BATCH_SIZE, NUM_WORKERS)\n",
        "    data_module_competencia.setup()\n",
        "\n",
        "    input_dim = X_train_std.shape[1]\n",
        "\n",
        "    pytorch_model_competencia = MultiLayerPerceptron(\n",
        "        input_size=input_dim,\n",
        "        hidden_units=(256, 128, 64),\n",
        "        num_classes=NUM_CLASSES_COMPETENCIA\n",
        "    )\n",
        "    lightning_model_competencia = LightningMLP(\n",
        "        model=pytorch_model_competencia,\n",
        "        learning_rate=LEARNING_RATE\n",
        "    )\n",
        "\n",
        "\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        save_top_k=1, mode=\"min\", monitor=\"valid_mae\",\n",
        "        dirpath=f\"logs_comp_{comp_idx}/\", filename=f\"best_model_comp_{comp_idx}\"\n",
        "    )\n",
        "    logger_competencia = CSVLogger(save_dir=\"logs/\", name=f\"mlp-coral-comp-{comp_idx}\")\n",
        "\n",
        "\n",
        "    early_stop_callback = EarlyStopping(\n",
        "    monitor=\"valid_qwk\",\n",
        "    min_delta=0.00,\n",
        "    patience=50,\n",
        "    verbose=True,\n",
        "    mode=\"max\"\n",
        "    )\n",
        "\n",
        "    callbacks_list = [\n",
        "        model_checkpoint_callback,\n",
        "        early_stop_callback\n",
        "    ]\n",
        "\n",
        "    trainer_competencia = pl.Trainer(\n",
        "        max_epochs=NUM_EPOCHS,\n",
        "        callbacks=callbacks_list,\n",
        "        accelerator=device_type,\n",
        "        devices=1,\n",
        "        logger=logger_competencia,\n",
        "        deterministic=True,\n",
        "        log_every_n_steps=10\n",
        "    )\n",
        "\n",
        "    start_time = time.time()\n",
        "    print(f\"Treinando modelo para Competência {comp_idx}...\", flush=True)\n",
        "    trainer_competencia.fit(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    runtime = (time.time() - start_time)/60\n",
        "    print(f\"Treinamento para Competência {comp_idx} levou {runtime:.2f} min.\", flush=True)\n",
        "\n",
        "    print(f\"Avaliando modelo para Competência {comp_idx} no conjunto de teste...\", flush=True)\n",
        "    test_results = trainer_competencia.test(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    resultados_por_competencia[f'competencia_{comp_idx}'] = test_results[0]\n",
        "\n",
        "    model_path = model_checkpoint_callback.best_model_path\n",
        "    best_model = LightningMLP.load_from_checkpoint(model_path, model=pytorch_model_competencia, learning_rate=LEARNING_RATE)\n",
        "    best_model.eval()\n",
        "\n",
        "    y_pred_list = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_module_competencia.test_dataloader():\n",
        "            features, _ = batch\n",
        "            logits = best_model(features)\n",
        "            probas = torch.sigmoid(logits)\n",
        "            predicted_labels = proba_to_label(probas)\n",
        "            y_pred_list.append(predicted_labels.cpu().numpy())\n",
        "\n",
        "    y_pred = np.hstack(y_pred_list)\n",
        "    y_true = y_test\n",
        "\n",
        "    y_pred_discreto = np.clip(np.round(y_pred), 0, NUM_CLASSES_COMPETENCIA - 1).astype(int)\n",
        "\n",
        "    print(\"--- Relatório de Classificação da Competência \", comp_idx, \" ---\")\n",
        "    print(classification_report(y_true, y_pred_discreto, zero_division=0.0))\n",
        "    print(\"\\n--- Matriz de Confusão da Competência \", comp_idx, \" ---\")\n",
        "    print(confusion_matrix(y_true, y_pred_discreto))\n",
        "\n",
        "    print(f\"--- Modelo para Competência {comp_idx} concluído ---\", flush=True)\n",
        "\n",
        "print(\"\\n--- Todos os modelos de competência foram treinados e avaliados ---\", flush=True)\n",
        "for comp, results in resultados_por_competencia.items():\n",
        "    print(f\"{comp}: QWK = {results['test_qwk']:.4f}, RMSE = {results['test_rmse']:.4f}, HDIV = {1- results['test_enem_acc']:.4f}\", flush=True)"
      ],
      "metadata": {
        "id": "3Q7U4acbEsR2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpR8i-cplwuP"
      },
      "source": [
        "# Murilo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pjX8p6I3lzO0"
      },
      "outputs": [],
      "source": [
        "df_murilo_train = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/df features Murilo/train_murilo.csv\")\n",
        "df_murilo_val = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/df features Murilo/validation_murilo.csv\")\n",
        "df_murilo_test = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/df features Murilo/test_murilo.csv\")\n",
        "df_murilo_test_easy = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/df features Murilo/df_murilo_test_easy.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hAiwHNxd3ZVd"
      },
      "outputs": [],
      "source": [
        "nota_total_col = 'nota_total'\n",
        "competencia_cols = ['nota_c1', 'nota_c2', 'nota_c3', 'nota_c4', 'nota_c5']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PeKXDSGJlCd7"
      },
      "outputs": [],
      "source": [
        "def mapeamento_ordinal(df):\n",
        "    # Dicionário que mapeia a nota real para o valor ordinal\n",
        "    mapeamento_competencia_ordinal = {\n",
        "        0: 0,\n",
        "        40: 1,\n",
        "        80: 2,\n",
        "        120: 3,\n",
        "        160: 4,\n",
        "        200: 5\n",
        "    }\n",
        "\n",
        "    for col_name in competencia_cols:\n",
        "        df[f'{col_name}_ordinal'] = df[col_name].map(mapeamento_competencia_ordinal)\n",
        "    return df\n",
        "\n",
        "df_test = mapeamento_ordinal(df_murilo_test)\n",
        "df_train = mapeamento_ordinal(df_murilo_train)\n",
        "df_val = mapeamento_ordinal(df_murilo_val)\n",
        "df_test_easy = mapeamento_ordinal(df_murilo_test_easy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMckhs72ldIe"
      },
      "outputs": [],
      "source": [
        "def prepare_feature_matrix_pure_handcrafted(df):\n",
        "    \"\"\"\n",
        "    Prepara a matriz de features usando apenas as features artesanais.\n",
        "    \"\"\"\n",
        "\n",
        "    primeira_coluna_metrica = 'n_verbos_e_pronomes_1ps'\n",
        "    ultima_coluna_metrica = 'similaridade_tit_1_constituicao_bertimbau'\n",
        "    colunas_handcrafted_nomes = df.loc[:, primeira_coluna_metrica:ultima_coluna_metrica].columns.tolist()\n",
        "\n",
        "    for col in colunas_handcrafted_nomes:\n",
        "        if col in df.columns and df[col].dtype == 'object':\n",
        "            df[col] = df[col].astype(str).str.replace('.', '', regex=False).str.replace(',', '.', regex=False)\n",
        "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "    handcrafted_features_matrix = df[colunas_handcrafted_nomes].fillna(df[colunas_handcrafted_nomes].mean()).values\n",
        "\n",
        "    X_pure_handcrafted = handcrafted_features_matrix\n",
        "    # print(f\"Matriz de features X_pure_handcrafted pronta. Dimensão: {X_pure_handcrafted.shape}\")\n",
        "\n",
        "    return X_pure_handcrafted\n",
        "\n",
        "# Passo 2: Aplicar a função a cada DataFrame para obter as matrizes X\n",
        "X_train_handcrafted_Murilo = prepare_feature_matrix_pure_handcrafted(df_train)\n",
        "X_val_handcrafted_Murilo = prepare_feature_matrix_pure_handcrafted(df_val)\n",
        "X_test_handcrafted_Murilo = prepare_feature_matrix_pure_handcrafted(df_test)\n",
        "X_test_easy_handcrafted_Murilo = prepare_feature_matrix_pure_handcrafted(df_test_easy)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "treinamento base test inteira"
      ],
      "metadata": {
        "id": "sJs96CZIOzS7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zr3oHbQVlwuQ"
      },
      "outputs": [],
      "source": [
        "resultados_por_competencia = {}\n",
        "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "for comp_idx in range(1, 6):\n",
        "    print(f\"\\n--- Treinando Modelo para Competência {comp_idx} ---\", flush=True)\n",
        "    y_train_series = df_train[f'nota_c{comp_idx}_ordinal']\n",
        "    y_val_series = df_val[f'nota_c{comp_idx}_ordinal']\n",
        "    y_test_series = df_test[f'nota_c{comp_idx}_ordinal']\n",
        "\n",
        "    X_train = X_train_handcrafted_Murilo\n",
        "    y_train = df_train[f'nota_c{comp_idx}_ordinal'].values\n",
        "    y_train = y_train_series.fillna(0).astype(int).values\n",
        "\n",
        "    X_val = X_val_handcrafted_Murilo\n",
        "    y_val = df_val[f'nota_c{comp_idx}_ordinal'].values\n",
        "    y_val = y_val_series.fillna(0).astype(int).values\n",
        "\n",
        "    X_test = X_test_handcrafted_Murilo\n",
        "    y_test = df_test[f'nota_c{comp_idx}_ordinal'].values\n",
        "    y_test = y_test_series.fillna(0).astype(int).values\n",
        "\n",
        "    print(f\"Divisão de dados para Competência {comp_idx}: Treino={X_train.shape}, Validação={X_val.shape}, Teste={X_test.shape}\", flush=True)\n",
        "\n",
        "    scaler_comp = StandardScaler()\n",
        "    X_train_std = scaler_comp.fit_transform(X_train)\n",
        "    X_val_std = scaler_comp.transform(X_val)\n",
        "    X_test_std = scaler_comp.transform(X_test)\n",
        "    print(f\"Features escaladas para Competência {comp_idx}.\", flush=True)\n",
        "\n",
        "    data_module_competencia = CompetenceDataModule(X_train_std, y_train, X_val_std, y_val, X_test_std, y_test, BATCH_SIZE, NUM_WORKERS)\n",
        "    data_module_competencia.setup()\n",
        "\n",
        "    input_dim = X_train_std.shape[1]\n",
        "\n",
        "    pytorch_model_competencia = MultiLayerPerceptron(\n",
        "        input_size=input_dim,\n",
        "        hidden_units=(256, 128, 64),\n",
        "        num_classes=NUM_CLASSES_COMPETENCIA\n",
        "    )\n",
        "    lightning_model_competencia = LightningMLP(\n",
        "        model=pytorch_model_competencia,\n",
        "        learning_rate=LEARNING_RATE\n",
        "    )\n",
        "\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        save_top_k=1, mode=\"min\", monitor=\"valid_mae\",\n",
        "        dirpath=f\"logs_comp_{comp_idx}/\", filename=f\"best_model_comp_{comp_idx}\"\n",
        "    )\n",
        "    logger_competencia = CSVLogger(save_dir=\"logs/\", name=f\"mlp-coral-comp-{comp_idx}\")\n",
        "\n",
        "\n",
        "    early_stop_callback = EarlyStopping(\n",
        "    monitor=\"valid_qwk\",\n",
        "    min_delta=0.00,\n",
        "    patience=50,\n",
        "    verbose=True,\n",
        "    mode=\"max\"\n",
        "    )\n",
        "\n",
        "    callbacks_list = [\n",
        "        model_checkpoint_callback,\n",
        "        early_stop_callback\n",
        "    ]\n",
        "\n",
        "    trainer_competencia = pl.Trainer(\n",
        "        max_epochs=NUM_EPOCHS,\n",
        "        callbacks=callbacks_list,\n",
        "        accelerator=device_type,\n",
        "        devices=1,\n",
        "        logger=logger_competencia,\n",
        "        deterministic=True,\n",
        "        log_every_n_steps=10\n",
        "    )\n",
        "\n",
        "    start_time = time.time()\n",
        "    print(f\"Treinando modelo para Competência {comp_idx}...\", flush=True)\n",
        "    trainer_competencia.fit(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    runtime = (time.time() - start_time)/60\n",
        "    print(f\"Treinamento para Competência {comp_idx} levou {runtime:.2f} min.\", flush=True)\n",
        "\n",
        "    print(f\"Avaliando modelo para Competência {comp_idx} no conjunto de teste...\", flush=True)\n",
        "    test_results = trainer_competencia.test(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    resultados_por_competencia[f'competencia_{comp_idx}'] = test_results[0]\n",
        "\n",
        "    model_path = model_checkpoint_callback.best_model_path\n",
        "    best_model = LightningMLP.load_from_checkpoint(model_path, model=pytorch_model_competencia, learning_rate=LEARNING_RATE)\n",
        "    best_model.eval()\n",
        "\n",
        "    y_pred_list = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_module_competencia.test_dataloader():\n",
        "            features, _ = batch\n",
        "            logits = best_model(features)\n",
        "            probas = torch.sigmoid(logits)\n",
        "            predicted_labels = proba_to_label(probas)\n",
        "            y_pred_list.append(predicted_labels.cpu().numpy())\n",
        "\n",
        "    y_pred = np.hstack(y_pred_list)\n",
        "    y_true = y_test\n",
        "    y_pred_discreto = np.clip(np.round(y_pred), 0, NUM_CLASSES_COMPETENCIA - 1).astype(int)\n",
        "\n",
        "    print(\"--- Relatório de Classificação da Competência \", comp_idx, \" ---\")\n",
        "    print(classification_report(y_true, y_pred_discreto, zero_division=0.0))\n",
        "    print(\"\\n--- Matriz de Confusão da Competência \", comp_idx, \" ---\")\n",
        "    print(confusion_matrix(y_true, y_pred_discreto))\n",
        "\n",
        "    print(f\"--- Modelo para Competência {comp_idx} concluído ---\", flush=True)\n",
        "\n",
        "print(\"\\n--- Todos os modelos de competência foram treinados e avaliados ---\", flush=True)\n",
        "for comp, results in resultados_por_competencia.items():\n",
        "    print(f\"{comp}: QWK = {results['test_qwk']:.4f}, RMSE = {results['test_rmse']:.4f}, HDIV = {1- results['test_enem_acc']:.4f}\", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Treinamento easy test"
      ],
      "metadata": {
        "id": "czEzRsC9O-od"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resultados_por_competencia = {}\n",
        "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "for comp_idx in range(1, 6):\n",
        "    print(f\"\\n--- Treinando Modelo para Competência {comp_idx} ---\", flush=True)\n",
        "    y_train_series = df_train[f'nota_c{comp_idx}_ordinal']\n",
        "    y_val_series = df_val[f'nota_c{comp_idx}_ordinal']\n",
        "    y_test_series = df_test_easy[f'nota_c{comp_idx}_ordinal']\n",
        "\n",
        "    X_train = X_train_handcrafted_Murilo\n",
        "    y_train = df_train[f'nota_c{comp_idx}_ordinal'].values\n",
        "    y_train = y_train_series.fillna(0).astype(int).values\n",
        "\n",
        "    X_val = X_val_handcrafted_Murilo\n",
        "    y_val = df_val[f'nota_c{comp_idx}_ordinal'].values\n",
        "    y_val = y_val_series.fillna(0).astype(int).values\n",
        "\n",
        "    X_test = X_test_easy_handcrafted_Murilo\n",
        "    y_test = df_test_easy[f'nota_c{comp_idx}_ordinal'].values\n",
        "    y_test = y_test_series.fillna(0).astype(int).values\n",
        "\n",
        "    print(f\"Divisão de dados para Competência {comp_idx}: Treino={X_train.shape}, Validação={X_val.shape}, Teste={X_test.shape}\", flush=True)\n",
        "\n",
        "    scaler_comp = StandardScaler()\n",
        "    X_train_std = scaler_comp.fit_transform(X_train)\n",
        "    X_val_std = scaler_comp.transform(X_val)\n",
        "    X_test_std = scaler_comp.transform(X_test)\n",
        "    print(f\"Features escaladas para Competência {comp_idx}.\", flush=True)\n",
        "\n",
        "    data_module_competencia = CompetenceDataModule(X_train_std, y_train, X_val_std, y_val, X_test_std, y_test, BATCH_SIZE, NUM_WORKERS)\n",
        "    data_module_competencia.setup()\n",
        "\n",
        "    input_dim = X_train_std.shape[1]\n",
        "\n",
        "    pytorch_model_competencia = MultiLayerPerceptron(\n",
        "        input_size=input_dim,\n",
        "        hidden_units=(256, 128, 64),\n",
        "        num_classes=NUM_CLASSES_COMPETENCIA\n",
        "    )\n",
        "    lightning_model_competencia = LightningMLP(\n",
        "        model=pytorch_model_competencia,\n",
        "        learning_rate=LEARNING_RATE\n",
        "    )\n",
        "\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        save_top_k=1, mode=\"min\", monitor=\"valid_mae\",\n",
        "        dirpath=f\"logs_comp_{comp_idx}/\", filename=f\"best_model_comp_{comp_idx}\"\n",
        "    )\n",
        "    logger_competencia = CSVLogger(save_dir=\"logs/\", name=f\"mlp-coral-comp-{comp_idx}\")\n",
        "\n",
        "\n",
        "    early_stop_callback = EarlyStopping(\n",
        "    monitor=\"valid_qwk\",\n",
        "    min_delta=0.00,\n",
        "    patience=50,\n",
        "    verbose=True,\n",
        "    mode=\"max\"\n",
        "    )\n",
        "\n",
        "    callbacks_list = [\n",
        "        model_checkpoint_callback,\n",
        "        early_stop_callback\n",
        "    ]\n",
        "\n",
        "    trainer_competencia = pl.Trainer(\n",
        "        max_epochs=NUM_EPOCHS,\n",
        "        callbacks=callbacks_list,\n",
        "        accelerator=device_type,\n",
        "        devices=1,\n",
        "        logger=logger_competencia,\n",
        "        deterministic=True,\n",
        "        log_every_n_steps=10\n",
        "    )\n",
        "\n",
        "    start_time = time.time()\n",
        "    print(f\"Treinando modelo para Competência {comp_idx}...\", flush=True)\n",
        "    trainer_competencia.fit(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    runtime = (time.time() - start_time)/60\n",
        "    print(f\"Treinamento para Competência {comp_idx} levou {runtime:.2f} min.\", flush=True)\n",
        "\n",
        "    print(f\"Avaliando modelo para Competência {comp_idx} no conjunto de teste...\", flush=True)\n",
        "    test_results = trainer_competencia.test(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    resultados_por_competencia[f'competencia_{comp_idx}'] = test_results[0]\n",
        "\n",
        "    model_path = model_checkpoint_callback.best_model_path\n",
        "    best_model = LightningMLP.load_from_checkpoint(model_path, model=pytorch_model_competencia, learning_rate=LEARNING_RATE)\n",
        "    best_model.eval()\n",
        "\n",
        "    y_pred_list = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_module_competencia.test_dataloader():\n",
        "            features, _ = batch\n",
        "            logits = best_model(features)\n",
        "            probas = torch.sigmoid(logits)\n",
        "            predicted_labels = proba_to_label(probas)\n",
        "            y_pred_list.append(predicted_labels.cpu().numpy())\n",
        "\n",
        "    y_pred = np.hstack(y_pred_list)\n",
        "    y_true = y_test\n",
        "    y_pred_discreto = np.clip(np.round(y_pred), 0, NUM_CLASSES_COMPETENCIA - 1).astype(int)\n",
        "\n",
        "    print(\"--- Relatório de Classificação da Competência \", comp_idx, \" ---\")\n",
        "    print(classification_report(y_true, y_pred_discreto, zero_division=0.0))\n",
        "    print(\"\\n--- Matriz de Confusão da Competência \", comp_idx, \" ---\")\n",
        "    print(confusion_matrix(y_true, y_pred_discreto))\n",
        "\n",
        "    print(f\"--- Modelo para Competência {comp_idx} concluído ---\", flush=True)\n",
        "\n",
        "print(\"\\n--- Todos os modelos de competência foram treinados e avaliados ---\", flush=True)\n",
        "for comp, results in resultados_por_competencia.items():\n",
        "    print(f\"{comp}: QWK = {results['test_qwk']:.4f}, RMSE = {results['test_rmse']:.4f}, HDIV = {1- results['test_enem_acc']:.4f}\", flush=True)"
      ],
      "metadata": {
        "id": "aPuWca3TO-Mg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0x03reKDj0n"
      },
      "source": [
        "# TF-IDF + NILC  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_FJEGzC9Flg-"
      },
      "outputs": [],
      "source": [
        "# Importação dos dataframes\n",
        "df_train = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/NILC + Embedding + ORD (final df)/df_train.csv\")\n",
        "df_val = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/NILC + Embedding + ORD (final df)/df_val.csv\")\n",
        "df_test_easy = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/test easy and hard/df_test_easy.csv\")\n",
        "df_test_hard = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/test easy and hard/df_test_hard.csv\")\n",
        "df_test = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/NILC + Embedding + ORD (final df)/df_test.csv\")\n",
        "\n",
        "def prepare_feature_matrix_pure_handcrafted(df):\n",
        "\n",
        "    primeira_coluna_metrica = ' adjective_ratio'\n",
        "    ultima_coluna_metrica = 'ratio_function_to_content_words'\n",
        "    colunas_handcrafted_nomes = df.loc[:, primeira_coluna_metrica:ultima_coluna_metrica].columns.tolist()\n",
        "\n",
        "    for col in colunas_handcrafted_nomes:\n",
        "        if col in df.columns and df[col].dtype == 'object':\n",
        "            df[col] = df[col].astype(str).str.replace('.', '', regex=False).str.replace(',', '.', regex=False)\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "    handcrafted_features_matrix = df[colunas_handcrafted_nomes].fillna(df[colunas_handcrafted_nomes].mean()).values\n",
        "\n",
        "    X_pure_handcrafted = handcrafted_features_matrix\n",
        "    print(f\"Matriz de features X_pure_handcrafted pronta. Dimensão: {X_pure_handcrafted.shape}\")\n",
        "\n",
        "    return X_pure_handcrafted\n",
        "\n",
        "X_train_handcrafted = prepare_feature_matrix_pure_handcrafted(df_train)\n",
        "X_val_handcrafted = prepare_feature_matrix_pure_handcrafted(df_val)\n",
        "X_test_handcrafted = prepare_feature_matrix_pure_handcrafted(df_test)\n",
        "X_test_easy_handcrafted = prepare_feature_matrix_pure_handcrafted(df_test_easy)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Treinamento base teste inteira"
      ],
      "metadata": {
        "id": "0ATnQbzyGsQY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TV4zqxkbFvcV"
      },
      "outputs": [],
      "source": [
        "resultados_por_competencia = {}\n",
        "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "for comp_idx in range(1, 6):\n",
        "    print(f\"\\n--- Treinando Modelo para Competência {comp_idx} ---\", flush=True)\n",
        "\n",
        "    X_train = np.hstack((X_train_handcrafted, X_train_tfidf_final_array))\n",
        "    y_train = df_train[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_val = np.hstack((X_val_handcrafted, X_val_tfidf_final_array))\n",
        "    y_val = df_val[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_test = np.hstack((X_test_handcrafted, X_test_tfidf_final_array))\n",
        "    y_test = df_test[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    print(f\"Divisão de dados para Competência {comp_idx}: Treino={X_train.shape}, Validação={X_val.shape}, Teste={X_test.shape}\", flush=True)\n",
        "\n",
        "    scaler_comp = StandardScaler()\n",
        "    X_train_std = scaler_comp.fit_transform(X_train)\n",
        "    X_val_std = scaler_comp.transform(X_val)\n",
        "    X_test_std = scaler_comp.transform(X_test)\n",
        "    print(f\"Features escaladas para Competência {comp_idx}.\", flush=True)\n",
        "\n",
        "    data_module_competencia = CompetenceDataModule(X_train_std, y_train, X_val_std, y_val, X_test_std, y_test, BATCH_SIZE, NUM_WORKERS)\n",
        "    data_module_competencia.setup()\n",
        "\n",
        "    input_dim = X_train_std.shape[1]\n",
        "\n",
        "    pytorch_model_competencia = MultiLayerPerceptron(\n",
        "        input_size=input_dim,\n",
        "        hidden_units=(256, 128, 64),\n",
        "        num_classes=NUM_CLASSES_COMPETENCIA\n",
        "    )\n",
        "    lightning_model_competencia = LightningMLP(\n",
        "        model=pytorch_model_competencia,\n",
        "        learning_rate=LEARNING_RATE\n",
        "    )\n",
        "\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        save_top_k=1, mode=\"min\", monitor=\"valid_mae\",\n",
        "        dirpath=f\"logs_comp_{comp_idx}/\", filename=f\"best_model_comp_{comp_idx}\"\n",
        "    )\n",
        "    logger_competencia = CSVLogger(save_dir=\"logs/\", name=f\"mlp-coral-comp-{comp_idx}\")\n",
        "\n",
        "\n",
        "    early_stop_callback = EarlyStopping(\n",
        "    monitor=\"valid_qwk\",\n",
        "    min_delta=0.00,\n",
        "    patience=50,\n",
        "    verbose=True,\n",
        "    mode=\"max\"\n",
        "    )\n",
        "\n",
        "    callbacks_list = [\n",
        "        model_checkpoint_callback,\n",
        "        early_stop_callback\n",
        "    ]\n",
        "\n",
        "    trainer_competencia = pl.Trainer(\n",
        "        max_epochs=NUM_EPOCHS,\n",
        "        callbacks=callbacks_list,\n",
        "        accelerator=device_type,\n",
        "        devices=1,\n",
        "        logger=logger_competencia,\n",
        "        deterministic=True,\n",
        "        log_every_n_steps=10\n",
        "    )\n",
        "\n",
        "    start_time = time.time()\n",
        "    print(f\"Treinando modelo para Competência {comp_idx}...\", flush=True)\n",
        "    trainer_competencia.fit(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    runtime = (time.time() - start_time)/60\n",
        "    print(f\"Treinamento para Competência {comp_idx} levou {runtime:.2f} min.\", flush=True)\n",
        "\n",
        "    print(f\"Avaliando modelo para Competência {comp_idx} no conjunto de teste...\", flush=True)\n",
        "    test_results = trainer_competencia.test(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    resultados_por_competencia[f'competencia_{comp_idx}'] = test_results[0]\n",
        "\n",
        "    model_path = model_checkpoint_callback.best_model_path\n",
        "    best_model = LightningMLP.load_from_checkpoint(model_path, model=pytorch_model_competencia, learning_rate=LEARNING_RATE)\n",
        "    best_model.eval()\n",
        "\n",
        "    y_pred_list = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_module_competencia.test_dataloader():\n",
        "            features, _ = batch\n",
        "            logits = best_model(features)\n",
        "            probas = torch.sigmoid(logits)\n",
        "            predicted_labels = proba_to_label(probas)\n",
        "            y_pred_list.append(predicted_labels.cpu().numpy())\n",
        "\n",
        "    y_pred = np.hstack(y_pred_list)\n",
        "    y_true = y_test\n",
        "\n",
        "    y_pred_discreto = np.clip(np.round(y_pred), 0, NUM_CLASSES_COMPETENCIA - 1).astype(int)\n",
        "\n",
        "    print(\"--- Relatório de Classificação da Competência \", comp_idx, \" ---\")\n",
        "    print(classification_report(y_true, y_pred_discreto, zero_division=0.0))\n",
        "    print(\"\\n--- Matriz de Confusão da Competência \", comp_idx, \" ---\")\n",
        "    print(confusion_matrix(y_true, y_pred_discreto))\n",
        "\n",
        "    print(f\"--- Modelo para Competência {comp_idx} concluído ---\", flush=True)\n",
        "\n",
        "print(\"\\n--- Todos os modelos de competência foram treinados e avaliados ---\", flush=True)\n",
        "for comp, results in resultados_por_competencia.items():\n",
        "    print(f\"{comp}: QWK = {results['test_qwk']:.4f}, RMSE = {results['test_rmse']:.4f}, HDIV = {1- results['test_enem_acc']:.4f}\", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Treinamento teste easy"
      ],
      "metadata": {
        "id": "ePXcUUVuGz9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resultados_por_competencia = {}\n",
        "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "for comp_idx in range(1, 6):\n",
        "    print(f\"\\n--- Treinando Modelo para Competência {comp_idx} ---\", flush=True)\n",
        "\n",
        "    X_train = np.hstack((X_train_handcrafted, X_train_tfidf_final_array))\n",
        "    y_train = df_train[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_val = np.hstack((X_val_handcrafted, X_val_tfidf_final_array))\n",
        "    y_val = df_val[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_test = np.hstack((X_test_easy_handcrafted, X_test_easy_tfidf_final_array))\n",
        "    y_test = df_test_easy[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    print(f\"Divisão de dados para Competência {comp_idx}: Treino={X_train.shape}, Validação={X_val.shape}, Teste={X_test.shape}\", flush=True)\n",
        "\n",
        "    scaler_comp = StandardScaler()\n",
        "    X_train_std = scaler_comp.fit_transform(X_train)\n",
        "    X_val_std = scaler_comp.transform(X_val)\n",
        "    X_test_std = scaler_comp.transform(X_test)\n",
        "    print(f\"Features escaladas para Competência {comp_idx}.\", flush=True)\n",
        "\n",
        "    data_module_competencia = CompetenceDataModule(X_train_std, y_train, X_val_std, y_val, X_test_std, y_test, BATCH_SIZE, NUM_WORKERS)\n",
        "    data_module_competencia.setup()\n",
        "\n",
        "    input_dim = X_train_std.shape[1]\n",
        "\n",
        "    pytorch_model_competencia = MultiLayerPerceptron(\n",
        "        input_size=input_dim,\n",
        "        hidden_units=(256, 128, 64),\n",
        "        num_classes=NUM_CLASSES_COMPETENCIA\n",
        "    )\n",
        "    lightning_model_competencia = LightningMLP(\n",
        "        model=pytorch_model_competencia,\n",
        "        learning_rate=LEARNING_RATE\n",
        "    )\n",
        "\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        save_top_k=1, mode=\"min\", monitor=\"valid_mae\",\n",
        "        dirpath=f\"logs_comp_{comp_idx}/\", filename=f\"best_model_comp_{comp_idx}\"\n",
        "    )\n",
        "    logger_competencia = CSVLogger(save_dir=\"logs/\", name=f\"mlp-coral-comp-{comp_idx}\")\n",
        "\n",
        "\n",
        "    early_stop_callback = EarlyStopping(\n",
        "    monitor=\"valid_qwk\",\n",
        "    min_delta=0.00,\n",
        "    patience=50,\n",
        "    verbose=True,\n",
        "    mode=\"max\"\n",
        "    )\n",
        "\n",
        "    callbacks_list = [\n",
        "        model_checkpoint_callback,\n",
        "        early_stop_callback\n",
        "    ]\n",
        "\n",
        "    trainer_competencia = pl.Trainer(\n",
        "        max_epochs=NUM_EPOCHS,\n",
        "        callbacks=callbacks_list,\n",
        "        accelerator=device_type,\n",
        "        devices=1,\n",
        "        logger=logger_competencia,\n",
        "        deterministic=True,\n",
        "        log_every_n_steps=10\n",
        "    )\n",
        "\n",
        "    start_time = time.time()\n",
        "    print(f\"Treinando modelo para Competência {comp_idx}...\", flush=True)\n",
        "    trainer_competencia.fit(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    runtime = (time.time() - start_time)/60\n",
        "    print(f\"Treinamento para Competência {comp_idx} levou {runtime:.2f} min.\", flush=True)\n",
        "\n",
        "    print(f\"Avaliando modelo para Competência {comp_idx} no conjunto de teste...\", flush=True)\n",
        "    test_results = trainer_competencia.test(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    resultados_por_competencia[f'competencia_{comp_idx}'] = test_results[0]\n",
        "\n",
        "    model_path = model_checkpoint_callback.best_model_path\n",
        "    best_model = LightningMLP.load_from_checkpoint(model_path, model=pytorch_model_competencia, learning_rate=LEARNING_RATE)\n",
        "    best_model.eval()\n",
        "\n",
        "    y_pred_list = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_module_competencia.test_dataloader():\n",
        "            features, _ = batch\n",
        "            logits = best_model(features)\n",
        "            probas = torch.sigmoid(logits)\n",
        "            predicted_labels = proba_to_label(probas)\n",
        "            y_pred_list.append(predicted_labels.cpu().numpy())\n",
        "\n",
        "    y_pred = np.hstack(y_pred_list)\n",
        "    y_true = y_test\n",
        "\n",
        "    y_pred_discreto = np.clip(np.round(y_pred), 0, NUM_CLASSES_COMPETENCIA - 1).astype(int)\n",
        "\n",
        "    print(\"--- Relatório de Classificação da Competência \", comp_idx, \" ---\")\n",
        "    print(classification_report(y_true, y_pred_discreto, zero_division=0.0))\n",
        "    print(\"\\n--- Matriz de Confusão da Competência \", comp_idx, \" ---\")\n",
        "    print(confusion_matrix(y_true, y_pred_discreto))\n",
        "\n",
        "    print(f\"--- Modelo para Competência {comp_idx} concluído ---\", flush=True)\n",
        "\n",
        "print(\"\\n--- Todos os modelos de competência foram treinados e avaliados ---\", flush=True)\n",
        "for comp, results in resultados_por_competencia.items():\n",
        "    print(f\"{comp}: QWK = {results['test_qwk']:.4f}, RMSE = {results['test_rmse']:.4f}, HDIV = {1- results['test_enem_acc']:.4f}\", flush=True)"
      ],
      "metadata": {
        "id": "ZC4YRsiVG2o8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Xhzol4FS3jp"
      },
      "source": [
        "# TF-IDF + BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G20j6wxkS-Ff"
      },
      "outputs": [],
      "source": [
        "# # Importação dos dataframes\n",
        "# df_train = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/NILC + Embedding + ORD (final df)/df_train.csv\")\n",
        "# df_val = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/NILC + Embedding + ORD (final df)/df_val.csv\")\n",
        "# df_test_easy = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/test easy and hard/df_test_easy.csv\")\n",
        "# df_test_hard = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/test easy and hard/df_test_hard.csv\")\n",
        "# df_test = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/NILC + Embedding + ORD (final df)/df_test.csv\")\n",
        "\n",
        "# def prepare_feature_matrix_pure_bert(df):\n",
        "#     df['bert_embedding'] = df['bert_embedding'].apply(\n",
        "#         lambda x: np.array(ast.literal_eval(re.sub(r'\\s+', ',', str(x).strip('[]')).strip(',')))\n",
        "#         if pd.notna(x) and isinstance(x, str) and x.strip() else np.zeros(768)\n",
        "#     )\n",
        "#     bert_embeddings_matrix = np.stack(df['bert_embedding'].values)\n",
        "\n",
        "#     X_pure_bert = bert_embeddings_matrix\n",
        "#     print(f\"Matriz de features X_pure_bert pronta. Dimensão: {X_pure_bert.shape}\")\n",
        "\n",
        "#     return X_pure_bert\n",
        "# X_train_pure = prepare_feature_matrix_pure_bert(df_train)\n",
        "# X_val_pure = prepare_feature_matrix_pure_bert(df_val)\n",
        "# X_test_pure = prepare_feature_matrix_pure_bert(df_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Treinamento com a base teste inteira"
      ],
      "metadata": {
        "id": "kGA8US-6I8rc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8NtVCXCTC4f",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "resultados_por_competencia = {}\n",
        "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "for comp_idx in range(1, 6):\n",
        "    print(f\"\\n--- Treinando Modelo para Competência {comp_idx} ---\", flush=True)\n",
        "\n",
        "    X_train = np.hstack((X_train_pure, X_train_tfidf_final_array))\n",
        "    y_train = df_train[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_val = np.hstack((X_val_pure, X_val_tfidf_final_array))\n",
        "    y_val = df_val[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_test = np.hstack((X_test_pure, X_test_tfidf_final_array))\n",
        "    y_test = df_test[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    print(f\"Divisão de dados para Competência {comp_idx}: Treino={X_train.shape}, Validação={X_val.shape}, Teste={X_test.shape}\", flush=True)\n",
        "\n",
        "    scaler_comp = StandardScaler()\n",
        "    X_train_std = scaler_comp.fit_transform(X_train)\n",
        "    X_val_std = scaler_comp.transform(X_val)\n",
        "    X_test_std = scaler_comp.transform(X_test)\n",
        "    print(f\"Features escaladas para Competência {comp_idx}.\", flush=True)\n",
        "\n",
        "    data_module_competencia = CompetenceDataModule(X_train_std, y_train, X_val_std, y_val, X_test_std, y_test, BATCH_SIZE, NUM_WORKERS)\n",
        "    data_module_competencia.setup()\n",
        "\n",
        "    input_dim = X_train_std.shape[1]\n",
        "\n",
        "    pytorch_model_competencia = MultiLayerPerceptron(\n",
        "        input_size=input_dim,\n",
        "        hidden_units=(256, 128, 64),\n",
        "        num_classes=NUM_CLASSES_COMPETENCIA\n",
        "    )\n",
        "    lightning_model_competencia = LightningMLP(\n",
        "        model=pytorch_model_competencia,\n",
        "        learning_rate=LEARNING_RATE\n",
        "    )\n",
        "\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        save_top_k=1, mode=\"min\", monitor=\"valid_mae\",\n",
        "        dirpath=f\"logs_comp_{comp_idx}/\", filename=f\"best_model_comp_{comp_idx}\"\n",
        "    )\n",
        "    logger_competencia = CSVLogger(save_dir=\"logs/\", name=f\"mlp-coral-comp-{comp_idx}\")\n",
        "\n",
        "\n",
        "    early_stop_callback = EarlyStopping(\n",
        "    monitor=\"valid_qwk\",\n",
        "    min_delta=0.00,\n",
        "    patience=50,\n",
        "    verbose=True,\n",
        "    mode=\"max\"\n",
        "    )\n",
        "\n",
        "    callbacks_list = [\n",
        "        model_checkpoint_callback,\n",
        "        early_stop_callback\n",
        "    ]\n",
        "\n",
        "    trainer_competencia = pl.Trainer(\n",
        "        max_epochs=NUM_EPOCHS,\n",
        "        callbacks=callbacks_list,\n",
        "        accelerator=device_type,\n",
        "        devices=1,\n",
        "        logger=logger_competencia,\n",
        "        deterministic=True,\n",
        "        log_every_n_steps=10\n",
        "    )\n",
        "\n",
        "    start_time = time.time()\n",
        "    print(f\"Treinando modelo para Competência {comp_idx}...\", flush=True)\n",
        "    trainer_competencia.fit(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    runtime = (time.time() - start_time)/60\n",
        "    print(f\"Treinamento para Competência {comp_idx} levou {runtime:.2f} min.\", flush=True)\n",
        "\n",
        "    print(f\"Avaliando modelo para Competência {comp_idx} no conjunto de teste...\", flush=True)\n",
        "    test_results = trainer_competencia.test(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    resultados_por_competencia[f'competencia_{comp_idx}'] = test_results[0]\n",
        "\n",
        "    model_path = model_checkpoint_callback.best_model_path\n",
        "    best_model = LightningMLP.load_from_checkpoint(model_path, model=pytorch_model_competencia, learning_rate=LEARNING_RATE)\n",
        "    best_model.eval()\n",
        "\n",
        "    y_pred_list = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_module_competencia.test_dataloader():\n",
        "            features, _ = batch\n",
        "            logits = best_model(features)\n",
        "            probas = torch.sigmoid(logits)\n",
        "            predicted_labels = proba_to_label(probas)\n",
        "            y_pred_list.append(predicted_labels.cpu().numpy())\n",
        "\n",
        "    y_pred = np.hstack(y_pred_list)\n",
        "    y_true = y_test\n",
        "    y_pred_discreto = np.clip(np.round(y_pred), 0, NUM_CLASSES_COMPETENCIA - 1).astype(int)\n",
        "\n",
        "    print(\"--- Relatório de Classificação da Competência \", comp_idx, \" ---\")\n",
        "    print(classification_report(y_true, y_pred_discreto, zero_division=0.0))\n",
        "    print(\"\\n--- Matriz de Confusão da Competência \", comp_idx, \" ---\")\n",
        "    print(confusion_matrix(y_true, y_pred_discreto))\n",
        "\n",
        "    print(f\"--- Modelo para Competência {comp_idx} concluído ---\", flush=True)\n",
        "\n",
        "print(\"\\n--- Todos os modelos de competência foram treinados e avaliados ---\", flush=True)\n",
        "for comp, results in resultados_por_competencia.items():\n",
        "    print(f\"{comp}: QWK = {results['test_qwk']:.4f}, RMSE = {results['test_rmse']:.4f}, HDIV = {1- results['test_enem_acc']:.4f}\", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Treinamento com teste easy"
      ],
      "metadata": {
        "id": "9F4MeGXZJI9n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resultados_por_competencia = {}\n",
        "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "for comp_idx in range(1, 6):\n",
        "    print(f\"\\n--- Treinando Modelo para Competência {comp_idx} ---\", flush=True)\n",
        "\n",
        "    X_train = np.hstack((X_train_pure, X_train_tfidf_final_array))\n",
        "    y_train = df_train[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_val = np.hstack((X_val_pure, X_val_tfidf_final_array))\n",
        "    y_val = df_val[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_test = np.hstack((X_test_easy_pure, X_test_easy_tfidf_final_array))\n",
        "    y_test = df_test_easy[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    print(f\"Divisão de dados para Competência {comp_idx}: Treino={X_train.shape}, Validação={X_val.shape}, Teste={X_test.shape}\", flush=True)\n",
        "\n",
        "    scaler_comp = StandardScaler()\n",
        "    X_train_std = scaler_comp.fit_transform(X_train)\n",
        "    X_val_std = scaler_comp.transform(X_val)\n",
        "    X_test_std = scaler_comp.transform(X_test)\n",
        "    print(f\"Features escaladas para Competência {comp_idx}.\", flush=True)\n",
        "\n",
        "    data_module_competencia = CompetenceDataModule(X_train_std, y_train, X_val_std, y_val, X_test_std, y_test, BATCH_SIZE, NUM_WORKERS)\n",
        "    data_module_competencia.setup()\n",
        "\n",
        "    input_dim = X_train_std.shape[1]\n",
        "\n",
        "    pytorch_model_competencia = MultiLayerPerceptron(\n",
        "        input_size=input_dim,\n",
        "        hidden_units=(256, 128, 64),\n",
        "        num_classes=NUM_CLASSES_COMPETENCIA\n",
        "    )\n",
        "    lightning_model_competencia = LightningMLP(\n",
        "        model=pytorch_model_competencia,\n",
        "        learning_rate=LEARNING_RATE\n",
        "    )\n",
        "\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        save_top_k=1, mode=\"min\", monitor=\"valid_mae\",\n",
        "        dirpath=f\"logs_comp_{comp_idx}/\", filename=f\"best_model_comp_{comp_idx}\"\n",
        "    )\n",
        "    logger_competencia = CSVLogger(save_dir=\"logs/\", name=f\"mlp-coral-comp-{comp_idx}\")\n",
        "\n",
        "\n",
        "    early_stop_callback = EarlyStopping(\n",
        "    monitor=\"valid_qwk\",\n",
        "    min_delta=0.00,\n",
        "    patience=50,\n",
        "    verbose=True,\n",
        "    mode=\"max\"\n",
        "    )\n",
        "\n",
        "    callbacks_list = [\n",
        "        model_checkpoint_callback,\n",
        "        early_stop_callback\n",
        "    ]\n",
        "\n",
        "    trainer_competencia = pl.Trainer(\n",
        "        max_epochs=NUM_EPOCHS,\n",
        "        callbacks=callbacks_list,\n",
        "        accelerator=device_type,\n",
        "        devices=1,\n",
        "        logger=logger_competencia,\n",
        "        deterministic=True,\n",
        "        log_every_n_steps=10\n",
        "    )\n",
        "\n",
        "    start_time = time.time()\n",
        "    print(f\"Treinando modelo para Competência {comp_idx}...\", flush=True)\n",
        "    trainer_competencia.fit(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    runtime = (time.time() - start_time)/60\n",
        "    print(f\"Treinamento para Competência {comp_idx} levou {runtime:.2f} min.\", flush=True)\n",
        "\n",
        "    print(f\"Avaliando modelo para Competência {comp_idx} no conjunto de teste...\", flush=True)\n",
        "    test_results = trainer_competencia.test(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    resultados_por_competencia[f'competencia_{comp_idx}'] = test_results[0]\n",
        "\n",
        "    model_path = model_checkpoint_callback.best_model_path\n",
        "    best_model = LightningMLP.load_from_checkpoint(model_path, model=pytorch_model_competencia, learning_rate=LEARNING_RATE)\n",
        "    best_model.eval()\n",
        "\n",
        "    y_pred_list = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_module_competencia.test_dataloader():\n",
        "            features, _ = batch\n",
        "            logits = best_model(features)\n",
        "            probas = torch.sigmoid(logits)\n",
        "            predicted_labels = proba_to_label(probas)\n",
        "            y_pred_list.append(predicted_labels.cpu().numpy())\n",
        "\n",
        "    y_pred = np.hstack(y_pred_list)\n",
        "    y_true = y_test\n",
        "    y_pred_discreto = np.clip(np.round(y_pred), 0, NUM_CLASSES_COMPETENCIA - 1).astype(int)\n",
        "\n",
        "    print(\"--- Relatório de Classificação da Competência \", comp_idx, \" ---\")\n",
        "    print(classification_report(y_true, y_pred_discreto, zero_division=0.0))\n",
        "    print(\"\\n--- Matriz de Confusão da Competência \", comp_idx, \" ---\")\n",
        "    print(confusion_matrix(y_true, y_pred_discreto))\n",
        "    print(f\"--- Modelo para Competência {comp_idx} concluído ---\", flush=True)\n",
        "\n",
        "print(\"\\n--- Todos os modelos de competência foram treinados e avaliados ---\", flush=True)\n",
        "for comp, results in resultados_por_competencia.items():\n",
        "    print(f\"{comp}: QWK = {results['test_qwk']:.4f}, RMSE = {results['test_rmse']:.4f}, HDIV = {1- results['test_enem_acc']:.4f}\", flush=True)"
      ],
      "metadata": {
        "id": "7CTqQdvrJLEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icNvU_I1zj6x"
      },
      "source": [
        "# TF-IDF + Murilo"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Treinamento base test inteira"
      ],
      "metadata": {
        "id": "PBUSQlGwPldF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "NwMbDfMQQue9"
      },
      "outputs": [],
      "source": [
        "# df_train = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_train.csv\")\n",
        "# df_val = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_validation.csv\")\n",
        "# df_test = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_test.csv\")\n",
        "\n",
        "\n",
        "resultados_por_competencia = {}\n",
        "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "for comp_idx in range(1, 6):\n",
        "    print(f\"\\n--- Treinando Modelo para Competência {comp_idx} ---\", flush=True)\n",
        "\n",
        "    X_train = np.hstack((X_train_handcrafted_Murilo, X_train_tfidf_final_array))\n",
        "    y_train = df_train[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_val = np.hstack((X_val_handcrafted_Murilo, X_val_tfidf_final_array))\n",
        "    y_val = df_val[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_test = np.hstack((X_test_handcrafted_Murilo, X_test_tfidf_final_array))\n",
        "    y_test = df_test[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    print(f\"Divisão de dados para Competência {comp_idx}: Treino={X_train.shape}, Validação={X_val.shape}, Teste={X_test.shape}\", flush=True)\n",
        "\n",
        "    scaler_comp = StandardScaler()\n",
        "    X_train_std = scaler_comp.fit_transform(X_train)\n",
        "    X_val_std = scaler_comp.transform(X_val)\n",
        "    X_test_std = scaler_comp.transform(X_test)\n",
        "    print(f\"Features escaladas para Competência {comp_idx}.\", flush=True)\n",
        "\n",
        "    data_module_competencia = CompetenceDataModule(X_train_std, y_train, X_val_std, y_val, X_test_std, y_test, BATCH_SIZE, NUM_WORKERS)\n",
        "    data_module_competencia.setup()\n",
        "\n",
        "    input_dim = X_train_std.shape[1]\n",
        "\n",
        "    pytorch_model_competencia = MultiLayerPerceptron(\n",
        "        input_size=input_dim,\n",
        "        hidden_units=(256, 128, 64),\n",
        "        num_classes=NUM_CLASSES_COMPETENCIA\n",
        "    )\n",
        "    lightning_model_competencia = LightningMLP(\n",
        "        model=pytorch_model_competencia,\n",
        "        learning_rate=LEARNING_RATE\n",
        "    )\n",
        "\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        save_top_k=1, mode=\"min\", monitor=\"valid_mae\",\n",
        "        dirpath=f\"logs_comp_{comp_idx}/\", filename=f\"best_model_comp_{comp_idx}\"\n",
        "    )\n",
        "    logger_competencia = CSVLogger(save_dir=\"logs/\", name=f\"mlp-coral-comp-{comp_idx}\")\n",
        "\n",
        "\n",
        "    early_stop_callback = EarlyStopping(\n",
        "    monitor=\"valid_qwk\",\n",
        "    min_delta=0.00,\n",
        "    patience=50,\n",
        "    verbose=True,\n",
        "    mode=\"max\"\n",
        "    )\n",
        "\n",
        "    callbacks_list = [\n",
        "        model_checkpoint_callback,\n",
        "        early_stop_callback\n",
        "    ]\n",
        "\n",
        "    trainer_competencia = pl.Trainer(\n",
        "        max_epochs=NUM_EPOCHS,\n",
        "        callbacks=callbacks_list,\n",
        "        accelerator=device_type,\n",
        "        devices=1,\n",
        "        logger=logger_competencia,\n",
        "        deterministic=True,\n",
        "        log_every_n_steps=10\n",
        "    )\n",
        "\n",
        "    start_time = time.time()\n",
        "    print(f\"Treinando modelo para Competência {comp_idx}...\", flush=True)\n",
        "    trainer_competencia.fit(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    runtime = (time.time() - start_time)/60\n",
        "    print(f\"Treinamento para Competência {comp_idx} levou {runtime:.2f} min.\", flush=True)\n",
        "\n",
        "    print(f\"Avaliando modelo para Competência {comp_idx} no conjunto de teste...\", flush=True)\n",
        "    test_results = trainer_competencia.test(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    resultados_por_competencia[f'competencia_{comp_idx}'] = test_results[0]\n",
        "\n",
        "    model_path = model_checkpoint_callback.best_model_path\n",
        "    best_model = LightningMLP.load_from_checkpoint(model_path, model=pytorch_model_competencia, learning_rate=LEARNING_RATE)\n",
        "    best_model.eval()\n",
        "\n",
        "    y_pred_list = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_module_competencia.test_dataloader():\n",
        "            features, _ = batch\n",
        "            logits = best_model(features)\n",
        "            probas = torch.sigmoid(logits)\n",
        "            predicted_labels = proba_to_label(probas)\n",
        "            y_pred_list.append(predicted_labels.cpu().numpy())\n",
        "\n",
        "    y_pred = np.hstack(y_pred_list)\n",
        "    y_true = y_test\n",
        "    y_pred_discreto = np.clip(np.round(y_pred), 0, NUM_CLASSES_COMPETENCIA - 1).astype(int)\n",
        "\n",
        "    print(\"--- Relatório de Classificação da Competência \", comp_idx, \" ---\")\n",
        "    print(classification_report(y_true, y_pred_discreto, zero_division=0.0))\n",
        "    print(\"\\n--- Matriz de Confusão da Competência \", comp_idx, \" ---\")\n",
        "    print(confusion_matrix(y_true, y_pred_discreto))\n",
        "\n",
        "    print(f\"--- Modelo para Competência {comp_idx} concluído ---\", flush=True)\n",
        "\n",
        "print(\"\\n--- Todos os modelos de competência foram treinados e avaliados ---\", flush=True)\n",
        "for comp, results in resultados_por_competencia.items():\n",
        "    print(f\"{comp}: QWK = {results['test_qwk']:.4f}, RMSE = {results['test_rmse']:.4f}, HDIV = {1- results['test_enem_acc']:.4f}\", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "treinamento easy test"
      ],
      "metadata": {
        "id": "_aHCA2xYPtIt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# df_train = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_train.csv\")\n",
        "# df_val = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_validation.csv\")\n",
        "# df_test = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_test.csv\")\n",
        "\n",
        "\n",
        "resultados_por_competencia = {}\n",
        "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "for comp_idx in range(1, 6):\n",
        "    print(f\"\\n--- Treinando Modelo para Competência {comp_idx} ---\", flush=True)\n",
        "\n",
        "    X_train = np.hstack((X_train_handcrafted_Murilo, X_train_tfidf_final_array))\n",
        "    y_train = df_train[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_val = np.hstack((X_val_handcrafted_Murilo, X_val_tfidf_final_array))\n",
        "    y_val = df_val[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_test = np.hstack((X_test_easy_handcrafted_Murilo, X_test_easy_tfidf_final_array))\n",
        "    y_test = df_test_easy[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    print(f\"Divisão de dados para Competência {comp_idx}: Treino={X_train.shape}, Validação={X_val.shape}, Teste={X_test.shape}\", flush=True)\n",
        "\n",
        "    scaler_comp = StandardScaler()\n",
        "    X_train_std = scaler_comp.fit_transform(X_train)\n",
        "    X_val_std = scaler_comp.transform(X_val)\n",
        "    X_test_std = scaler_comp.transform(X_test)\n",
        "    print(f\"Features escaladas para Competência {comp_idx}.\", flush=True)\n",
        "\n",
        "    data_module_competencia = CompetenceDataModule(X_train_std, y_train, X_val_std, y_val, X_test_std, y_test, BATCH_SIZE, NUM_WORKERS)\n",
        "    data_module_competencia.setup()\n",
        "\n",
        "    input_dim = X_train_std.shape[1]\n",
        "\n",
        "    pytorch_model_competencia = MultiLayerPerceptron(\n",
        "        input_size=input_dim,\n",
        "        hidden_units=(256, 128, 64),\n",
        "        num_classes=NUM_CLASSES_COMPETENCIA\n",
        "    )\n",
        "    lightning_model_competencia = LightningMLP(\n",
        "        model=pytorch_model_competencia,\n",
        "        learning_rate=LEARNING_RATE\n",
        "    )\n",
        "\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        save_top_k=1, mode=\"min\", monitor=\"valid_mae\",\n",
        "        dirpath=f\"logs_comp_{comp_idx}/\", filename=f\"best_model_comp_{comp_idx}\"\n",
        "    )\n",
        "    logger_competencia = CSVLogger(save_dir=\"logs/\", name=f\"mlp-coral-comp-{comp_idx}\")\n",
        "\n",
        "\n",
        "    early_stop_callback = EarlyStopping(\n",
        "    monitor=\"valid_qwk\",\n",
        "    min_delta=0.00,\n",
        "    patience=50,\n",
        "    verbose=True,\n",
        "    mode=\"max\"\n",
        "    )\n",
        "\n",
        "    callbacks_list = [\n",
        "        model_checkpoint_callback,\n",
        "        early_stop_callback\n",
        "    ]\n",
        "\n",
        "    trainer_competencia = pl.Trainer(\n",
        "        max_epochs=NUM_EPOCHS,\n",
        "        callbacks=callbacks_list,\n",
        "        accelerator=device_type,\n",
        "        devices=1,\n",
        "        logger=logger_competencia,\n",
        "        deterministic=True,\n",
        "        log_every_n_steps=10\n",
        "    )\n",
        "\n",
        "    start_time = time.time()\n",
        "    print(f\"Treinando modelo para Competência {comp_idx}...\", flush=True)\n",
        "    trainer_competencia.fit(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    runtime = (time.time() - start_time)/60\n",
        "    print(f\"Treinamento para Competência {comp_idx} levou {runtime:.2f} min.\", flush=True)\n",
        "\n",
        "    print(f\"Avaliando modelo para Competência {comp_idx} no conjunto de teste...\", flush=True)\n",
        "    test_results = trainer_competencia.test(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    resultados_por_competencia[f'competencia_{comp_idx}'] = test_results[0]\n",
        "\n",
        "    model_path = model_checkpoint_callback.best_model_path\n",
        "    best_model = LightningMLP.load_from_checkpoint(model_path, model=pytorch_model_competencia, learning_rate=LEARNING_RATE)\n",
        "    best_model.eval()\n",
        "\n",
        "    y_pred_list = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_module_competencia.test_dataloader():\n",
        "            features, _ = batch\n",
        "            logits = best_model(features)\n",
        "            probas = torch.sigmoid(logits)\n",
        "            predicted_labels = proba_to_label(probas)\n",
        "            y_pred_list.append(predicted_labels.cpu().numpy())\n",
        "\n",
        "    y_pred = np.hstack(y_pred_list)\n",
        "    y_true = y_test\n",
        "    y_pred_discreto = np.clip(np.round(y_pred), 0, NUM_CLASSES_COMPETENCIA - 1).astype(int)\n",
        "\n",
        "    print(\"--- Relatório de Classificação da Competência \", comp_idx, \" ---\")\n",
        "    print(classification_report(y_true, y_pred_discreto, zero_division=0.0))\n",
        "    print(\"\\n--- Matriz de Confusão da Competência \", comp_idx, \" ---\")\n",
        "    print(confusion_matrix(y_true, y_pred_discreto))\n",
        "\n",
        "    print(f\"--- Modelo para Competência {comp_idx} concluído ---\", flush=True)\n",
        "\n",
        "print(\"\\n--- Todos os modelos de competência foram treinados e avaliados ---\", flush=True)\n",
        "for comp, results in resultados_por_competencia.items():\n",
        "    print(f\"{comp}: QWK = {results['test_qwk']:.4f}, RMSE = {results['test_rmse']:.4f}, HDIV = {1- results['test_enem_acc']:.4f}\", flush=True)"
      ],
      "metadata": {
        "id": "YDbibFjwPr0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9Qj8PYb-PjP"
      },
      "source": [
        "# NILC + BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XNlCSucwKxQa"
      },
      "outputs": [],
      "source": [
        "# Importação dos dataframes\n",
        "df_train = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/NILC + Embedding + ORD (final df)/df_train.csv\")\n",
        "df_val = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/NILC + Embedding + ORD (final df)/df_val.csv\")\n",
        "df_test_easy = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/test easy and hard/df_test_easy.csv\")\n",
        "df_test_hard = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/test easy and hard/df_test_hard.csv\")\n",
        "df_test = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/NILC + Embedding + ORD (final df)/df_test.csv\")\n",
        "\n",
        "def prepare_feature_matrix(df):\n",
        "    df['bert_embedding'] = df['bert_embedding'].apply(\n",
        "        lambda x: np.array(ast.literal_eval(re.sub(r'\\s+', ',', str(x).strip('[]')).strip(',')))\n",
        "        if pd.notna(x) and isinstance(x, str) and x.strip() else np.zeros(768)\n",
        "    )\n",
        "    bert_embeddings_matrix = np.stack(df['bert_embedding'].values)\n",
        "\n",
        "    primeira_coluna_metrica = ' adjective_ratio'\n",
        "    ultima_coluna_metrica = 'ratio_function_to_content_words'\n",
        "    colunas_handcrafted_nomes = df.loc[:, primeira_coluna_metrica:ultima_coluna_metrica].columns.tolist()\n",
        "\n",
        "    for col in colunas_handcrafted_nomes:\n",
        "        if col in df.columns and df[col].dtype == 'object':\n",
        "            df[col] = df[col].astype(str).str.replace('.', '', regex=False).str.replace(',', '.', regex=False)\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "    handcrafted_features_matrix = df[colunas_handcrafted_nomes].fillna(df[colunas_handcrafted_nomes].mean()).values\n",
        "\n",
        "    X_combined = np.hstack((bert_embeddings_matrix, handcrafted_features_matrix))\n",
        "    print(f\"Matriz de features X_combined pronta. Dimensão: {X_combined.shape}\")\n",
        "\n",
        "    return X_combined\n",
        "\n",
        "X_train_combined = prepare_feature_matrix(df_train)\n",
        "X_val_combined = prepare_feature_matrix(df_val)\n",
        "X_test_combined = prepare_feature_matrix(df_test)\n",
        "X_test_easy_combined = prepare_feature_matrix(df_test_easy)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "treinamento base teste inteira"
      ],
      "metadata": {
        "id": "BVw4gDVnKevt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nsX0KXqd9IR"
      },
      "outputs": [],
      "source": [
        "resultados_por_competencia = {}\n",
        "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\" #\n",
        "\n",
        "for comp_idx in range(1, 6):\n",
        "    print(f\"\\n--- Treinando Modelo para Competência {comp_idx} ---\", flush=True)\n",
        "\n",
        "    X_train = X_train_combined\n",
        "    y_train = df_train[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_val = X_val_combined\n",
        "    y_val = df_val[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_test = X_test_combined\n",
        "    y_test = df_test[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    print(f\"Divisão de dados para Competência {comp_idx}: Treino={X_train.shape}, Validação={X_val.shape}, Teste={X_test.shape}\", flush=True)\n",
        "\n",
        "    scaler_comp = StandardScaler()\n",
        "    X_train_std = scaler_comp.fit_transform(X_train)\n",
        "    X_val_std = scaler_comp.transform(X_val)\n",
        "    X_test_std = scaler_comp.transform(X_test)\n",
        "    print(f\"Features escaladas para Competência {comp_idx}.\", flush=True)\n",
        "\n",
        "    data_module_competencia = CompetenceDataModule(X_train_std, y_train, X_val_std, y_val, X_test_std, y_test, BATCH_SIZE, NUM_WORKERS)\n",
        "    data_module_competencia.setup()\n",
        "\n",
        "    input_dim = X_train_std.shape[1]\n",
        "\n",
        "    pytorch_model_competencia = MultiLayerPerceptron(\n",
        "        input_size=input_dim,\n",
        "        hidden_units=(256, 128, 64),\n",
        "        num_classes=NUM_CLASSES_COMPETENCIA\n",
        "    )\n",
        "    lightning_model_competencia = LightningMLP(\n",
        "        model=pytorch_model_competencia,\n",
        "        learning_rate=LEARNING_RATE\n",
        "    )\n",
        "\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        save_top_k=1, mode=\"min\", monitor=\"valid_mae\",\n",
        "        dirpath=f\"logs_comp_{comp_idx}/\", filename=f\"best_model_comp_{comp_idx}\"\n",
        "    )\n",
        "    logger_competencia = CSVLogger(save_dir=\"logs/\", name=f\"mlp-coral-comp-{comp_idx}\")\n",
        "\n",
        "\n",
        "    early_stop_callback = EarlyStopping(\n",
        "    monitor=\"valid_qwk\",\n",
        "    min_delta=0.00,\n",
        "    patience=50,\n",
        "    verbose=True,\n",
        "    mode=\"max\"\n",
        "    )\n",
        "\n",
        "    callbacks_list = [\n",
        "        model_checkpoint_callback,\n",
        "        early_stop_callback\n",
        "    ]\n",
        "\n",
        "    trainer_competencia = pl.Trainer(\n",
        "        max_epochs=NUM_EPOCHS,\n",
        "        callbacks=callbacks_list,\n",
        "        accelerator=device_type,\n",
        "        devices=1,\n",
        "        logger=logger_competencia,\n",
        "        deterministic=True,\n",
        "        log_every_n_steps=10\n",
        "    )\n",
        "\n",
        "    start_time = time.time()\n",
        "    print(f\"Treinando modelo para Competência {comp_idx}...\", flush=True)\n",
        "    trainer_competencia.fit(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    runtime = (time.time() - start_time)/60\n",
        "    print(f\"Treinamento para Competência {comp_idx} levou {runtime:.2f} min.\", flush=True)\n",
        "\n",
        "    print(f\"Avaliando modelo para Competência {comp_idx} no conjunto de teste...\", flush=True)\n",
        "    test_results = trainer_competencia.test(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    resultados_por_competencia[f'competencia_{comp_idx}'] = test_results[0]\n",
        "\n",
        "    model_path = model_checkpoint_callback.best_model_path\n",
        "    best_model = LightningMLP.load_from_checkpoint(model_path, model=pytorch_model_competencia, learning_rate=LEARNING_RATE)\n",
        "    best_model.eval()\n",
        "\n",
        "    y_pred_list = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_module_competencia.test_dataloader():\n",
        "            features, _ = batch\n",
        "            logits = best_model(features)\n",
        "            probas = torch.sigmoid(logits)\n",
        "            predicted_labels = proba_to_label(probas)\n",
        "            y_pred_list.append(predicted_labels.cpu().numpy())\n",
        "\n",
        "    y_pred = np.hstack(y_pred_list)\n",
        "    y_true = y_test\n",
        "\n",
        "    y_pred_discreto = np.clip(np.round(y_pred), 0, NUM_CLASSES_COMPETENCIA - 1).astype(int)\n",
        "\n",
        "    print(\"--- Relatório de Classificação da Competência \", comp_idx, \" ---\")\n",
        "    print(classification_report(y_true, y_pred_discreto, zero_division=0.0))\n",
        "    print(\"\\n--- Matriz de Confusão da Competência \", comp_idx, \" ---\")\n",
        "    print(confusion_matrix(y_true, y_pred_discreto))\n",
        "\n",
        "    print(f\"--- Modelo para Competência {comp_idx} concluído ---\", flush=True)\n",
        "\n",
        "print(\"\\n--- Todos os modelos de competência foram treinados e avaliados ---\", flush=True)\n",
        "for comp, results in resultados_por_competencia.items():\n",
        "    print(f\"{comp}: QWK = {results['test_qwk']:.4f}, RMSE = {results['test_rmse']:.4f}, HDIV = {1- results['test_enem_acc']:.4f}\", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "treinamento base easy"
      ],
      "metadata": {
        "id": "7l-NBG09Km-Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resultados_por_competencia = {}\n",
        "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\" #\n",
        "\n",
        "for comp_idx in range(1, 6):\n",
        "    print(f\"\\n--- Treinando Modelo para Competência {comp_idx} ---\", flush=True)\n",
        "\n",
        "    X_train = X_train_combined\n",
        "    y_train = df_train[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_val = X_val_combined\n",
        "    y_val = df_val[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_test = X_test_easy_combined\n",
        "    y_test = df_test_easy[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    print(f\"Divisão de dados para Competência {comp_idx}: Treino={X_train.shape}, Validação={X_val.shape}, Teste={X_test.shape}\", flush=True)\n",
        "\n",
        "    scaler_comp = StandardScaler()\n",
        "    X_train_std = scaler_comp.fit_transform(X_train)\n",
        "    X_val_std = scaler_comp.transform(X_val)\n",
        "    X_test_std = scaler_comp.transform(X_test)\n",
        "    print(f\"Features escaladas para Competência {comp_idx}.\", flush=True)\n",
        "\n",
        "    data_module_competencia = CompetenceDataModule(X_train_std, y_train, X_val_std, y_val, X_test_std, y_test, BATCH_SIZE, NUM_WORKERS)\n",
        "    data_module_competencia.setup()\n",
        "\n",
        "    input_dim = X_train_std.shape[1]\n",
        "\n",
        "    pytorch_model_competencia = MultiLayerPerceptron(\n",
        "        input_size=input_dim,\n",
        "        hidden_units=(256, 128, 64),\n",
        "        num_classes=NUM_CLASSES_COMPETENCIA\n",
        "    )\n",
        "    lightning_model_competencia = LightningMLP(\n",
        "        model=pytorch_model_competencia,\n",
        "        learning_rate=LEARNING_RATE\n",
        "    )\n",
        "\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        save_top_k=1, mode=\"min\", monitor=\"valid_mae\",\n",
        "        dirpath=f\"logs_comp_{comp_idx}/\", filename=f\"best_model_comp_{comp_idx}\"\n",
        "    )\n",
        "    logger_competencia = CSVLogger(save_dir=\"logs/\", name=f\"mlp-coral-comp-{comp_idx}\")\n",
        "\n",
        "\n",
        "    early_stop_callback = EarlyStopping(\n",
        "    monitor=\"valid_qwk\",\n",
        "    min_delta=0.00,\n",
        "    patience=50,\n",
        "    verbose=True,\n",
        "    mode=\"max\"\n",
        "    )\n",
        "\n",
        "    callbacks_list = [\n",
        "        model_checkpoint_callback,\n",
        "        early_stop_callback\n",
        "    ]\n",
        "\n",
        "    trainer_competencia = pl.Trainer(\n",
        "        max_epochs=NUM_EPOCHS,\n",
        "        callbacks=callbacks_list,\n",
        "        accelerator=device_type,\n",
        "        devices=1,\n",
        "        logger=logger_competencia,\n",
        "        deterministic=True,\n",
        "        log_every_n_steps=10\n",
        "    )\n",
        "\n",
        "    start_time = time.time()\n",
        "    print(f\"Treinando modelo para Competência {comp_idx}...\", flush=True)\n",
        "    trainer_competencia.fit(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    runtime = (time.time() - start_time)/60\n",
        "    print(f\"Treinamento para Competência {comp_idx} levou {runtime:.2f} min.\", flush=True)\n",
        "\n",
        "    print(f\"Avaliando modelo para Competência {comp_idx} no conjunto de teste...\", flush=True)\n",
        "    test_results = trainer_competencia.test(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    resultados_por_competencia[f'competencia_{comp_idx}'] = test_results[0]\n",
        "\n",
        "    model_path = model_checkpoint_callback.best_model_path\n",
        "    best_model = LightningMLP.load_from_checkpoint(model_path, model=pytorch_model_competencia, learning_rate=LEARNING_RATE)\n",
        "    best_model.eval()\n",
        "\n",
        "    y_pred_list = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_module_competencia.test_dataloader():\n",
        "            features, _ = batch\n",
        "            logits = best_model(features)\n",
        "            probas = torch.sigmoid(logits)\n",
        "            predicted_labels = proba_to_label(probas)\n",
        "            y_pred_list.append(predicted_labels.cpu().numpy())\n",
        "\n",
        "    y_pred = np.hstack(y_pred_list)\n",
        "    y_true = y_test\n",
        "\n",
        "    y_pred_discreto = np.clip(np.round(y_pred), 0, NUM_CLASSES_COMPETENCIA - 1).astype(int)\n",
        "\n",
        "    print(\"--- Relatório de Classificação da Competência \", comp_idx, \" ---\")\n",
        "    print(classification_report(y_true, y_pred_discreto, zero_division=0.0))\n",
        "    print(\"\\n--- Matriz de Confusão da Competência \", comp_idx, \" ---\")\n",
        "    print(confusion_matrix(y_true, y_pred_discreto))\n",
        "\n",
        "    print(f\"--- Modelo para Competência {comp_idx} concluído ---\", flush=True)\n",
        "\n",
        "print(\"\\n--- Todos os modelos de competência foram treinados e avaliados ---\", flush=True)\n",
        "for comp, results in resultados_por_competencia.items():\n",
        "    print(f\"{comp}: QWK = {results['test_qwk']:.4f}, RMSE = {results['test_rmse']:.4f}, HDIV = {1- results['test_enem_acc']:.4f}\", flush=True)"
      ],
      "metadata": {
        "id": "XqJ0SjTPKtaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2Q4PcRc1xYz"
      },
      "source": [
        "# NILC + Murilo"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "treinamento base test inteira"
      ],
      "metadata": {
        "id": "aoHlAXo2P9he"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gcVCOpw7kQoJ"
      },
      "outputs": [],
      "source": [
        "# df_train = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_train.csv\")\n",
        "# df_val = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_validation.csv\")\n",
        "# df_test = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_test.csv\")\n",
        "\n",
        "resultados_por_competencia = {}\n",
        "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "for comp_idx in range(1, 6):\n",
        "    print(f\"\\n--- Treinando Modelo para Competência {comp_idx} ---\", flush=True)\n",
        "\n",
        "    X_train = np.hstack((X_train_handcrafted, X_train_handcrafted_Murilo))\n",
        "    y_train = df_train[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_val = np.hstack((X_val_handcrafted, X_val_handcrafted_Murilo))\n",
        "    y_val = df_val[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_test = np.hstack((X_test_handcrafted, X_test_handcrafted_Murilo))\n",
        "    y_test = df_test[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    print(f\"Divisão de dados para Competência {comp_idx}: Treino={X_train.shape}, Validação={X_val.shape}, Teste={X_test.shape}\", flush=True)\n",
        "\n",
        "    scaler_comp = StandardScaler()\n",
        "    X_train_std = scaler_comp.fit_transform(X_train)\n",
        "    X_val_std = scaler_comp.transform(X_val)\n",
        "    X_test_std = scaler_comp.transform(X_test)\n",
        "    print(f\"Features escaladas para Competência {comp_idx}.\", flush=True)\n",
        "\n",
        "    data_module_competencia = CompetenceDataModule(X_train_std, y_train, X_val_std, y_val, X_test_std, y_test, BATCH_SIZE, NUM_WORKERS)\n",
        "    data_module_competencia.setup()\n",
        "\n",
        "    input_dim = X_train_std.shape[1]\n",
        "\n",
        "    pytorch_model_competencia = MultiLayerPerceptron(\n",
        "        input_size=input_dim,\n",
        "        hidden_units=(256, 128, 64),\n",
        "        num_classes=NUM_CLASSES_COMPETENCIA\n",
        "    )\n",
        "    lightning_model_competencia = LightningMLP(\n",
        "        model=pytorch_model_competencia,\n",
        "        learning_rate=LEARNING_RATE\n",
        "    )\n",
        "\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        save_top_k=1, mode=\"min\", monitor=\"valid_mae\",\n",
        "        dirpath=f\"logs_comp_{comp_idx}/\", filename=f\"best_model_comp_{comp_idx}\"\n",
        "    )\n",
        "    logger_competencia = CSVLogger(save_dir=\"logs/\", name=f\"mlp-coral-comp-{comp_idx}\")\n",
        "\n",
        "\n",
        "    early_stop_callback = EarlyStopping(\n",
        "    monitor=\"valid_qwk\",\n",
        "    min_delta=0.00,\n",
        "    patience=50,\n",
        "    verbose=True,\n",
        "    mode=\"max\"\n",
        "    )\n",
        "\n",
        "    callbacks_list = [\n",
        "        model_checkpoint_callback,\n",
        "        early_stop_callback\n",
        "    ]\n",
        "\n",
        "    trainer_competencia = pl.Trainer(\n",
        "        max_epochs=NUM_EPOCHS,\n",
        "        callbacks=callbacks_list,\n",
        "        accelerator=device_type,\n",
        "        devices=1,\n",
        "        logger=logger_competencia,\n",
        "        deterministic=True,\n",
        "        log_every_n_steps=10\n",
        "    )\n",
        "\n",
        "    start_time = time.time()\n",
        "    print(f\"Treinando modelo para Competência {comp_idx}...\", flush=True)\n",
        "    trainer_competencia.fit(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    runtime = (time.time() - start_time)/60\n",
        "    print(f\"Treinamento para Competência {comp_idx} levou {runtime:.2f} min.\", flush=True)\n",
        "\n",
        "    print(f\"Avaliando modelo para Competência {comp_idx} no conjunto de teste...\", flush=True)\n",
        "    test_results = trainer_competencia.test(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    resultados_por_competencia[f'competencia_{comp_idx}'] = test_results[0]\n",
        "\n",
        "    model_path = model_checkpoint_callback.best_model_path\n",
        "    best_model = LightningMLP.load_from_checkpoint(model_path, model=pytorch_model_competencia, learning_rate=LEARNING_RATE)\n",
        "    best_model.eval()\n",
        "\n",
        "    y_pred_list = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_module_competencia.test_dataloader():\n",
        "            features, _ = batch\n",
        "            logits = best_model(features)\n",
        "            probas = torch.sigmoid(logits)\n",
        "            predicted_labels = proba_to_label(probas)\n",
        "            y_pred_list.append(predicted_labels.cpu().numpy())\n",
        "\n",
        "    y_pred = np.hstack(y_pred_list)\n",
        "    y_true = y_test\n",
        "\n",
        "    y_pred_discreto = np.clip(np.round(y_pred), 0, NUM_CLASSES_COMPETENCIA - 1).astype(int)\n",
        "\n",
        "    print(\"--- Relatório de Classificação da Competência \", comp_idx, \" ---\")\n",
        "    print(classification_report(y_true, y_pred_discreto, zero_division=0.0))\n",
        "    print(\"\\n--- Matriz de Confusão da Competência \", comp_idx, \" ---\")\n",
        "    print(confusion_matrix(y_true, y_pred_discreto))\n",
        "    print(f\"--- Modelo para Competência {comp_idx} concluído ---\", flush=True)\n",
        "\n",
        "print(\"\\n--- Todos os modelos de competência foram treinados e avaliados ---\", flush=True)\n",
        "for comp, results in resultados_por_competencia.items():\n",
        "    print(f\"{comp}: QWK = {results['test_qwk']:.4f}, RMSE = {results['test_rmse']:.4f}, HDIV = {1- results['test_enem_acc']:.4f}\", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "treinamento easy test"
      ],
      "metadata": {
        "id": "zIQJ7xalQHUu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# df_train = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_train.csv\")\n",
        "# df_val = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_validation.csv\")\n",
        "# df_test = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_test.csv\")\n",
        "\n",
        "resultados_por_competencia = {}\n",
        "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "for comp_idx in range(1, 6):\n",
        "    print(f\"\\n--- Treinando Modelo para Competência {comp_idx} ---\", flush=True)\n",
        "\n",
        "    X_train = np.hstack((X_train_handcrafted, X_train_handcrafted_Murilo))\n",
        "    y_train = df_train[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_val = np.hstack((X_val_handcrafted, X_val_handcrafted_Murilo))\n",
        "    y_val = df_val[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_test = np.hstack((X_test_easy_handcrafted, X_test_easy_handcrafted_Murilo))\n",
        "    y_test = df_test_easy[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    print(f\"Divisão de dados para Competência {comp_idx}: Treino={X_train.shape}, Validação={X_val.shape}, Teste={X_test.shape}\", flush=True)\n",
        "\n",
        "    scaler_comp = StandardScaler()\n",
        "    X_train_std = scaler_comp.fit_transform(X_train)\n",
        "    X_val_std = scaler_comp.transform(X_val)\n",
        "    X_test_std = scaler_comp.transform(X_test)\n",
        "    print(f\"Features escaladas para Competência {comp_idx}.\", flush=True)\n",
        "\n",
        "    data_module_competencia = CompetenceDataModule(X_train_std, y_train, X_val_std, y_val, X_test_std, y_test, BATCH_SIZE, NUM_WORKERS)\n",
        "    data_module_competencia.setup()\n",
        "\n",
        "    input_dim = X_train_std.shape[1]\n",
        "\n",
        "    pytorch_model_competencia = MultiLayerPerceptron(\n",
        "        input_size=input_dim,\n",
        "        hidden_units=(256, 128, 64),\n",
        "        num_classes=NUM_CLASSES_COMPETENCIA\n",
        "    )\n",
        "    lightning_model_competencia = LightningMLP(\n",
        "        model=pytorch_model_competencia,\n",
        "        learning_rate=LEARNING_RATE\n",
        "    )\n",
        "\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        save_top_k=1, mode=\"min\", monitor=\"valid_mae\",\n",
        "        dirpath=f\"logs_comp_{comp_idx}/\", filename=f\"best_model_comp_{comp_idx}\"\n",
        "    )\n",
        "    logger_competencia = CSVLogger(save_dir=\"logs/\", name=f\"mlp-coral-comp-{comp_idx}\")\n",
        "\n",
        "\n",
        "    early_stop_callback = EarlyStopping(\n",
        "    monitor=\"valid_qwk\",\n",
        "    min_delta=0.00,\n",
        "    patience=50,\n",
        "    verbose=True,\n",
        "    mode=\"max\"\n",
        "    )\n",
        "\n",
        "    callbacks_list = [\n",
        "        model_checkpoint_callback,\n",
        "        early_stop_callback\n",
        "    ]\n",
        "\n",
        "    trainer_competencia = pl.Trainer(\n",
        "        max_epochs=NUM_EPOCHS,\n",
        "        callbacks=callbacks_list,\n",
        "        accelerator=device_type,\n",
        "        devices=1,\n",
        "        logger=logger_competencia,\n",
        "        deterministic=True,\n",
        "        log_every_n_steps=10\n",
        "    )\n",
        "\n",
        "    start_time = time.time()\n",
        "    print(f\"Treinando modelo para Competência {comp_idx}...\", flush=True)\n",
        "    trainer_competencia.fit(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    runtime = (time.time() - start_time)/60\n",
        "    print(f\"Treinamento para Competência {comp_idx} levou {runtime:.2f} min.\", flush=True)\n",
        "\n",
        "    print(f\"Avaliando modelo para Competência {comp_idx} no conjunto de teste...\", flush=True)\n",
        "    test_results = trainer_competencia.test(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    resultados_por_competencia[f'competencia_{comp_idx}'] = test_results[0]\n",
        "\n",
        "    model_path = model_checkpoint_callback.best_model_path\n",
        "    best_model = LightningMLP.load_from_checkpoint(model_path, model=pytorch_model_competencia, learning_rate=LEARNING_RATE)\n",
        "    best_model.eval()\n",
        "\n",
        "    y_pred_list = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_module_competencia.test_dataloader():\n",
        "            features, _ = batch\n",
        "            logits = best_model(features)\n",
        "            probas = torch.sigmoid(logits)\n",
        "            predicted_labels = proba_to_label(probas)\n",
        "            y_pred_list.append(predicted_labels.cpu().numpy())\n",
        "\n",
        "    y_pred = np.hstack(y_pred_list)\n",
        "    y_true = y_test\n",
        "\n",
        "    y_pred_discreto = np.clip(np.round(y_pred), 0, NUM_CLASSES_COMPETENCIA - 1).astype(int)\n",
        "\n",
        "    print(\"--- Relatório de Classificação da Competência \", comp_idx, \" ---\")\n",
        "    print(classification_report(y_true, y_pred_discreto, zero_division=0.0))\n",
        "    print(\"\\n--- Matriz de Confusão da Competência \", comp_idx, \" ---\")\n",
        "    print(confusion_matrix(y_true, y_pred_discreto))\n",
        "\n",
        "    print(f\"--- Modelo para Competência {comp_idx} concluído ---\", flush=True)\n",
        "\n",
        "print(\"\\n--- Todos os modelos de competência foram treinados e avaliados ---\", flush=True)\n",
        "for comp, results in resultados_por_competencia.items():\n",
        "    print(f\"{comp}: QWK = {results['test_qwk']:.4f}, RMSE = {results['test_rmse']:.4f}, HDIV = {1- results['test_enem_acc']:.4f}\", flush=True)"
      ],
      "metadata": {
        "id": "LzVuU8mBQLLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5VKkj742HSt"
      },
      "source": [
        "# BERT + Murilo"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "treinamento base test inteira"
      ],
      "metadata": {
        "id": "FFa8_ZIRQtcW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "peE0gWSYlFv3"
      },
      "outputs": [],
      "source": [
        "# df_train = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_train.csv\")\n",
        "# df_val = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_validation.csv\")\n",
        "# df_test = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_test.csv\")\n",
        "\n",
        "resultados_por_competencia = {}\n",
        "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "for comp_idx in range(1, 6):\n",
        "    print(f\"\\n--- Treinando Modelo para Competência {comp_idx} ---\", flush=True)\n",
        "\n",
        "    X_train = np.hstack((X_train_pure, X_train_handcrafted_Murilo))\n",
        "    y_train = df_train[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_val = np.hstack((X_val_pure, X_val_handcrafted_Murilo))\n",
        "    y_val = df_val[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_test = np.hstack((X_test_pure, X_test_handcrafted_Murilo))\n",
        "    y_test = df_test[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    print(f\"Divisão de dados para Competência {comp_idx}: Treino={X_train.shape}, Validação={X_val.shape}, Teste={X_test.shape}\", flush=True)\n",
        "\n",
        "    scaler_comp = StandardScaler()\n",
        "    X_train_std = scaler_comp.fit_transform(X_train)\n",
        "    X_val_std = scaler_comp.transform(X_val)\n",
        "    X_test_std = scaler_comp.transform(X_test)\n",
        "    print(f\"Features escaladas para Competência {comp_idx}.\", flush=True)\n",
        "\n",
        "    data_module_competencia = CompetenceDataModule(X_train_std, y_train, X_val_std, y_val, X_test_std, y_test, BATCH_SIZE, NUM_WORKERS)\n",
        "    data_module_competencia.setup()\n",
        "\n",
        "    input_dim = X_train_std.shape[1]\n",
        "\n",
        "    pytorch_model_competencia = MultiLayerPerceptron(\n",
        "        input_size=input_dim,\n",
        "        hidden_units=(256, 128, 64),\n",
        "        num_classes=NUM_CLASSES_COMPETENCIA\n",
        "    )\n",
        "    lightning_model_competencia = LightningMLP(\n",
        "        model=pytorch_model_competencia,\n",
        "        learning_rate=LEARNING_RATE\n",
        "    )\n",
        "\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        save_top_k=1, mode=\"min\", monitor=\"valid_mae\",\n",
        "        dirpath=f\"logs_comp_{comp_idx}/\", filename=f\"best_model_comp_{comp_idx}\"\n",
        "    )\n",
        "    logger_competencia = CSVLogger(save_dir=\"logs/\", name=f\"mlp-coral-comp-{comp_idx}\")\n",
        "\n",
        "\n",
        "    early_stop_callback = EarlyStopping(\n",
        "    monitor=\"valid_qwk\",\n",
        "    min_delta=0.00,\n",
        "    patience=50,\n",
        "    verbose=True,\n",
        "    mode=\"max\"\n",
        "    )\n",
        "\n",
        "\n",
        "    callbacks_list = [\n",
        "        model_checkpoint_callback,\n",
        "        early_stop_callback\n",
        "    ]\n",
        "\n",
        "    trainer_competencia = pl.Trainer(\n",
        "        max_epochs=NUM_EPOCHS,\n",
        "        callbacks=callbacks_list,\n",
        "        accelerator=device_type,\n",
        "        devices=1,\n",
        "        logger=logger_competencia,\n",
        "        deterministic=True,\n",
        "        log_every_n_steps=10\n",
        "    )\n",
        "\n",
        "\n",
        "    start_time = time.time()\n",
        "    print(f\"Treinando modelo para Competência {comp_idx}...\", flush=True)\n",
        "    trainer_competencia.fit(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    runtime = (time.time() - start_time)/60\n",
        "    print(f\"Treinamento para Competência {comp_idx} levou {runtime:.2f} min.\", flush=True)\n",
        "\n",
        "\n",
        "    print(f\"Avaliando modelo para Competência {comp_idx} no conjunto de teste...\", flush=True)\n",
        "    test_results = trainer_competencia.test(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    resultados_por_competencia[f'competencia_{comp_idx}'] = test_results[0]\n",
        "    model_path = model_checkpoint_callback.best_model_path\n",
        "    best_model = LightningMLP.load_from_checkpoint(model_path, model=pytorch_model_competencia, learning_rate=LEARNING_RATE)\n",
        "    best_model.eval()\n",
        "\n",
        "    y_pred_list = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_module_competencia.test_dataloader():\n",
        "            features, _ = batch\n",
        "            logits = best_model(features)\n",
        "            probas = torch.sigmoid(logits)\n",
        "            predicted_labels = proba_to_label(probas)\n",
        "            y_pred_list.append(predicted_labels.cpu().numpy())\n",
        "\n",
        "    y_pred = np.hstack(y_pred_list)\n",
        "    y_true = y_test\n",
        "    y_pred_discreto = np.clip(np.round(y_pred), 0, NUM_CLASSES_COMPETENCIA - 1).astype(int)\n",
        "\n",
        "    print(\"--- Relatório de Classificação da Competência \", comp_idx, \" ---\")\n",
        "    print(classification_report(y_true, y_pred_discreto, zero_division=0.0))\n",
        "    print(\"\\n--- Matriz de Confusão da Competência \", comp_idx, \" ---\")\n",
        "    print(confusion_matrix(y_true, y_pred_discreto))\n",
        "\n",
        "    print(f\"--- Modelo para Competência {comp_idx} concluído ---\", flush=True)\n",
        "\n",
        "print(\"\\n--- Todos os modelos de competência foram treinados e avaliados ---\", flush=True)\n",
        "for comp, results in resultados_por_competencia.items():\n",
        "    print(f\"{comp}: QWK = {results['test_qwk']:.4f}, RMSE = {results['test_rmse']:.4f}, HDIV = {1- results['test_enem_acc']:.4f}\", flush=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#treinamento easy test"
      ],
      "metadata": {
        "id": "TpIhc_lpQyet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_train = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_train.csv\")\n",
        "# df_val = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_validation.csv\")\n",
        "# df_test = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_test.csv\")\n",
        "\n",
        "resultados_por_competencia = {}\n",
        "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "for comp_idx in range(1, 6):\n",
        "    print(f\"\\n--- Treinando Modelo para Competência {comp_idx} ---\", flush=True)\n",
        "\n",
        "    X_train = np.hstack((X_train_pure, X_train_handcrafted_Murilo))\n",
        "    y_train = df_train[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_val = np.hstack((X_val_pure, X_val_handcrafted_Murilo))\n",
        "    y_val = df_val[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_test = np.hstack((X_test_easy_pure, X_test_easy_handcrafted_Murilo))\n",
        "    y_test = df_test_easy[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    print(f\"Divisão de dados para Competência {comp_idx}: Treino={X_train.shape}, Validação={X_val.shape}, Teste={X_test.shape}\", flush=True)\n",
        "\n",
        "    scaler_comp = StandardScaler()\n",
        "    X_train_std = scaler_comp.fit_transform(X_train)\n",
        "    X_val_std = scaler_comp.transform(X_val)\n",
        "    X_test_std = scaler_comp.transform(X_test)\n",
        "    print(f\"Features escaladas para Competência {comp_idx}.\", flush=True)\n",
        "\n",
        "    data_module_competencia = CompetenceDataModule(X_train_std, y_train, X_val_std, y_val, X_test_std, y_test, BATCH_SIZE, NUM_WORKERS)\n",
        "    data_module_competencia.setup()\n",
        "\n",
        "    input_dim = X_train_std.shape[1]\n",
        "\n",
        "    pytorch_model_competencia = MultiLayerPerceptron(\n",
        "        input_size=input_dim,\n",
        "        hidden_units=(256, 128, 64),\n",
        "        num_classes=NUM_CLASSES_COMPETENCIA\n",
        "    )\n",
        "    lightning_model_competencia = LightningMLP(\n",
        "        model=pytorch_model_competencia,\n",
        "        learning_rate=LEARNING_RATE\n",
        "    )\n",
        "\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        save_top_k=1, mode=\"min\", monitor=\"valid_mae\",\n",
        "        dirpath=f\"logs_comp_{comp_idx}/\", filename=f\"best_model_comp_{comp_idx}\"\n",
        "    )\n",
        "    logger_competencia = CSVLogger(save_dir=\"logs/\", name=f\"mlp-coral-comp-{comp_idx}\")\n",
        "\n",
        "\n",
        "    early_stop_callback = EarlyStopping(\n",
        "    monitor=\"valid_qwk\",\n",
        "    min_delta=0.00,\n",
        "    patience=50,\n",
        "    verbose=True,\n",
        "    mode=\"max\"\n",
        "    )\n",
        "\n",
        "\n",
        "    callbacks_list = [\n",
        "        model_checkpoint_callback,\n",
        "        early_stop_callback\n",
        "    ]\n",
        "\n",
        "    trainer_competencia = pl.Trainer(\n",
        "        max_epochs=NUM_EPOCHS,\n",
        "        callbacks=callbacks_list,\n",
        "        accelerator=device_type,\n",
        "        devices=1,\n",
        "        logger=logger_competencia,\n",
        "        deterministic=True,\n",
        "        log_every_n_steps=10\n",
        "    )\n",
        "\n",
        "\n",
        "    start_time = time.time()\n",
        "    print(f\"Treinando modelo para Competência {comp_idx}...\", flush=True)\n",
        "    trainer_competencia.fit(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    runtime = (time.time() - start_time)/60\n",
        "    print(f\"Treinamento para Competência {comp_idx} levou {runtime:.2f} min.\", flush=True)\n",
        "\n",
        "\n",
        "    print(f\"Avaliando modelo para Competência {comp_idx} no conjunto de teste...\", flush=True)\n",
        "    test_results = trainer_competencia.test(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    resultados_por_competencia[f'competencia_{comp_idx}'] = test_results[0]\n",
        "    model_path = model_checkpoint_callback.best_model_path\n",
        "    best_model = LightningMLP.load_from_checkpoint(model_path, model=pytorch_model_competencia, learning_rate=LEARNING_RATE)\n",
        "    best_model.eval()\n",
        "\n",
        "    y_pred_list = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_module_competencia.test_dataloader():\n",
        "            features, _ = batch\n",
        "            logits = best_model(features)\n",
        "            probas = torch.sigmoid(logits)\n",
        "            predicted_labels = proba_to_label(probas)\n",
        "            y_pred_list.append(predicted_labels.cpu().numpy())\n",
        "\n",
        "    y_pred = np.hstack(y_pred_list)\n",
        "    y_true = y_test\n",
        "    y_pred_discreto = np.clip(np.round(y_pred), 0, NUM_CLASSES_COMPETENCIA - 1).astype(int)\n",
        "\n",
        "    print(\"--- Relatório de Classificação da Competência \", comp_idx, \" ---\")\n",
        "    print(classification_report(y_true, y_pred_discreto, zero_division=0.0))\n",
        "    print(\"\\n--- Matriz de Confusão da Competência \", comp_idx, \" ---\")\n",
        "    print(confusion_matrix(y_true, y_pred_discreto))\n",
        "\n",
        "    print(f\"--- Modelo para Competência {comp_idx} concluído ---\", flush=True)\n",
        "\n",
        "print(\"\\n--- Todos os modelos de competência foram treinados e avaliados ---\", flush=True)\n",
        "for comp, results in resultados_por_competencia.items():\n",
        "    print(f\"{comp}: QWK = {results['test_qwk']:.4f}, RMSE = {results['test_rmse']:.4f}, HDIV = {1- results['test_enem_acc']:.4f}\", flush=True)"
      ],
      "metadata": {
        "id": "icpe48oBQ16g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKVQ_fbTN7XN"
      },
      "source": [
        "# TF-IDF + NILC + BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5pc_LcxaOLEt"
      },
      "outputs": [],
      "source": [
        "# df_train = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_train.csv\")\n",
        "# df_val = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_validation.csv\")\n",
        "# df_test = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_test.csv\")\n",
        "\n",
        "resultados_por_competencia = {}\n",
        "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "for comp_idx in range(1, 6):\n",
        "    print(f\"\\n--- Treinando Modelo para Competência {comp_idx} ---\", flush=True)\n",
        "\n",
        "    X_train = np.hstack((X_train_combined, X_train_tfidf_final_array))\n",
        "    y_train = df_train[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_val = np.hstack((X_val_combined, X_val_tfidf_final_array))\n",
        "    y_val = df_val[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_test = np.hstack((X_test_combined, X_test_tfidf_final_array))\n",
        "    y_test = df_test[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    print(f\"Divisão de dados para Competência {comp_idx}: Treino={X_train.shape}, Validação={X_val.shape}, Teste={X_test.shape}\", flush=True)\n",
        "    scaler_comp = StandardScaler()\n",
        "    X_train_std = scaler_comp.fit_transform(X_train)\n",
        "    X_val_std = scaler_comp.transform(X_val)\n",
        "    X_test_std = scaler_comp.transform(X_test)\n",
        "    print(f\"Features escaladas para Competência {comp_idx}.\", flush=True)\n",
        "\n",
        "    data_module_competencia = CompetenceDataModule(X_train_std, y_train, X_val_std, y_val, X_test_std, y_test, BATCH_SIZE, NUM_WORKERS)\n",
        "    data_module_competencia.setup()\n",
        "\n",
        "    input_dim = X_train_std.shape[1]\n",
        "\n",
        "    pytorch_model_competencia = MultiLayerPerceptron(\n",
        "        input_size=input_dim,\n",
        "        hidden_units=(256, 128, 64),\n",
        "        num_classes=NUM_CLASSES_COMPETENCIA\n",
        "    )\n",
        "    lightning_model_competencia = LightningMLP(\n",
        "        model=pytorch_model_competencia,\n",
        "        learning_rate=LEARNING_RATE\n",
        "    )\n",
        "\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        save_top_k=1, mode=\"min\", monitor=\"valid_mae\",\n",
        "        dirpath=f\"logs_comp_{comp_idx}/\", filename=f\"best_model_comp_{comp_idx}\"\n",
        "    )\n",
        "    logger_competencia = CSVLogger(save_dir=\"logs/\", name=f\"mlp-coral-comp-{comp_idx}\")\n",
        "\n",
        "\n",
        "    early_stop_callback = EarlyStopping(\n",
        "    monitor=\"valid_qwk\",\n",
        "    min_delta=0.00,\n",
        "    patience=50,\n",
        "    verbose=True,\n",
        "    mode=\"max\"\n",
        "    )\n",
        "\n",
        "    callbacks_list = [\n",
        "        model_checkpoint_callback,\n",
        "        early_stop_callback\n",
        "    ]\n",
        "\n",
        "    trainer_competencia = pl.Trainer(\n",
        "        max_epochs=NUM_EPOCHS,\n",
        "        callbacks=callbacks_list,\n",
        "        accelerator=device_type,\n",
        "        devices=1,\n",
        "        logger=logger_competencia,\n",
        "        deterministic=True,\n",
        "        log_every_n_steps=10\n",
        "    )\n",
        "\n",
        "\n",
        "    start_time = time.time()\n",
        "    print(f\"Treinando modelo para Competência {comp_idx}...\", flush=True)\n",
        "    trainer_competencia.fit(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    runtime = (time.time() - start_time)/60\n",
        "    print(f\"Treinamento para Competência {comp_idx} levou {runtime:.2f} min.\", flush=True)\n",
        "\n",
        "    print(f\"Avaliando modelo para Competência {comp_idx} no conjunto de teste...\", flush=True)\n",
        "    test_results = trainer_competencia.test(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    resultados_por_competencia[f'competencia_{comp_idx}'] = test_results[0]\n",
        "\n",
        "    model_path = model_checkpoint_callback.best_model_path\n",
        "    best_model = LightningMLP.load_from_checkpoint(model_path, model=pytorch_model_competencia, learning_rate=LEARNING_RATE)\n",
        "    best_model.eval()\n",
        "\n",
        "    y_pred_list = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_module_competencia.test_dataloader():\n",
        "            features, _ = batch\n",
        "            logits = best_model(features)\n",
        "            probas = torch.sigmoid(logits)\n",
        "            predicted_labels = proba_to_label(probas)\n",
        "            y_pred_list.append(predicted_labels.cpu().numpy())\n",
        "\n",
        "    y_pred = np.hstack(y_pred_list)\n",
        "    y_true = y_test\n",
        "    y_pred_discreto = np.clip(np.round(y_pred), 0, NUM_CLASSES_COMPETENCIA - 1).astype(int)\n",
        "\n",
        "    print(\"--- Relatório de Classificação da Competência \", comp_idx, \" ---\")\n",
        "    print(classification_report(y_true, y_pred_discreto, zero_division=0.0))\n",
        "    print(\"\\n--- Matriz de Confusão da Competência \", comp_idx, \" ---\")\n",
        "    print(confusion_matrix(y_true, y_pred_discreto))\n",
        "\n",
        "    print(f\"--- Modelo para Competência {comp_idx} concluído ---\", flush=True)\n",
        "\n",
        "print(\"\\n--- Todos os modelos de competência foram treinados e avaliados ---\", flush=True)\n",
        "for comp, results in resultados_por_competencia.items():\n",
        "    print(f\"{comp}: QWK = {results['test_qwk']:.4f}, RMSE = {results['test_rmse']:.4f}, HDIV = {1- results['test_enem_acc']:.4f}\", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "treinamento base easy"
      ],
      "metadata": {
        "id": "enHnsoT4LFUn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# df_train = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_train.csv\")\n",
        "# df_val = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_validation.csv\")\n",
        "# df_test = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_test.csv\")\n",
        "\n",
        "resultados_por_competencia = {}\n",
        "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "for comp_idx in range(1, 6):\n",
        "    print(f\"\\n--- Treinando Modelo para Competência {comp_idx} ---\", flush=True)\n",
        "\n",
        "    X_train = np.hstack((X_train_combined, X_train_tfidf_final_array))\n",
        "    y_train = df_train[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_val = np.hstack((X_val_combined, X_val_tfidf_final_array))\n",
        "    y_val = df_val[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_test = np.hstack((X_test_easy_combined, X_test_easy_tfidf_final_array))\n",
        "    y_test = df_test_easy[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    print(f\"Divisão de dados para Competência {comp_idx}: Treino={X_train.shape}, Validação={X_val.shape}, Teste={X_test.shape}\", flush=True)\n",
        "    scaler_comp = StandardScaler()\n",
        "    X_train_std = scaler_comp.fit_transform(X_train)\n",
        "    X_val_std = scaler_comp.transform(X_val)\n",
        "    X_test_std = scaler_comp.transform(X_test)\n",
        "    print(f\"Features escaladas para Competência {comp_idx}.\", flush=True)\n",
        "\n",
        "    data_module_competencia = CompetenceDataModule(X_train_std, y_train, X_val_std, y_val, X_test_std, y_test, BATCH_SIZE, NUM_WORKERS)\n",
        "    data_module_competencia.setup()\n",
        "\n",
        "    input_dim = X_train_std.shape[1]\n",
        "\n",
        "    pytorch_model_competencia = MultiLayerPerceptron(\n",
        "        input_size=input_dim,\n",
        "        hidden_units=(256, 128, 64),\n",
        "        num_classes=NUM_CLASSES_COMPETENCIA\n",
        "    )\n",
        "    lightning_model_competencia = LightningMLP(\n",
        "        model=pytorch_model_competencia,\n",
        "        learning_rate=LEARNING_RATE\n",
        "    )\n",
        "\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        save_top_k=1, mode=\"min\", monitor=\"valid_mae\",\n",
        "        dirpath=f\"logs_comp_{comp_idx}/\", filename=f\"best_model_comp_{comp_idx}\"\n",
        "    )\n",
        "    logger_competencia = CSVLogger(save_dir=\"logs/\", name=f\"mlp-coral-comp-{comp_idx}\")\n",
        "\n",
        "\n",
        "    early_stop_callback = EarlyStopping(\n",
        "    monitor=\"valid_qwk\",\n",
        "    min_delta=0.00,\n",
        "    patience=50,\n",
        "    verbose=True,\n",
        "    mode=\"max\"\n",
        "    )\n",
        "\n",
        "    callbacks_list = [\n",
        "        model_checkpoint_callback,\n",
        "        early_stop_callback\n",
        "    ]\n",
        "\n",
        "    trainer_competencia = pl.Trainer(\n",
        "        max_epochs=NUM_EPOCHS,\n",
        "        callbacks=callbacks_list,\n",
        "        accelerator=device_type,\n",
        "        devices=1,\n",
        "        logger=logger_competencia,\n",
        "        deterministic=True,\n",
        "        log_every_n_steps=10\n",
        "    )\n",
        "\n",
        "\n",
        "    start_time = time.time()\n",
        "    print(f\"Treinando modelo para Competência {comp_idx}...\", flush=True)\n",
        "    trainer_competencia.fit(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    runtime = (time.time() - start_time)/60\n",
        "    print(f\"Treinamento para Competência {comp_idx} levou {runtime:.2f} min.\", flush=True)\n",
        "\n",
        "    print(f\"Avaliando modelo para Competência {comp_idx} no conjunto de teste...\", flush=True)\n",
        "    test_results = trainer_competencia.test(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    resultados_por_competencia[f'competencia_{comp_idx}'] = test_results[0]\n",
        "\n",
        "    model_path = model_checkpoint_callback.best_model_path\n",
        "    best_model = LightningMLP.load_from_checkpoint(model_path, model=pytorch_model_competencia, learning_rate=LEARNING_RATE)\n",
        "    best_model.eval()\n",
        "\n",
        "    y_pred_list = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_module_competencia.test_dataloader():\n",
        "            features, _ = batch\n",
        "            logits = best_model(features)\n",
        "            probas = torch.sigmoid(logits)\n",
        "            predicted_labels = proba_to_label(probas)\n",
        "            y_pred_list.append(predicted_labels.cpu().numpy())\n",
        "\n",
        "    y_pred = np.hstack(y_pred_list)\n",
        "    y_true = y_test\n",
        "    y_pred_discreto = np.clip(np.round(y_pred), 0, NUM_CLASSES_COMPETENCIA - 1).astype(int)\n",
        "\n",
        "    print(\"--- Relatório de Classificação da Competência \", comp_idx, \" ---\")\n",
        "    print(classification_report(y_true, y_pred_discreto, zero_division=0.0))\n",
        "    print(\"\\n--- Matriz de Confusão da Competência \", comp_idx, \" ---\")\n",
        "    print(confusion_matrix(y_true, y_pred_discreto))\n",
        "\n",
        "    print(f\"--- Modelo para Competência {comp_idx} concluído ---\", flush=True)\n",
        "\n",
        "print(\"\\n--- Todos os modelos de competência foram treinados e avaliados ---\", flush=True)\n",
        "for comp, results in resultados_por_competencia.items():\n",
        "    print(f\"{comp}: QWK = {results['test_qwk']:.4f}, RMSE = {results['test_rmse']:.4f}, HDIV = {1- results['test_enem_acc']:.4f}\", flush=True)"
      ],
      "metadata": {
        "id": "JV3aeL-VLHe7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvIotJtLJFDB"
      },
      "source": [
        "# TF IDF + NILC + Murilo"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "treinamento base test inteira"
      ],
      "metadata": {
        "id": "CuOAv9riRRWf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t0-X2WdqJONY"
      },
      "outputs": [],
      "source": [
        "# df_train = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_train.csv\")\n",
        "# df_val = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_validation.csv\")\n",
        "# df_test = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_test.csv\")\n",
        "\n",
        "resultados_por_competencia = {}\n",
        "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "for comp_idx in range(1, 6):\n",
        "    print(f\"\\n--- Treinando Modelo para Competência {comp_idx} ---\", flush=True)\n",
        "\n",
        "    X_train = np.hstack((X_train_handcrafted, X_train_tfidf_final_array, X_train_handcrafted_Murilo))\n",
        "    y_train = df_train[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_val = np.hstack((X_val_handcrafted, X_val_tfidf_final_array, X_val_handcrafted_Murilo))\n",
        "    y_val = df_val[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_test = np.hstack((X_test_handcrafted, X_test_tfidf_final_array, X_test_handcrafted_Murilo))\n",
        "    y_test = df_test[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    print(f\"Divisão de dados para Competência {comp_idx}: Treino={X_train.shape}, Validação={X_val.shape}, Teste={X_test.shape}\", flush=True)\n",
        "\n",
        "    scaler_comp = StandardScaler()\n",
        "    X_train_std = scaler_comp.fit_transform(X_train)\n",
        "    X_val_std = scaler_comp.transform(X_val)\n",
        "    X_test_std = scaler_comp.transform(X_test)\n",
        "    print(f\"Features escaladas para Competência {comp_idx}.\", flush=True)\n",
        "\n",
        "\n",
        "    data_module_competencia = CompetenceDataModule(X_train_std, y_train, X_val_std, y_val, X_test_std, y_test, BATCH_SIZE, NUM_WORKERS)\n",
        "    data_module_competencia.setup()\n",
        "\n",
        "    input_dim = X_train_std.shape[1]\n",
        "\n",
        "    pytorch_model_competencia = MultiLayerPerceptron(\n",
        "        input_size=input_dim,\n",
        "        hidden_units=(256, 128, 64),\n",
        "        num_classes=NUM_CLASSES_COMPETENCIA\n",
        "    )\n",
        "    lightning_model_competencia = LightningMLP(\n",
        "        model=pytorch_model_competencia,\n",
        "        learning_rate=LEARNING_RATE\n",
        "    )\n",
        "\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        save_top_k=1, mode=\"min\", monitor=\"valid_mae\",\n",
        "        dirpath=f\"logs_comp_{comp_idx}/\", filename=f\"best_model_comp_{comp_idx}\"\n",
        "    )\n",
        "    logger_competencia = CSVLogger(save_dir=\"logs/\", name=f\"mlp-coral-comp-{comp_idx}\")\n",
        "\n",
        "\n",
        "    early_stop_callback = EarlyStopping(\n",
        "    monitor=\"valid_qwk\",\n",
        "    min_delta=0.00,\n",
        "    patience=50,\n",
        "    verbose=True,\n",
        "    mode=\"max\"\n",
        "    )\n",
        "\n",
        "    callbacks_list = [\n",
        "        model_checkpoint_callback,\n",
        "        early_stop_callback\n",
        "    ]\n",
        "\n",
        "    trainer_competencia = pl.Trainer(\n",
        "        max_epochs=NUM_EPOCHS,\n",
        "        callbacks=callbacks_list,\n",
        "        accelerator=device_type,\n",
        "        devices=1,\n",
        "        logger=logger_competencia,\n",
        "        deterministic=True,\n",
        "        log_every_n_steps=10\n",
        "    )\n",
        "\n",
        "    start_time = time.time()\n",
        "    print(f\"Treinando modelo para Competência {comp_idx}...\", flush=True)\n",
        "    trainer_competencia.fit(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    runtime = (time.time() - start_time)/60\n",
        "    print(f\"Treinamento para Competência {comp_idx} levou {runtime:.2f} min.\", flush=True)\n",
        "\n",
        "    print(f\"Avaliando modelo para Competência {comp_idx} no conjunto de teste...\", flush=True)\n",
        "    test_results = trainer_competencia.test(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    resultados_por_competencia[f'competencia_{comp_idx}'] = test_results[0]\n",
        "\n",
        "    model_path = model_checkpoint_callback.best_model_path\n",
        "    best_model = LightningMLP.load_from_checkpoint(model_path, model=pytorch_model_competencia, learning_rate=LEARNING_RATE)\n",
        "    best_model.eval()\n",
        "\n",
        "    y_pred_list = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_module_competencia.test_dataloader():\n",
        "            features, _ = batch\n",
        "            logits = best_model(features)\n",
        "            probas = torch.sigmoid(logits)\n",
        "            predicted_labels = proba_to_label(probas)\n",
        "            y_pred_list.append(predicted_labels.cpu().numpy())\n",
        "\n",
        "    y_pred = np.hstack(y_pred_list)\n",
        "    y_true = y_test\n",
        "    y_pred_discreto = np.clip(np.round(y_pred), 0, NUM_CLASSES_COMPETENCIA - 1).astype(int)\n",
        "\n",
        "    print(\"--- Relatório de Classificação da Competência \", comp_idx, \" ---\")\n",
        "    print(classification_report(y_true, y_pred_discreto, zero_division=0.0))\n",
        "    print(\"\\n--- Matriz de Confusão da Competência \", comp_idx, \" ---\")\n",
        "    print(confusion_matrix(y_true, y_pred_discreto))\n",
        "\n",
        "    print(f\"--- Modelo para Competência {comp_idx} concluído ---\", flush=True)\n",
        "\n",
        "print(\"\\n--- Todos os modelos de competência foram treinados e avaliados ---\", flush=True)\n",
        "for comp, results in resultados_por_competencia.items():\n",
        "    print(f\"{comp}: QWK = {results['test_qwk']:.4f}, RMSE = {results['test_rmse']:.4f}, HDIV = {1- results['test_enem_acc']:.4f}\", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "treinamento base test easy"
      ],
      "metadata": {
        "id": "UnLPRzylRXh0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# df_train = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_train.csv\")\n",
        "# df_val = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_validation.csv\")\n",
        "# df_test = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_test.csv\")\n",
        "\n",
        "resultados_por_competencia = {}\n",
        "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "for comp_idx in range(1, 6):\n",
        "    print(f\"\\n--- Treinando Modelo para Competência {comp_idx} ---\", flush=True)\n",
        "\n",
        "    X_train = np.hstack((X_train_handcrafted, X_train_tfidf_final_array, X_train_handcrafted_Murilo))\n",
        "    y_train = df_train[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_val = np.hstack((X_val_handcrafted, X_val_tfidf_final_array, X_val_handcrafted_Murilo))\n",
        "    y_val = df_val[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_test = np.hstack((X_test_easy_handcrafted, X_test_easy_tfidf_final_array, X_test_easy_handcrafted_Murilo))\n",
        "    y_test = df_test_easy[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    print(f\"Divisão de dados para Competência {comp_idx}: Treino={X_train.shape}, Validação={X_val.shape}, Teste={X_test.shape}\", flush=True)\n",
        "\n",
        "    scaler_comp = StandardScaler()\n",
        "    X_train_std = scaler_comp.fit_transform(X_train)\n",
        "    X_val_std = scaler_comp.transform(X_val)\n",
        "    X_test_std = scaler_comp.transform(X_test)\n",
        "    print(f\"Features escaladas para Competência {comp_idx}.\", flush=True)\n",
        "\n",
        "\n",
        "    data_module_competencia = CompetenceDataModule(X_train_std, y_train, X_val_std, y_val, X_test_std, y_test, BATCH_SIZE, NUM_WORKERS)\n",
        "    data_module_competencia.setup()\n",
        "\n",
        "    input_dim = X_train_std.shape[1]\n",
        "\n",
        "    pytorch_model_competencia = MultiLayerPerceptron(\n",
        "        input_size=input_dim,\n",
        "        hidden_units=(256, 128, 64),\n",
        "        num_classes=NUM_CLASSES_COMPETENCIA\n",
        "    )\n",
        "    lightning_model_competencia = LightningMLP(\n",
        "        model=pytorch_model_competencia,\n",
        "        learning_rate=LEARNING_RATE\n",
        "    )\n",
        "\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        save_top_k=1, mode=\"min\", monitor=\"valid_mae\",\n",
        "        dirpath=f\"logs_comp_{comp_idx}/\", filename=f\"best_model_comp_{comp_idx}\"\n",
        "    )\n",
        "    logger_competencia = CSVLogger(save_dir=\"logs/\", name=f\"mlp-coral-comp-{comp_idx}\")\n",
        "\n",
        "\n",
        "    early_stop_callback = EarlyStopping(\n",
        "    monitor=\"valid_qwk\",\n",
        "    min_delta=0.00,\n",
        "    patience=50,\n",
        "    verbose=True,\n",
        "    mode=\"max\"\n",
        "    )\n",
        "\n",
        "    callbacks_list = [\n",
        "        model_checkpoint_callback,\n",
        "        early_stop_callback\n",
        "    ]\n",
        "\n",
        "    trainer_competencia = pl.Trainer(\n",
        "        max_epochs=NUM_EPOCHS,\n",
        "        callbacks=callbacks_list,\n",
        "        accelerator=device_type,\n",
        "        devices=1,\n",
        "        logger=logger_competencia,\n",
        "        deterministic=True,\n",
        "        log_every_n_steps=10\n",
        "    )\n",
        "\n",
        "    start_time = time.time()\n",
        "    print(f\"Treinando modelo para Competência {comp_idx}...\", flush=True)\n",
        "    trainer_competencia.fit(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    runtime = (time.time() - start_time)/60\n",
        "    print(f\"Treinamento para Competência {comp_idx} levou {runtime:.2f} min.\", flush=True)\n",
        "\n",
        "    print(f\"Avaliando modelo para Competência {comp_idx} no conjunto de teste...\", flush=True)\n",
        "    test_results = trainer_competencia.test(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    resultados_por_competencia[f'competencia_{comp_idx}'] = test_results[0]\n",
        "\n",
        "    model_path = model_checkpoint_callback.best_model_path\n",
        "    best_model = LightningMLP.load_from_checkpoint(model_path, model=pytorch_model_competencia, learning_rate=LEARNING_RATE)\n",
        "    best_model.eval()\n",
        "\n",
        "    y_pred_list = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_module_competencia.test_dataloader():\n",
        "            features, _ = batch\n",
        "            logits = best_model(features)\n",
        "            probas = torch.sigmoid(logits)\n",
        "            predicted_labels = proba_to_label(probas)\n",
        "            y_pred_list.append(predicted_labels.cpu().numpy())\n",
        "\n",
        "    y_pred = np.hstack(y_pred_list)\n",
        "    y_true = y_test\n",
        "    y_pred_discreto = np.clip(np.round(y_pred), 0, NUM_CLASSES_COMPETENCIA - 1).astype(int)\n",
        "\n",
        "    print(\"--- Relatório de Classificação da Competência \", comp_idx, \" ---\")\n",
        "    print(classification_report(y_true, y_pred_discreto, zero_division=0.0))\n",
        "    print(\"\\n--- Matriz de Confusão da Competência \", comp_idx, \" ---\")\n",
        "    print(confusion_matrix(y_true, y_pred_discreto))\n",
        "\n",
        "    print(f\"--- Modelo para Competência {comp_idx} concluído ---\", flush=True)\n",
        "\n",
        "print(\"\\n--- Todos os modelos de competência foram treinados e avaliados ---\", flush=True)\n",
        "for comp, results in resultados_por_competencia.items():\n",
        "    print(f\"{comp}: QWK = {results['test_qwk']:.4f}, RMSE = {results['test_rmse']:.4f}, HDIV = {1- results['test_enem_acc']:.4f}\", flush=True)"
      ],
      "metadata": {
        "id": "xItkw0wrRZxU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HsYfeRAFmun"
      },
      "source": [
        "# TF IDF + BERT + Murilo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uZS6Qv40lbOH"
      },
      "outputs": [],
      "source": [
        "# df_train = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_train.csv\")\n",
        "# df_val = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_validation.csv\")\n",
        "# df_test = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_test.csv\")\n",
        "\n",
        "resultados_por_competencia = {}\n",
        "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "for comp_idx in range(1, 6):\n",
        "    print(f\"\\n--- Treinando Modelo para Competência {comp_idx} ---\", flush=True)\n",
        "\n",
        "    X_train = np.hstack((X_train_pure, X_train_tfidf_final_array, X_train_handcrafted_Murilo))\n",
        "    y_train = df_train[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_val = np.hstack((X_val_pure, X_val_tfidf_final_array, X_val_handcrafted_Murilo))\n",
        "    y_val = df_val[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_test = np.hstack((X_test_pure, X_test_tfidf_final_array, X_test_handcrafted_Murilo))\n",
        "    y_test = df_test[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    print(f\"Divisão de dados para Competência {comp_idx}: Treino={X_train.shape}, Validação={X_val.shape}, Teste={X_test.shape}\", flush=True)\n",
        "\n",
        "    scaler_comp = StandardScaler()\n",
        "    X_train_std = scaler_comp.fit_transform(X_train)\n",
        "    X_val_std = scaler_comp.transform(X_val)\n",
        "    X_test_std = scaler_comp.transform(X_test)\n",
        "    print(f\"Features escaladas para Competência {comp_idx}.\", flush=True)\n",
        "\n",
        "    data_module_competencia = CompetenceDataModule(X_train_std, y_train, X_val_std, y_val, X_test_std, y_test, BATCH_SIZE, NUM_WORKERS)\n",
        "    data_module_competencia.setup()\n",
        "\n",
        "    input_dim = X_train_std.shape[1]\n",
        "\n",
        "    pytorch_model_competencia = MultiLayerPerceptron(\n",
        "        input_size=input_dim,\n",
        "        hidden_units=(256, 128, 64),\n",
        "        num_classes=NUM_CLASSES_COMPETENCIA\n",
        "    )\n",
        "    lightning_model_competencia = LightningMLP(\n",
        "        model=pytorch_model_competencia,\n",
        "        learning_rate=LEARNING_RATE\n",
        "    )\n",
        "\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        save_top_k=1, mode=\"min\", monitor=\"valid_mae\",\n",
        "        dirpath=f\"logs_comp_{comp_idx}/\", filename=f\"best_model_comp_{comp_idx}\"\n",
        "    )\n",
        "    logger_competencia = CSVLogger(save_dir=\"logs/\", name=f\"mlp-coral-comp-{comp_idx}\")\n",
        "\n",
        "\n",
        "    early_stop_callback = EarlyStopping(\n",
        "    monitor=\"valid_qwk\",\n",
        "    min_delta=0.00,\n",
        "    patience=50,\n",
        "    verbose=True,\n",
        "    mode=\"max\"\n",
        "    )\n",
        "\n",
        "    callbacks_list = [\n",
        "        model_checkpoint_callback,\n",
        "        early_stop_callback\n",
        "    ]\n",
        "\n",
        "    trainer_competencia = pl.Trainer(\n",
        "        max_epochs=NUM_EPOCHS,\n",
        "        callbacks=callbacks_list,\n",
        "        accelerator=device_type,\n",
        "        devices=1,\n",
        "        logger=logger_competencia,\n",
        "        deterministic=True,\n",
        "        log_every_n_steps=10\n",
        "    )\n",
        "\n",
        "    start_time = time.time()\n",
        "    print(f\"Treinando modelo para Competência {comp_idx}...\", flush=True)\n",
        "    trainer_competencia.fit(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    runtime = (time.time() - start_time)/60\n",
        "    print(f\"Treinamento para Competência {comp_idx} levou {runtime:.2f} min.\", flush=True)\n",
        "\n",
        "    print(f\"Avaliando modelo para Competência {comp_idx} no conjunto de teste...\", flush=True)\n",
        "    test_results = trainer_competencia.test(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    resultados_por_competencia[f'competencia_{comp_idx}'] = test_results[0]\n",
        "\n",
        "    model_path = model_checkpoint_callback.best_model_path\n",
        "    best_model = LightningMLP.load_from_checkpoint(model_path, model=pytorch_model_competencia, learning_rate=LEARNING_RATE)\n",
        "    best_model.eval()\n",
        "\n",
        "    y_pred_list = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_module_competencia.test_dataloader():\n",
        "            features, _ = batch\n",
        "            logits = best_model(features)\n",
        "            probas = torch.sigmoid(logits)\n",
        "            predicted_labels = proba_to_label(probas)\n",
        "            y_pred_list.append(predicted_labels.cpu().numpy())\n",
        "\n",
        "    y_pred = np.hstack(y_pred_list)\n",
        "    y_true = y_test\n",
        "    y_pred_discreto = np.clip(np.round(y_pred), 0, NUM_CLASSES_COMPETENCIA - 1).astype(int)\n",
        "\n",
        "    print(\"--- Relatório de Classificação da Competência \", comp_idx, \" ---\")\n",
        "    print(classification_report(y_true, y_pred_discreto, zero_division=0.0))\n",
        "    print(\"\\n--- Matriz de Confusão da Competência \", comp_idx, \" ---\")\n",
        "    print(confusion_matrix(y_true, y_pred_discreto))\n",
        "\n",
        "    print(f\"--- Modelo para Competência {comp_idx} concluído ---\", flush=True)\n",
        "\n",
        "print(\"\\n--- Todos os modelos de competência foram treinados e avaliados ---\", flush=True)\n",
        "for comp, results in resultados_por_competencia.items():\n",
        "    print(f\"{comp}: QWK = {results['test_qwk']:.4f}, RMSE = {results['test_rmse']:.4f}, HDIV = {1- results['test_enem_acc']:.4f}\", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "teste easy"
      ],
      "metadata": {
        "id": "WNAsMvVJTON8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# df_train = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_train.csv\")\n",
        "# df_val = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_validation.csv\")\n",
        "# df_test = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_test.csv\")\n",
        "\n",
        "resultados_por_competencia = {}\n",
        "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "for comp_idx in range(1, 6):\n",
        "    print(f\"\\n--- Treinando Modelo para Competência {comp_idx} ---\", flush=True)\n",
        "\n",
        "    X_train = np.hstack((X_train_pure, X_train_tfidf_final_array, X_train_handcrafted_Murilo))\n",
        "    y_train = df_train[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_val = np.hstack((X_val_pure, X_val_tfidf_final_array, X_val_handcrafted_Murilo))\n",
        "    y_val = df_val[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_test = np.hstack((X_test_easy_pure, X_test_easy_tfidf_final_array, X_test_easy_handcrafted_Murilo))\n",
        "    y_test = df_test_easy[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    print(f\"Divisão de dados para Competência {comp_idx}: Treino={X_train.shape}, Validação={X_val.shape}, Teste={X_test.shape}\", flush=True)\n",
        "\n",
        "    scaler_comp = StandardScaler()\n",
        "    X_train_std = scaler_comp.fit_transform(X_train)\n",
        "    X_val_std = scaler_comp.transform(X_val)\n",
        "    X_test_std = scaler_comp.transform(X_test)\n",
        "    print(f\"Features escaladas para Competência {comp_idx}.\", flush=True)\n",
        "\n",
        "    data_module_competencia = CompetenceDataModule(X_train_std, y_train, X_val_std, y_val, X_test_std, y_test, BATCH_SIZE, NUM_WORKERS)\n",
        "    data_module_competencia.setup()\n",
        "\n",
        "    input_dim = X_train_std.shape[1]\n",
        "\n",
        "    pytorch_model_competencia = MultiLayerPerceptron(\n",
        "        input_size=input_dim,\n",
        "        hidden_units=(256, 128, 64),\n",
        "        num_classes=NUM_CLASSES_COMPETENCIA\n",
        "    )\n",
        "    lightning_model_competencia = LightningMLP(\n",
        "        model=pytorch_model_competencia,\n",
        "        learning_rate=LEARNING_RATE\n",
        "    )\n",
        "\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        save_top_k=1, mode=\"min\", monitor=\"valid_mae\",\n",
        "        dirpath=f\"logs_comp_{comp_idx}/\", filename=f\"best_model_comp_{comp_idx}\"\n",
        "    )\n",
        "    logger_competencia = CSVLogger(save_dir=\"logs/\", name=f\"mlp-coral-comp-{comp_idx}\")\n",
        "\n",
        "\n",
        "    early_stop_callback = EarlyStopping(\n",
        "    monitor=\"valid_qwk\",\n",
        "    min_delta=0.00,\n",
        "    patience=50,\n",
        "    verbose=True,\n",
        "    mode=\"max\"\n",
        "    )\n",
        "\n",
        "    callbacks_list = [\n",
        "        model_checkpoint_callback,\n",
        "        early_stop_callback\n",
        "    ]\n",
        "\n",
        "    trainer_competencia = pl.Trainer(\n",
        "        max_epochs=NUM_EPOCHS,\n",
        "        callbacks=callbacks_list,\n",
        "        accelerator=device_type,\n",
        "        devices=1,\n",
        "        logger=logger_competencia,\n",
        "        deterministic=True,\n",
        "        log_every_n_steps=10\n",
        "    )\n",
        "\n",
        "    start_time = time.time()\n",
        "    print(f\"Treinando modelo para Competência {comp_idx}...\", flush=True)\n",
        "    trainer_competencia.fit(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    runtime = (time.time() - start_time)/60\n",
        "    print(f\"Treinamento para Competência {comp_idx} levou {runtime:.2f} min.\", flush=True)\n",
        "\n",
        "    print(f\"Avaliando modelo para Competência {comp_idx} no conjunto de teste...\", flush=True)\n",
        "    test_results = trainer_competencia.test(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    resultados_por_competencia[f'competencia_{comp_idx}'] = test_results[0]\n",
        "\n",
        "    model_path = model_checkpoint_callback.best_model_path\n",
        "    best_model = LightningMLP.load_from_checkpoint(model_path, model=pytorch_model_competencia, learning_rate=LEARNING_RATE)\n",
        "    best_model.eval()\n",
        "\n",
        "    y_pred_list = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_module_competencia.test_dataloader():\n",
        "            features, _ = batch\n",
        "            logits = best_model(features)\n",
        "            probas = torch.sigmoid(logits)\n",
        "            predicted_labels = proba_to_label(probas)\n",
        "            y_pred_list.append(predicted_labels.cpu().numpy())\n",
        "\n",
        "    y_pred = np.hstack(y_pred_list)\n",
        "    y_true = y_test\n",
        "    y_pred_discreto = np.clip(np.round(y_pred), 0, NUM_CLASSES_COMPETENCIA - 1).astype(int)\n",
        "\n",
        "    print(\"--- Relatório de Classificação da Competência \", comp_idx, \" ---\")\n",
        "    print(classification_report(y_true, y_pred_discreto, zero_division=0.0))\n",
        "    print(\"\\n--- Matriz de Confusão da Competência \", comp_idx, \" ---\")\n",
        "    print(confusion_matrix(y_true, y_pred_discreto))\n",
        "\n",
        "    print(f\"--- Modelo para Competência {comp_idx} concluído ---\", flush=True)\n",
        "\n",
        "print(\"\\n--- Todos os modelos de competência foram treinados e avaliados ---\", flush=True)\n",
        "for comp, results in resultados_por_competencia.items():\n",
        "    print(f\"{comp}: QWK = {results['test_qwk']:.4f}, RMSE = {results['test_rmse']:.4f}, HDIV = {1- results['test_enem_acc']:.4f}\", flush=True)"
      ],
      "metadata": {
        "id": "geIwH83pTQkL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3qUt7Z5F3-g"
      },
      "source": [
        "# NILC + BERT + Murilo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-V3xt76vmV-2"
      },
      "outputs": [],
      "source": [
        "# df_train = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_train.csv\")\n",
        "# df_val = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_validation.csv\")\n",
        "# df_test = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_test.csv\")\n",
        "\n",
        "resultados_por_competencia = {}\n",
        "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "for comp_idx in range(1, 6):\n",
        "    print(f\"\\n--- Treinando Modelo para Competência {comp_idx} ---\", flush=True)\n",
        "\n",
        "    X_train = np.hstack((X_train_pure, X_train_handcrafted, X_train_handcrafted_Murilo))\n",
        "    y_train = df_train[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_val = np.hstack((X_val_pure, X_val_handcrafted, X_val_handcrafted_Murilo))\n",
        "    y_val = df_val[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_test = np.hstack((X_test_pure, X_test_handcrafted, X_test_handcrafted_Murilo))\n",
        "    y_test = df_test[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    print(f\"Divisão de dados para Competência {comp_idx}: Treino={X_train.shape}, Validação={X_val.shape}, Teste={X_test.shape}\", flush=True)\n",
        "\n",
        "    scaler_comp = StandardScaler()\n",
        "    X_train_std = scaler_comp.fit_transform(X_train)\n",
        "    X_val_std = scaler_comp.transform(X_val)\n",
        "    X_test_std = scaler_comp.transform(X_test)\n",
        "    print(f\"Features escaladas para Competência {comp_idx}.\", flush=True)\n",
        "\n",
        "    data_module_competencia = CompetenceDataModule(X_train_std, y_train, X_val_std, y_val, X_test_std, y_test, BATCH_SIZE, NUM_WORKERS)\n",
        "    data_module_competencia.setup()\n",
        "\n",
        "    input_dim = X_train_std.shape[1]\n",
        "\n",
        "    pytorch_model_competencia = MultiLayerPerceptron(\n",
        "        input_size=input_dim,\n",
        "        hidden_units=(256, 128, 64),\n",
        "        num_classes=NUM_CLASSES_COMPETENCIA\n",
        "    )\n",
        "    lightning_model_competencia = LightningMLP(\n",
        "        model=pytorch_model_competencia,\n",
        "        learning_rate=LEARNING_RATE\n",
        "    )\n",
        "\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        save_top_k=1, mode=\"min\", monitor=\"valid_mae\",\n",
        "        dirpath=f\"logs_comp_{comp_idx}/\", filename=f\"best_model_comp_{comp_idx}\"\n",
        "    )\n",
        "    logger_competencia = CSVLogger(save_dir=\"logs/\", name=f\"mlp-coral-comp-{comp_idx}\")\n",
        "\n",
        "\n",
        "    early_stop_callback = EarlyStopping(\n",
        "    monitor=\"valid_qwk\",\n",
        "    min_delta=0.00,\n",
        "    patience=50,\n",
        "    verbose=True,\n",
        "    mode=\"max\"\n",
        "    )\n",
        "\n",
        "    callbacks_list = [\n",
        "        model_checkpoint_callback,\n",
        "        early_stop_callback\n",
        "    ]\n",
        "\n",
        "    trainer_competencia = pl.Trainer(\n",
        "        max_epochs=NUM_EPOCHS,\n",
        "        callbacks=callbacks_list,\n",
        "        accelerator=device_type,\n",
        "        devices=1,\n",
        "        logger=logger_competencia,\n",
        "        deterministic=True,\n",
        "        log_every_n_steps=10\n",
        "    )\n",
        "\n",
        "    start_time = time.time()\n",
        "    print(f\"Treinando modelo para Competência {comp_idx}...\", flush=True)\n",
        "    trainer_competencia.fit(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    runtime = (time.time() - start_time)/60\n",
        "    print(f\"Treinamento para Competência {comp_idx} levou {runtime:.2f} min.\", flush=True)\n",
        "\n",
        "    print(f\"Avaliando modelo para Competência {comp_idx} no conjunto de teste...\", flush=True)\n",
        "    test_results = trainer_competencia.test(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    resultados_por_competencia[f'competencia_{comp_idx}'] = test_results[0]\n",
        "\n",
        "    model_path = model_checkpoint_callback.best_model_path\n",
        "    best_model = LightningMLP.load_from_checkpoint(model_path, model=pytorch_model_competencia, learning_rate=LEARNING_RATE)\n",
        "    best_model.eval()\n",
        "\n",
        "    y_pred_list = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_module_competencia.test_dataloader():\n",
        "            features, _ = batch\n",
        "            logits = best_model(features)\n",
        "            probas = torch.sigmoid(logits)\n",
        "            predicted_labels = proba_to_label(probas)\n",
        "            y_pred_list.append(predicted_labels.cpu().numpy())\n",
        "\n",
        "    y_pred = np.hstack(y_pred_list)\n",
        "    y_true = y_test\n",
        "    y_pred_discreto = np.clip(np.round(y_pred), 0, NUM_CLASSES_COMPETENCIA - 1).astype(int)\n",
        "\n",
        "    print(\"--- Relatório de Classificação da Competência \", comp_idx, \" ---\")\n",
        "    print(classification_report(y_true, y_pred_discreto, zero_division=0.0))\n",
        "    print(\"\\n--- Matriz de Confusão da Competência \", comp_idx, \" ---\")\n",
        "    print(confusion_matrix(y_true, y_pred_discreto))\n",
        "\n",
        "    print(f\"--- Modelo para Competência {comp_idx} concluído ---\", flush=True)\n",
        "\n",
        "print(\"\\n--- Todos os modelos de competência foram treinados e avaliados ---\", flush=True)\n",
        "for comp, results in resultados_por_competencia.items():\n",
        "    print(f\"{comp}: QWK = {results['test_qwk']:.4f}, RMSE = {results['test_rmse']:.4f}, HDIV = {1- results['test_enem_acc']:.4f}\", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "test easy"
      ],
      "metadata": {
        "id": "eJsby4pHTldb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# df_train = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_train.csv\")\n",
        "# df_val = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_validation.csv\")\n",
        "# df_test = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_test.csv\")\n",
        "\n",
        "resultados_por_competencia = {}\n",
        "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "for comp_idx in range(1, 6):\n",
        "    print(f\"\\n--- Treinando Modelo para Competência {comp_idx} ---\", flush=True)\n",
        "\n",
        "    X_train = np.hstack((X_train_pure, X_train_handcrafted, X_train_handcrafted_Murilo))\n",
        "    y_train = df_train[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_val = np.hstack((X_val_pure, X_val_handcrafted, X_val_handcrafted_Murilo))\n",
        "    y_val = df_val[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_test = np.hstack((X_test_easy_pure, X_test_easy_handcrafted, X_test_easy_handcrafted_Murilo))\n",
        "    y_test = df_test_easy[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    print(f\"Divisão de dados para Competência {comp_idx}: Treino={X_train.shape}, Validação={X_val.shape}, Teste={X_test.shape}\", flush=True)\n",
        "\n",
        "    scaler_comp = StandardScaler()\n",
        "    X_train_std = scaler_comp.fit_transform(X_train)\n",
        "    X_val_std = scaler_comp.transform(X_val)\n",
        "    X_test_std = scaler_comp.transform(X_test)\n",
        "    print(f\"Features escaladas para Competência {comp_idx}.\", flush=True)\n",
        "\n",
        "    data_module_competencia = CompetenceDataModule(X_train_std, y_train, X_val_std, y_val, X_test_std, y_test, BATCH_SIZE, NUM_WORKERS)\n",
        "    data_module_competencia.setup()\n",
        "\n",
        "    input_dim = X_train_std.shape[1]\n",
        "\n",
        "    pytorch_model_competencia = MultiLayerPerceptron(\n",
        "        input_size=input_dim,\n",
        "        hidden_units=(256, 128, 64),\n",
        "        num_classes=NUM_CLASSES_COMPETENCIA\n",
        "    )\n",
        "    lightning_model_competencia = LightningMLP(\n",
        "        model=pytorch_model_competencia,\n",
        "        learning_rate=LEARNING_RATE\n",
        "    )\n",
        "\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        save_top_k=1, mode=\"min\", monitor=\"valid_mae\",\n",
        "        dirpath=f\"logs_comp_{comp_idx}/\", filename=f\"best_model_comp_{comp_idx}\"\n",
        "    )\n",
        "    logger_competencia = CSVLogger(save_dir=\"logs/\", name=f\"mlp-coral-comp-{comp_idx}\")\n",
        "\n",
        "\n",
        "    early_stop_callback = EarlyStopping(\n",
        "    monitor=\"valid_qwk\",\n",
        "    min_delta=0.00,\n",
        "    patience=50,\n",
        "    verbose=True,\n",
        "    mode=\"max\"\n",
        "    )\n",
        "\n",
        "    callbacks_list = [\n",
        "        model_checkpoint_callback,\n",
        "        early_stop_callback\n",
        "    ]\n",
        "\n",
        "    trainer_competencia = pl.Trainer(\n",
        "        max_epochs=NUM_EPOCHS,\n",
        "        callbacks=callbacks_list,\n",
        "        accelerator=device_type,\n",
        "        devices=1,\n",
        "        logger=logger_competencia,\n",
        "        deterministic=True,\n",
        "        log_every_n_steps=10\n",
        "    )\n",
        "\n",
        "    start_time = time.time()\n",
        "    print(f\"Treinando modelo para Competência {comp_idx}...\", flush=True)\n",
        "    trainer_competencia.fit(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    runtime = (time.time() - start_time)/60\n",
        "    print(f\"Treinamento para Competência {comp_idx} levou {runtime:.2f} min.\", flush=True)\n",
        "\n",
        "    print(f\"Avaliando modelo para Competência {comp_idx} no conjunto de teste...\", flush=True)\n",
        "    test_results = trainer_competencia.test(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    resultados_por_competencia[f'competencia_{comp_idx}'] = test_results[0]\n",
        "\n",
        "    model_path = model_checkpoint_callback.best_model_path\n",
        "    best_model = LightningMLP.load_from_checkpoint(model_path, model=pytorch_model_competencia, learning_rate=LEARNING_RATE)\n",
        "    best_model.eval()\n",
        "\n",
        "    y_pred_list = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_module_competencia.test_dataloader():\n",
        "            features, _ = batch\n",
        "            logits = best_model(features)\n",
        "            probas = torch.sigmoid(logits)\n",
        "            predicted_labels = proba_to_label(probas)\n",
        "            y_pred_list.append(predicted_labels.cpu().numpy())\n",
        "\n",
        "    y_pred = np.hstack(y_pred_list)\n",
        "    y_true = y_test\n",
        "    y_pred_discreto = np.clip(np.round(y_pred), 0, NUM_CLASSES_COMPETENCIA - 1).astype(int)\n",
        "\n",
        "    print(\"--- Relatório de Classificação da Competência \", comp_idx, \" ---\")\n",
        "    print(classification_report(y_true, y_pred_discreto, zero_division=0.0))\n",
        "    print(\"\\n--- Matriz de Confusão da Competência \", comp_idx, \" ---\")\n",
        "    print(confusion_matrix(y_true, y_pred_discreto))\n",
        "\n",
        "    print(f\"--- Modelo para Competência {comp_idx} concluído ---\", flush=True)\n",
        "\n",
        "print(\"\\n--- Todos os modelos de competência foram treinados e avaliados ---\", flush=True)\n",
        "for comp, results in resultados_por_competencia.items():\n",
        "    print(f\"{comp}: QWK = {results['test_qwk']:.4f}, RMSE = {results['test_rmse']:.4f}, HDIV = {1- results['test_enem_acc']:.4f}\", flush=True)"
      ],
      "metadata": {
        "id": "O-QXCUjYTm1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9Q6qpwOwvtJ"
      },
      "source": [
        "# TF IDF + NILC + BERT + Murilo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tyAFTMs3Kygn"
      },
      "outputs": [],
      "source": [
        "# df_train = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_train.csv\")\n",
        "# df_val = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_validation.csv\")\n",
        "# df_test = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_test.csv\")\n",
        "\n",
        "resultados_por_competencia = {}\n",
        "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "for comp_idx in range(1, 6):\n",
        "    print(f\"\\n--- Treinando Modelo para Competência {comp_idx} ---\", flush=True)\n",
        "\n",
        "    X_train = np.hstack((X_train_handcrafted, X_train_tfidf_final_array, X_train_handcrafted_Murilo, X_train_pure))\n",
        "    y_train = df_train[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_val = np.hstack((X_val_handcrafted, X_val_tfidf_final_array, X_val_handcrafted_Murilo, X_val_pure))\n",
        "    y_val = df_val[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_test = np.hstack((X_test_handcrafted, X_test_tfidf_final_array, X_test_handcrafted_Murilo, X_test_pure))\n",
        "    y_test = df_test[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    print(f\"Divisão de dados para Competência {comp_idx}: Treino={X_train.shape}, Validação={X_val.shape}, Teste={X_test.shape}\", flush=True)\n",
        "\n",
        "    scaler_comp = StandardScaler()\n",
        "    X_train_std = scaler_comp.fit_transform(X_train)\n",
        "    X_val_std = scaler_comp.transform(X_val)\n",
        "    X_test_std = scaler_comp.transform(X_test)\n",
        "    print(f\"Features escaladas para Competência {comp_idx}.\", flush=True)\n",
        "\n",
        "    data_module_competencia = CompetenceDataModule(X_train_std, y_train, X_val_std, y_val, X_test_std, y_test, BATCH_SIZE, NUM_WORKERS)\n",
        "    data_module_competencia.setup()\n",
        "\n",
        "    input_dim = X_train_std.shape[1]\n",
        "\n",
        "    pytorch_model_competencia = MultiLayerPerceptron(\n",
        "        input_size=input_dim,\n",
        "        hidden_units=(256, 128, 64),\n",
        "        num_classes=NUM_CLASSES_COMPETENCIA\n",
        "    )\n",
        "    lightning_model_competencia = LightningMLP(\n",
        "        model=pytorch_model_competencia,\n",
        "        learning_rate=LEARNING_RATE\n",
        "    )\n",
        "\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        save_top_k=1, mode=\"min\", monitor=\"valid_mae\",\n",
        "        dirpath=f\"logs_comp_{comp_idx}/\", filename=f\"best_model_comp_{comp_idx}\"\n",
        "    )\n",
        "    logger_competencia = CSVLogger(save_dir=\"logs/\", name=f\"mlp-coral-comp-{comp_idx}\")\n",
        "\n",
        "\n",
        "    early_stop_callback = EarlyStopping(\n",
        "    monitor=\"valid_qwk\",\n",
        "    min_delta=0.00,\n",
        "    patience=50,\n",
        "    verbose=True,\n",
        "    mode=\"max\"\n",
        "    )\n",
        "\n",
        "    callbacks_list = [\n",
        "        model_checkpoint_callback,\n",
        "        early_stop_callback\n",
        "    ]\n",
        "\n",
        "    trainer_competencia = pl.Trainer(\n",
        "        max_epochs=NUM_EPOCHS,\n",
        "        callbacks=callbacks_list,\n",
        "        accelerator=device_type,\n",
        "        devices=1,\n",
        "        logger=logger_competencia,\n",
        "        deterministic=True,\n",
        "        log_every_n_steps=10\n",
        "    )\n",
        "\n",
        "    start_time = time.time()\n",
        "    print(f\"Treinando modelo para Competência {comp_idx}...\", flush=True)\n",
        "    trainer_competencia.fit(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    runtime = (time.time() - start_time)/60\n",
        "    print(f\"Treinamento para Competência {comp_idx} levou {runtime:.2f} min.\", flush=True)\n",
        "\n",
        "    print(f\"Avaliando modelo para Competência {comp_idx} no conjunto de teste...\", flush=True)\n",
        "    test_results = trainer_competencia.test(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    resultados_por_competencia[f'competencia_{comp_idx}'] = test_results[0]\n",
        "\n",
        "    model_path = model_checkpoint_callback.best_model_path\n",
        "    best_model = LightningMLP.load_from_checkpoint(model_path, model=pytorch_model_competencia, learning_rate=LEARNING_RATE)\n",
        "    best_model.eval()\n",
        "\n",
        "    y_pred_list = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_module_competencia.test_dataloader():\n",
        "            features, _ = batch\n",
        "            logits = best_model(features)\n",
        "            probas = torch.sigmoid(logits)\n",
        "            predicted_labels = proba_to_label(probas)\n",
        "            y_pred_list.append(predicted_labels.cpu().numpy())\n",
        "\n",
        "    y_pred = np.hstack(y_pred_list)\n",
        "    y_true = y_test\n",
        "\n",
        "    y_pred_discreto = np.clip(np.round(y_pred), 0, NUM_CLASSES_COMPETENCIA - 1).astype(int)\n",
        "\n",
        "    print(\"--- Relatório de Classificação da Competência \", comp_idx, \" ---\")\n",
        "    print(classification_report(y_true, y_pred_discreto, zero_division=0.0))\n",
        "    print(\"\\n--- Matriz de Confusão da Competência \", comp_idx, \" ---\")\n",
        "    print(confusion_matrix(y_true, y_pred_discreto))\n",
        "    print(f\"--- Modelo para Competência {comp_idx} concluído ---\", flush=True)\n",
        "\n",
        "print(\"\\n--- Todos os modelos de competência foram treinados e avaliados ---\", flush=True)\n",
        "for comp, results in resultados_por_competencia.items():\n",
        "    print(f\"{comp}: QWK = {results['test_qwk']:.4f}, RMSE = {results['test_rmse']:.4f}, HDIV = {1- results['test_enem_acc']:.4f}\", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "teste easy"
      ],
      "metadata": {
        "id": "Fcyxpw73T0rw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# df_train = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_train.csv\")\n",
        "# df_val = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_validation.csv\")\n",
        "# df_test = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_test.csv\")\n",
        "\n",
        "resultados_por_competencia = {}\n",
        "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "for comp_idx in range(1, 6):\n",
        "    print(f\"\\n--- Treinando Modelo para Competência {comp_idx} ---\", flush=True)\n",
        "\n",
        "    X_train = np.hstack((X_train_handcrafted, X_train_tfidf_final_array, X_train_handcrafted_Murilo, X_train_pure))\n",
        "    y_train = df_train[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_val = np.hstack((X_val_handcrafted, X_val_tfidf_final_array, X_val_handcrafted_Murilo, X_val_pure))\n",
        "    y_val = df_val[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_test = np.hstack((X_test_easy_handcrafted, X_test_easy_tfidf_final_array, X_test_easy_handcrafted_Murilo, X_test_easy_pure))\n",
        "    y_test = df_test_easy[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    print(f\"Divisão de dados para Competência {comp_idx}: Treino={X_train.shape}, Validação={X_val.shape}, Teste={X_test.shape}\", flush=True)\n",
        "\n",
        "    scaler_comp = StandardScaler()\n",
        "    X_train_std = scaler_comp.fit_transform(X_train)\n",
        "    X_val_std = scaler_comp.transform(X_val)\n",
        "    X_test_std = scaler_comp.transform(X_test)\n",
        "    print(f\"Features escaladas para Competência {comp_idx}.\", flush=True)\n",
        "\n",
        "    data_module_competencia = CompetenceDataModule(X_train_std, y_train, X_val_std, y_val, X_test_std, y_test, BATCH_SIZE, NUM_WORKERS)\n",
        "    data_module_competencia.setup()\n",
        "\n",
        "    input_dim = X_train_std.shape[1]\n",
        "\n",
        "    pytorch_model_competencia = MultiLayerPerceptron(\n",
        "        input_size=input_dim,\n",
        "        hidden_units=(256, 128, 64),\n",
        "        num_classes=NUM_CLASSES_COMPETENCIA\n",
        "    )\n",
        "    lightning_model_competencia = LightningMLP(\n",
        "        model=pytorch_model_competencia,\n",
        "        learning_rate=LEARNING_RATE\n",
        "    )\n",
        "\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        save_top_k=1, mode=\"min\", monitor=\"valid_mae\",\n",
        "        dirpath=f\"logs_comp_{comp_idx}/\", filename=f\"best_model_comp_{comp_idx}\"\n",
        "    )\n",
        "    logger_competencia = CSVLogger(save_dir=\"logs/\", name=f\"mlp-coral-comp-{comp_idx}\")\n",
        "\n",
        "\n",
        "    early_stop_callback = EarlyStopping(\n",
        "    monitor=\"valid_qwk\",\n",
        "    min_delta=0.00,\n",
        "    patience=50,\n",
        "    verbose=True,\n",
        "    mode=\"max\"\n",
        "    )\n",
        "\n",
        "    callbacks_list = [\n",
        "        model_checkpoint_callback,\n",
        "        early_stop_callback\n",
        "    ]\n",
        "\n",
        "    trainer_competencia = pl.Trainer(\n",
        "        max_epochs=NUM_EPOCHS,\n",
        "        callbacks=callbacks_list,\n",
        "        accelerator=device_type,\n",
        "        devices=1,\n",
        "        logger=logger_competencia,\n",
        "        deterministic=True,\n",
        "        log_every_n_steps=10\n",
        "    )\n",
        "\n",
        "    start_time = time.time()\n",
        "    print(f\"Treinando modelo para Competência {comp_idx}...\", flush=True)\n",
        "    trainer_competencia.fit(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    runtime = (time.time() - start_time)/60\n",
        "    print(f\"Treinamento para Competência {comp_idx} levou {runtime:.2f} min.\", flush=True)\n",
        "\n",
        "    print(f\"Avaliando modelo para Competência {comp_idx} no conjunto de teste...\", flush=True)\n",
        "    test_results = trainer_competencia.test(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    resultados_por_competencia[f'competencia_{comp_idx}'] = test_results[0]\n",
        "\n",
        "    model_path = model_checkpoint_callback.best_model_path\n",
        "    best_model = LightningMLP.load_from_checkpoint(model_path, model=pytorch_model_competencia, learning_rate=LEARNING_RATE)\n",
        "    best_model.eval()\n",
        "\n",
        "    y_pred_list = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_module_competencia.test_dataloader():\n",
        "            features, _ = batch\n",
        "            logits = best_model(features)\n",
        "            probas = torch.sigmoid(logits)\n",
        "            predicted_labels = proba_to_label(probas)\n",
        "            y_pred_list.append(predicted_labels.cpu().numpy())\n",
        "\n",
        "    y_pred = np.hstack(y_pred_list)\n",
        "    y_true = y_test\n",
        "\n",
        "    y_pred_discreto = np.clip(np.round(y_pred), 0, NUM_CLASSES_COMPETENCIA - 1).astype(int)\n",
        "\n",
        "    print(\"--- Relatório de Classificação da Competência \", comp_idx, \" ---\")\n",
        "    print(classification_report(y_true, y_pred_discreto, zero_division=0.0))\n",
        "    print(\"\\n--- Matriz de Confusão da Competência \", comp_idx, \" ---\")\n",
        "    print(confusion_matrix(y_true, y_pred_discreto))\n",
        "\n",
        "    print(f\"--- Modelo para Competência {comp_idx} concluído ---\", flush=True)\n",
        "\n",
        "print(\"\\n--- Todos os modelos de competência foram treinados e avaliados ---\", flush=True)\n",
        "for comp, results in resultados_por_competencia.items():\n",
        "    print(f\"{comp}: QWK = {results['test_qwk']:.4f}, RMSE = {results['test_rmse']:.4f}, HDIV = {1- results['test_enem_acc']:.4f}\", flush=True)"
      ],
      "metadata": {
        "id": "7M-GR4QwT2on"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "neyIHZ4sV7c0",
        "v8cWBuX7avcA",
        "al-3J8En5enw",
        "dZYW-Jsu3RtE",
        "PpR3-rOG5sX1",
        "Luqc3udpwAX5",
        "BAt8GrhA8fin",
        "RWNec_aT8vNY",
        "sJmzDbPsSYry",
        "HpR8i-cplwuP",
        "D0x03reKDj0n",
        "5Xhzol4FS3jp",
        "icNvU_I1zj6x",
        "U9Qj8PYb-PjP",
        "v2Q4PcRc1xYz",
        "C5VKkj742HSt",
        "FKVQ_fbTN7XN",
        "gvIotJtLJFDB",
        "0HsYfeRAFmun",
        "Q3qUt7Z5F3-g"
      ],
      "provenance": [],
      "mount_file_id": "1i5-vPwnxR9NwmAXD3RX11bpoyHRmI6QP",
      "authorship_tag": "ABX9TyPb/UiJ5OISDiCqSTnwHM4S",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}